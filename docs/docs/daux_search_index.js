load_search_index({"pages":[{"title":"Kalaxy2 Cluster","text":"Useful links: https:\/\/github.com\/donb4iu\/kalaxy2 https:\/\/donb4iu.github.io\/kalaxy2\/","tags":"","url":"index.html"},{"title":"convolutional neural network","text":"Table of Contents Convolutional Neural Network References #Convolutional Neural Network #References Running a Convolutional Neural Network on Raspberry PI","tags":"","url":"ai\/convolutional_neural_network.html"},{"title":"ansible automation","text":"Table of Contents Anisble Automation Ansible Role: microk8s Requirements License Usage Role Variables Basic playbook Custom certificate request template Adding worker only nodes (1.23+ only) Testing Using Molecule wrapper and system Python Using Python virtual environment Create partitions MicroK8s Community play books Storage role #Anisble Automation Kubernetes With Ansible #Ansible Role: microk8s istvano\/ansible_role_microk8s cloud-native-skunkworks\/microk8s-ansible Role to download and install microk8s the smallest, simplest, pure production K8s. #Requirements Ansible &gt;= 2.7 Linux Distribution Debian Family Ubuntu Xenial (16.04) Bionic (18.04) Focal (20.04) Arch Linux (untested) #License MIT #Usage #Role Variables Some variables available in this role are listed here. The full set is defined in [defaults\/main.yml](defaults\/main.yml). microk8s_version: Version to use, defaults to 1.19\/stable. microk8s_plugins: Enable\/disable various plugins. A string will be passed as arg when enabling addon using name:arg microk8s_enable_HA: Enable\/disable high-availability. microk8s_group_HA: Hostgroup whose members will form HA cluster. microk8s_group_WORKERS: Hostgroup whose members will act as worker nodes only (no control-plane components run here) microk8s_csr_template: If defined, will cause a custom CSR to be used in generating certificates. #Basic playbook - hosts: servers roles: - role: istvano.microk8s vars: microk8s_plugins: dns: \"1.1.1.1\" istio: true ingress: true #Custom certificate request template It might be useful to customize the certificate request template used by MicroK8s in generating cluster certificates. For example, additional SANs can be added to the certificates such that the MicroK8s certificates validate when addressed from outside the cluster, such as through a reverse proxy. To generate a CSR template, the easiest is probably to use the role without a template, and then copy the CSR in \/var\/snap\/microk8s\/current\/certs\/csr.conf.template to your playbook\u2019s templates directory, make the edits and set the microk8s_csr_template variable accordingly, and re-run the playbook. #Adding worker only nodes (1.23+ only) It is possible to configure additional nodes to act as workers only within your microk8s cluster. This is possible by configuring the ansible hostgroup microk8s_WORKERS (name of the group is configurable via microk8s_group_WORKERS). Every host listed within the hostgroup will essentially run microk8s join .... --worker, more info on this can be found here: microk8s-clustering. #Testing #Using Molecule wrapper and system Python .\/moleculew lint .\/moleculew create .\/moleculew list .\/moleculew check .\/moleculew test #Using Python virtual environment Set up virtual environment $ python3 -m venv venv Activate the environment $ . venv\/bin\/activate Install Molecule with lint and Docker options $ pip install 'molecule[lint,docker]' Install up-to-date Ansible package if necessary $ pip install ansible Run the test commands: molecule lint molecule create molecule list molecule check molecule test #Create partitions ansible disk partition management using playbook #MicroK8s Ansible Role: microk8s #Community play books Community play books #Storage role Simple Partitioning with Ansible Storage Role","tags":"","url":"ansible\/ansible_automation.html"},{"title":"microk8s setup","text":"Table of Contents MicroK8s Setup Reference Commands #( 01\/06\/24@11:19PM )( donbuddenbaum@donbs-imac ):~\/Documents\/Kalaxy2\/ansible@main\u2717\u2717\u2717 #MicroK8s Setup #Reference An Ansible MicroK8s Install of Kubernetes istvano\/ansible_role_microk8s https:\/\/github.com\/8grams\/ansible-microk8s\/blob\/main\/install_microk8s.yaml https:\/\/github.com\/cloud-native-skunkworks\/microk8s-ansible\/blob\/main\/microk8s\/tasks\/main.yml #Commands ##( 01\/06\/24@11:19PM )( donbuddenbaum@donbs-imac ):~\/Documents\/Kalaxy2\/ansible@main\u2717\u2717\u2717 ansible rpi4 -m ping [WARNING]: Invalid characters were found in group names but not replaced, use -vvvv to see details arm64-02 | SUCCESS =&gt; { &quot;changed&quot;: false, &quot;ping&quot;: &quot;pong&quot; } arm64-05 | SUCCESS =&gt; { &quot;changed&quot;: false, &quot;ping&quot;: &quot;pong&quot; } arm64-04 | SUCCESS =&gt; { &quot;changed&quot;: false, &quot;ping&quot;: &quot;pong&quot; } arm64-03 | SUCCESS =&gt; { &quot;changed&quot;: false, &quot;ping&quot;: &quot;pong&quot; } arm64-01 | SUCCESS =&gt; { &quot;changed&quot;: false, &quot;ping&quot;: &quot;pong&quot; }","tags":"","url":"ansible\/microk8s_setup.html"},{"title":"storage","text":"Table of Contents Storage #Storage Create a Logical volume using Ansible","tags":"","url":"ansible\/storage.html"},{"title":"actions","text":"Table of Contents Git Actions Resources Setup Docker Run #Git Actions #Resources Copy files to another repository Deploying static sites to GitHub Pages using GitHub Actions Using Docker Run inside of GitHub Actions #Setup #Docker Run - name: Generate static Daux webpages uses: addnab\/docker-run-action@v3 with: image: daux\/daux.io:latest options: | --rm -v ${{ github.workspace }}:\/build -w \/build run: \/daux\/bin\/daux generate -s markdown -d docs addnab\/docker-run-action@v3 doesnt support entry point so have to call executible directly","tags":"","url":"automation\/github\/actions.html"},{"title":"jenkins argocd","text":"Table of Contents Jenkins &amp; ArgoCD References Setup #Jenkins &amp; ArgoCD #References Technical Guide: End-to-End CI\/CD DevOps with Jenkins, Terraform, Docker, Kubernetes, SonarQube, ArgoCD, AWS EC2, EKS, and GitHub Actions (Django Deployment) djangoproject #Setup","tags":"","url":"cicd\/jenkins_argocd.html"},{"title":"docker","text":"Table of Contents Clickhose Docker Reference #Clickhose Docker #Reference https:\/\/hub.docker.com\/r\/clickhouse\/clickhouse-server\/","tags":"","url":"clickhouse\/docker.html"},{"title":"documentation","text":"Table of Contents Clickhouse Documentation Reference Setup #Clickhouse Documentation #Reference Install ClickHouse Effortlessly Deploying ClickHouse on Kubernetes: A Comprehensive Guide ClickHouse on Kubernetes Installing Clickhouse on a kubernetes cluster #Setup","tags":"","url":"clickhouse\/documentation.html"},{"title":"kubernetes operator","text":"Table of Contents ClickHouse Kubernetes Operator References Setup Quick Start Setup #( 02\/18\/24@10:18PM )( donbuddenbaum@donbs-imac ):~\/Documents\/clickhouse-operator\/deploy\/operator@master\u2714 #( 02\/18\/24@11:22PM )( donbuddenbaum@donbs-imac ):~\/Documents\/Kalaxy2@main\u2714 Tests #( 02\/18\/24@10:22PM )( donbuddenbaum@donbs-imac ):~\/Documents\/clickhouse-operator\/deploy\/operator@master\u2714 #( 02\/18\/24@10:31PM )( donbuddenbaum@donbs-imac ):~\/Documents\/Kalaxy2\/yaml\/clickhouse@main\u2717\u2717\u2717 #( 02\/18\/24@10:32PM )( donbuddenbaum@donbs-imac ):~\/Documents\/Kalaxy2\/yaml\/clickhouse@main\u2717\u2717\u2717 chi-demo-01-demo-01-0-0-0.chi-demo-01-demo-01-0-0.demo.svc.cluster.local :) chi-demo-01-demo-01-0-0-0.chi-demo-01-demo-01-0-0.demo.svc.cluster.local :) chi-demo-01-demo-01-0-0-0.chi-demo-01-demo-01-0-0.demo.svc.cluster.local :) chi-demo-01-demo-01-0-0-0.chi-demo-01-demo-01-0-0.demo.svc.cluster.local :) SELECT DISTINCT(pickup_ntaname) FROM trips chi-demo-01-demo-01-0-0-0.chi-demo-01-demo-01-0-0.demo.svc.cluster.local :) SELECT round(avg(tip_amount), 2) FROM trips chi-demo-01-demo-01-0-0-0.chi-demo-01-demo-01-0-0.demo.svc.cluster.local :) SELECT passenger_count, ceil(avg(total_amount),2) AS average_total_amount FROM trips GROUP BY passenger_count chi-demo-01-demo-01-0-0-0.chi-demo-01-demo-01-0-0.demo.svc.cluster.local :) CREATE DICTIONARY taxi_zone_dictionary(LocationID UInt16 DEFAULT 0,Borough String,Zone String,service_zone String) PRIMARY KEY LocationID SOURCE(HTTP(URL \u2018https:\/\/datasets-documentation.s3.eu-west-3.amazonaws.com\/nyc-taxi\/taxi_zone_lookup.csv\u2019 FORMAT \u2018CSVWithNames\u2019)) LIFETIME(MIN 0 MAX 0) LAYOUT(HASHED_ARRAY()) chi-demo-01-demo-01-0-0-0.chi-demo-01-demo-01-0-0.demo.svc.cluster.local :) SELECT dictGet(\u2018taxi_zone_dictionary\u2019, \u2018Borough\u2019, 132) chi-demo-01-demo-01-0-0-0.chi-demo-01-demo-01-0-0.demo.svc.cluster.local :) SELECT dictGet(\u2018taxi_zone_dictionary\u2019, \u2018Borough\u2019, 132) chi-demo-01-demo-01-0-0-0.chi-demo-01-demo-01-0-0.demo.svc.cluster.local :) SELECT count(1) AS total, dictGetOrDefault(\u2018taxi_zone_dictionary\u2019,\u2018Borough\u2019, toUInt64(pickup_nyct2010_gid), \u2018Unknown\u2019) AS borough_name FROM trips WHERE dropoff_nyct2010_gid = 132 OR dropoff_nyct2010_gid = 138 GROUP BY borough_name ORDER BY total DESC chi-demo-01-demo-01-0-0-0.chi-demo-01-demo-01-0-0.demo.svc.cluster.local :) SELECT count(1) AS total, Borough FROM trips JOIN taxi_zone_dictionary ON toUInt64(trips.pickup_nyct2010_gid) = taxi_zone_dictionary.LocationID WHERE dropoff_nyct2010_gid = 132 OR dropoff_nyct2010_gid = 138 GROUP BY Borough ORDER BY total DESC #ClickHouse Kubernetes Operator #References Quick Start Guides Effortlessly Deploying ClickHouse on Kubernetes: A Comprehensive Guide #Setup #Quick Start #Setup ##( 02\/18\/24@10:18PM )( donbuddenbaum@donbs-imac ):~\/Documents\/clickhouse-operator\/deploy\/operator@master\u2714 kubectl apply -f https:\/\/raw.githubusercontent.com\/Altinity\/clickhouse-operator\/master\/deploy\/operator\/clickhouse-operator-install-bundle.yaml customresourcedefinition.apiextensions.k8s.io\/clickhouseinstallations.clickhouse.altinity.com unchanged customresourcedefinition.apiextensions.k8s.io\/clickhouseinstallationtemplates.clickhouse.altinity.com unchanged customresourcedefinition.apiextensions.k8s.io\/clickhouseoperatorconfigurations.clickhouse.altinity.com unchanged customresourcedefinition.apiextensions.k8s.io\/clickhousekeeperinstallations.clickhouse-keeper.altinity.com unchanged serviceaccount\/clickhouse-operator unchanged clusterrole.rbac.authorization.k8s.io\/clickhouse-operator-kube-system unchanged clusterrolebinding.rbac.authorization.k8s.io\/clickhouse-operator-kube-system unchanged configmap\/etc-clickhouse-operator-files unchanged configmap\/etc-clickhouse-operator-confd-files configured configmap\/etc-clickhouse-operator-configd-files unchanged configmap\/etc-clickhouse-operator-templatesd-files unchanged configmap\/etc-clickhouse-operator-usersd-files unchanged secret\/clickhouse-operator configured deployment.apps\/clickhouse-operator unchanged service\/clickhouse-operator-metrics unchanged ##( 02\/18\/24@11:22PM )( donbuddenbaum@donbs-imac ):~\/Documents\/Kalaxy2@main\u2714 kubectl get all -n demo NAME READY STATUS RESTARTS AGE pod\/chi-demo-01-demo-01-0-0-0 1\/1 Running 0 56m NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE service\/chi-demo-01-demo-01-0-0 ClusterIP None &lt;none&gt; 9000\/TCP,8123\/TCP,9009\/TCP 56m service\/clickhouse-demo-01 LoadBalancer 10.152.183.114 192.168.2.21 8123:31182\/TCP,9000:31455\/TCP 56m NAME READY AGE statefulset.apps\/chi-demo-01-demo-01-0-0 1\/1 56m #Tests ##( 02\/18\/24@10:22PM )( donbuddenbaum@donbs-imac ):~\/Documents\/clickhouse-operator\/deploy\/operator@master\u2714 kubectl create namespace demo namespace\/demo created ##( 02\/18\/24@10:31PM )( donbuddenbaum@donbs-imac ):~\/Documents\/Kalaxy2\/yaml\/clickhouse@main\u2717\u2717\u2717 kubectl apply -f demo.yaml -n demo clickhouseinstallation.clickhouse.altinity.com\/demo-01 created ##( 02\/18\/24@10:32PM )( donbuddenbaum@donbs-imac ):~\/Documents\/Kalaxy2\/yaml\/clickhouse@main\u2717\u2717\u2717 kubectl exec -it chi-demo-01-demo-01-0-0-0 -n demo \u2013 clickhouse-client ClickHouse client version 24.1.5.6 (official build). Connecting to localhost:9000 as user default. Connected to ClickHouse server version 24.1.5. #chi-demo-01-demo-01-0-0-0.chi-demo-01-demo-01-0-0.demo.svc.cluster.local :) CREATE TABLE trips ( trip_id UInt32, vendor_id Enum8(\u20181\u2019 = 1, \u20182\u2019 = 2, \u20183\u2019 = 3, \u20184\u2019 = 4, \u2018CMT\u2019 = 5, \u2018VTS\u2019 = 6, \u2018DDS\u2019 = 7, \u2018B02512\u2019 = 10, \u2018B02598\u2019 = 11, \u2018B02617\u2019 = 12, \u2018B02682\u2019 = 13, \u2018B02764\u2019 = 14, \u2018\u2019 = 15), pickup_date Date, pickup_datetime DateTime, dropoff_date Date, dropoff_datetime DateTime, store_and_fwd_flag UInt8, rate_code_id UInt8, pickup_longitude Float64, pickup_latitude Float64, dropoff_longitude Float64, dropoff_latitude Float64, passenger_count UInt8, trip_distance Float64, fare_amount Float32, extra Float32, mta_tax Float32, tip_amount Float32, tolls_amount Float32, ehail_fee Float32, improvement_surcharge Float32, total_amount Float32, payment_type Enum8(\u2018UNK\u2019 = 0, \u2018CSH\u2019 = 1, \u2018CRE\u2019 = 2, \u2018NOC\u2019 = 3, \u2018DIS\u2019 = 4), trip_type UInt8, pickup FixedString(25), dropoff FixedString(25), cab_type Enum8(\u2018yellow\u2019 = 1, \u2018green\u2019 = 2, \u2018uber\u2019 = 3), pickup_nyct2010_gid Int8, pickup_ctlabel Float32, pickup_borocode Int8, pickup_ct2010 String, pickup_boroct2010 String, pickup_cdeligibil String, pickup_ntacode FixedString(4), pickup_ntaname String, pickup_puma UInt16, dropoff_nyct2010_gid UInt8, dropoff_ctlabel Float32, dropoff_borocode UInt8, dropoff_ct2010 String, dropoff_boroct2010 String, dropoff_cdeligibil String, dropoff_ntacode FixedString(4), dropoff_ntaname String, dropoff_puma UInt16 ) ENGINE = MergeTree PARTITION BY toYYYYMM(pickup_date) ORDER BY pickup_datetime Query id: 58068e7f-c033-434f-a6e6-d3022a6265d4 Ok. 0 rows in set. Elapsed: 0.015 sec. #chi-demo-01-demo-01-0-0-0.chi-demo-01-demo-01-0-0.demo.svc.cluster.local :) INSERT INTO trips SELECT * FROM s3( \u2018https:\/\/datasets-documentation.s3.eu-west-3.amazonaws.com\/nyc-taxi\/trips_{1..2}.gz\u2019, \u2018TabSeparatedWithNames\u2019, \u201c trip_id UInt32, vendor_id Enum8(\u20181\u2019 = 1, \u20182\u2019 = 2, \u20183\u2019 = 3, \u20184\u2019 = 4, \u2018CMT\u2019 = 5, \u2018VTS\u2019 = 6, \u2018DDS\u2019 = 7, \u2018B02512\u2019 = 10, \u2018B02598\u2019 = 11, \u2018B02617\u2019 = 12, \u2018B02682\u2019 = 13, \u2018B02764\u2019 = 14, \u2018\u2019 = 15), pickup_date Date, pickup_datetime DateTime, dropoff_date Date, dropoff_datetime DateTime, store_and_fwd_flag UInt8, rate_code_id UInt8, pickup_longitude Float64, pickup_latitude Float64, dropoff_longitude Float64, dropoff_latitude Float64, passenger_count UInt8, trip_distance Float64, fare_amount Float32, extra Float32, mta_tax Float32, tip_amount Float32, tolls_amount Float32, ehail_fee Float32, improvement_surcharge Float32, total_amount Float32, payment_type Enum8(\u2018UNK\u2019 = 0, \u2018CSH\u2019 = 1, \u2018CRE\u2019 = 2, \u2018NOC\u2019 = 3, \u2018DIS\u2019 = 4), trip_type UInt8, pickup FixedString(25), dropoff FixedString(25), cab_type Enum8(\u2018yellow\u2019 = 1, \u2018green\u2019 = 2, \u2018uber\u2019 = 3), pickup_nyct2010_gid Int8, pickup_ctlabel Float32, pickup_borocode Int8, pickup_ct2010 String, pickup_boroct2010 String, pickup_cdeligibil String, pickup_ntacode FixedString(4), pickup_ntaname String, pickup_puma UInt16, dropoff_nyct2010_gid UInt8, dropoff_ctlabel Float32, dropoff_borocode UInt8, dropoff_ct2010 String, dropoff_boroct2010 String, dropoff_cdeligibil String, dropoff_ntacode FixedString(4), dropoff_ntaname String, dropoff_puma UInt16 \u201c) SETTINGS input_format_try_infer_datetimes = 0 INSERT INTO trips SETTINGS input_format_try_infer_datetimes = 0 SELECT * FROM s3(\u2018https:\/\/datasets-documentation.s3.eu-west-3.amazonaws.com\/nyc-taxi\/trips_{1..2}.gz\u2019, \u2018TabSeparatedWithNames\u2019, \\n \\trip_id` UInt32,\\n `vendor_id` Enum8(\u20181\u2019 = 1, \u20182\u2019 = 2, \u20183\u2019 = 3, \u20184\u2019 = 4, \u2018CMT\u2019 = 5, \u2018VTS\u2019 = 6, \u2018DDS\u2019 = 7, \u2018B02512\u2019 = 10, \u2018B02598\u2019 = 11, \u2018B02617\u2019 = 12, \u2018B02682\u2019 = 13, \u2018B02764\u2019 = 14, \u2018\u2019 = 15),\\n `pickup_date` Date,\\n `pickup_datetime` DateTime,\\n `dropoff_date` Date,\\n `dropoff_datetime` DateTime,\\n `store_and_fwd_flag` UInt8,\\n `rate_code_id` UInt8,\\n `pickup_longitude` Float64,\\n `pickup_latitude` Float64,\\n `dropoff_longitude` Float64,\\n `dropoff_latitude` Float64,\\n `passenger_count` UInt8,\\n `trip_distance` Float64,\\n `fare_amount` Float32,\\n `extra` Float32,\\n `mta_tax` Float32,\\n `tip_amount` Float32,\\n `tolls_amount` Float32,\\n `ehail_fee` Float32,\\n `improvement_surcharge` Float32,\\n `total_amount` Float32,\\n `payment_type` Enum8(\u2018UNK\u2019 = 0, \u2018CSH\u2019 = 1, \u2018CRE\u2019 = 2, \u2018NOC\u2019 = 3, \u2018DIS\u2019 = 4),\\n `trip_type` UInt8,\\n `pickup` FixedString(25),\\n `dropoff` FixedString(25),\\n `cab_type` Enum8(\u2018yellow\u2019 = 1, \u2018green\u2019 = 2, \u2018uber\u2019 = 3),\\n `pickup_nyct2010_gid` Int8,\\n `pickup_ctlabel` Float32,\\n `pickup_borocode` Int8,\\n `pickup_ct2010` String,\\n `pickup_boroct2010` String,\\n `pickup_cdeligibil` String,\\n `pickup_ntacode` FixedString(4),\\n `pickup_ntaname` String,\\n `pickup_puma` UInt16,\\n `dropoff_nyct2010_gid` UInt8,\\n `dropoff_ctlabel` Float32,\\n `dropoff_borocode` UInt8,\\n `dropoff_ct2010` String,\\n `dropoff_boroct2010` String,\\n `dropoff_cdeligibil` String,\\n `dropoff_ntacode` FixedString(4),\\n `dropoff_ntaname` String,\\n `dropoff_puma` UInt16\\n`) SETTINGS input_format_try_infer_datetimes = 0 Query id: 99d6ebed-032e-4138-8edc-342f5db144f6 Ok. 0 rows in set. Elapsed: 30.854 sec. Processed 2.00 million rows, 163.07 MB (64.81 thousand rows\/s., 5.29 MB\/s.) Peak memory usage: 1.20 GiB. #chi-demo-01-demo-01-0-0-0.chi-demo-01-demo-01-0-0.demo.svc.cluster.local :) SELECT count() FROM trips Query id: be0ab8c1-dd68-4f8a-9e25-3468c44566a9 \u250c\u2500count()\u2500\u2510 \u2502 1999657 \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 1 row in set. Elapsed: 0.003 sec. #chi-demo-01-demo-01-0-0-0.chi-demo-01-demo-01-0-0.demo.svc.cluster.local :) SELECT DISTINCT(pickup_ntaname) FROM trips SELECT DISTINCT pickup_ntaname FROM trips Query id: ec13863e-cc72-4495-9faf-60d86e5084d9 \u250c\u2500pickup_ntaname\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502 Upper East Side-Carnegie Hill \u2502 \u2502 East Village \u2502 \u2502 SoHo-TriBeCa-Civic Center-Little Italy \u2502 \u2502 Lincoln Square \u2502 \u2502 Battery Park City-Lower Manhattan \u2502 \u2502 Midtown-Midtown South \u2502 \u2502 North Side-South Side \u2502 \u2502 Gramercy \u2502 \u2502 Murray Hill-Kips Bay \u2502 \u2502 Airport \u2502 \u2502 Clinton \u2502 \u2502 Central Harlem South \u2502 \u2502 Hudson Yards-Chelsea-Flatiron-Union Square \u2502 \u2502 West Village \u2502 \u2502 West Concourse \u2502 \u2502 Lenox Hill-Roosevelt Island \u2502 \u2502 Woodlawn-Wakefield \u2502 \u2502 Lower East Side \u2502 \u2502 Chinatown \u2502 \u2502 Upper West Side \u2502 \u2502 DUMBO-Vinegar Hill-Downtown Brooklyn-Boerum Hill \u2502 \u2502 \u2502 \u2502 Fort Greene \u2502 \u2502 Park Slope-Gowanus \u2502 \u2502 East Harlem North \u2502 \u2502 Turtle Bay-East Midtown \u2502 \u2502 Greenpoint \u2502 \u2502 East Williamsburg \u2502 \u2502 East Concourse-Concourse Village \u2502 \u2502 Astoria \u2502 \u2502 North Corona \u2502 \u2502 South Ozone Park \u2502 \u2502 Yorkville \u2502 \u2502 Crown Heights South \u2502 \u2502 Manhattanville \u2502 \u2502 Jackson Heights \u2502 \u2502 Kensington-Ocean Parkway \u2502 \u2502 Queensbridge-Ravenswood-Long Island City \u2502 \u2502 Elmhurst \u2502 \u2502 Carroll Gardens-Columbia Street-Red Hook \u2502 \u2502 Morningside Heights \u2502 \u2502 Bedford \u2502 \u2502 Woodside \u2502 \u2502 Old Astoria \u2502 \u2502 Ocean Hill \u2502 \u2502 Central Harlem North-Polo Grounds \u2502 \u2502 Hunters Point-Sunnyside-West Maspeth \u2502 \u2502 Rego Park \u2502 \u2502 Steinway \u2502 \u2502 Stuyvesant Town-Cooper Village \u2502 \u2502 Hamilton Heights \u2502 \u2502 East Harlem South \u2502 \u2502 park-cemetery-etc-Manhattan \u2502 \u2502 Kew Gardens \u2502 \u2502 Jamaica \u2502 \u2502 Sunset Park West \u2502 \u2502 Washington Heights South \u2502 \u2502 park-cemetery-etc-Queens \u2502 \u2502 Windsor Terrace \u2502 \u2502 Williamsburg \u2502 \u2502 Arden Heights \u2502 \u2502 Mott Haven-Port Morris \u2502 \u2502 Elmhurst-Maspeth \u2502 \u2502 Clinton Hill \u2502 \u2502 Newark Airport \u2502 \u2502 Hunts Point \u2502 \u2502 Brooklyn Heights-Cobble Hill \u2502 \u2502 Stuyvesant Heights \u2502 \u2502 Richmond Hill \u2502 \u2502 East Elmhurst \u2502 \u2502 Flushing \u2502 \u2502 Briarwood-Jamaica Hills \u2502 \u2502 Melrose South-Mott Haven North \u2502 \u2502 Glendale \u2502 \u2502 Spuyten Duyvil-Kingsbridge \u2502 \u2502 Crown Heights North \u2502 \u2502 South Jamaica \u2502 \u2502 Prospect Heights \u2502 \u2502 Kingsbridge Heights \u2502 \u2502 Prospect Lefferts Gardens-Wingate \u2502 \u2502 Bushwick South \u2502 \u2502 Kew Gardens Hills \u2502 \u2502 East New York \u2502 \u2502 Bay Ridge \u2502 \u2502 Sheepshead Bay-Gerritsen Beach-Manhattan Beach \u2502 \u2502 Forest Hills \u2502 \u2502 Baisley Park \u2502 \u2502 Marble Hill-Inwood \u2502 \u2502 park-cemetery-etc-Brooklyn \u2502 \u2502 Ozone Park \u2502 \u2502 Bushwick North \u2502 \u2502 Brownsville \u2502 \u2502 Jamaica Estates-Holliswood \u2502 \u2502 Flatbush \u2502 \u2502 University Heights-Morris Heights \u2502 \u2502 Murray Hill \u2502 \u2502 Springfield Gardens South-Brookville \u2502 \u2502 Bedford Park-Fordham North \u2502 \u2502 Ocean Parkway South \u2502 \u2502 Rosedale \u2502 \u2502 Corona \u2502 \u2502 Mount Hope \u2502 \u2502 Belmont \u2502 \u2502 Maspeth \u2502 \u2502 Ridgewood \u2502 \u2502 Woodhaven \u2502 \u2502 park-cemetery-etc-Bronx \u2502 \u2502 Pelham Bay-Country Club-City Island \u2502 \u2502 Borough Park \u2502 \u2502 Bensonhurst East \u2502 \u2502 Highbridge \u2502 \u2502 Washington Heights North \u2502 \u2502 Middle Village \u2502 \u2502 Homecrest \u2502 \u2502 Midwood \u2502 \u2502 Hammels-Arverne-Edgemere \u2502 \u2502 East New York (Pennsylvania Ave) \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u250c\u2500pickup_ntaname\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502 Bellerose \u2502 \u2502 Rugby-Remsen Village \u2502 \u2502 Dyker Heights \u2502 \u2502 Norwood \u2502 \u2502 Brighton Beach \u2502 \u2502 Canarsie \u2502 \u2502 Flatlands \u2502 \u2502 Cypress Hills-City Line \u2502 \u2502 Claremont-Bathgate \u2502 \u2502 Sunset Park East \u2502 \u2502 Fresh Meadows-Utopia \u2502 \u2502 Pomonok-Flushing Heights-Hillcrest \u2502 \u2502 East Flatbush-Farragut \u2502 \u2502 Great Kills \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u250c\u2500pickup_ntaname\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502 Gravesend \u2502 \u2502 Soundview-Castle Hill-Clason Point-Harding Park \u2502 \u2502 Georgetown-Marine Park-Bergen Beach-Mill Basin \u2502 \u2502 Springfield Gardens North \u2502 \u2502 Queensboro Hill \u2502 \u2502 Erasmus \u2502 \u2502 Van Cortlandt Village \u2502 \u2502 Bayside-Bayside Hills \u2502 \u2502 West Farms-Bronx River \u2502 \u2502 Morrisania-Melrose \u2502 \u2502 West New Brighton-New Brighton-St. George \u2502 \u2502 East Tremont \u2502 \u2502 Queens Village \u2502 \u2502 Soundview-Bruckner \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u250c\u2500pickup_ntaname\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502 Eastchester-Edenwald-Baychester \u2502 \u2502 Bronxdale \u2502 \u2502 Westchester-Unionport \u2502 \u2502 College Point \u2502 \u2502 Laurelton \u2502 \u2502 Williamsbridge-Olinville \u2502 \u2502 Old Town-Dongan Hills-South Beach \u2502 \u2502 Van Nest-Morris Park-Westchester Square \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u250c\u2500pickup_ntaname\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502 Seagate-Coney Island \u2502 \u2502 Stapleton-Rosebank \u2502 \u2502 Schuylerville-Throgs Neck-Edgewater Park \u2502 \u2502 Bensonhurst West \u2502 \u2502 Parkchester \u2502 \u2502 Madison \u2502 \u2502 Crotona Park East \u2502 \u2502 St. Albans \u2502 \u2502 Fordham South \u2502 \u2502 East Flushing \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u250c\u2500pickup_ntaname\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502 Breezy Point-Belle Harbor-Rockaway Park-Broad Channel \u2502 \u2502 Bath Beach \u2502 \u2502 Pelham Parkway \u2502 \u2502 Co-op City \u2502 \u2502 Longwood \u2502 \u2502 North Riverdale-Fieldston-Riverdale \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u250c\u2500pickup_ntaname\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502 Auburndale \u2502 \u2502 Grasmere-Arrochar-Ft. Wadsworth \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u250c\u2500pickup_ntaname\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502 Allerton-Pelham Gardens \u2502 \u2502 West Brighton \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u250c\u2500pickup_ntaname\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502 Whitestone \u2502 \u2502 Lindenwood-Howard Beach \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u250c\u2500pickup_ntaname\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502 New Dorp-Midland Beach \u2502 \u2502 Ft. Totten-Bay Terrace-Clearview \u2502 \u2502 Glen Oaks-Floral Park-New Hyde Park \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u250c\u2500pickup_ntaname\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502 New Springville-Bloomfield-Travis \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u250c\u2500pickup_ntaname\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502 Douglas Manor-Douglaston-Little Neck \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u250c\u2500pickup_ntaname\u2500\u2510 \u2502 Hollis \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u250c\u2500pickup_ntaname\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502 Annadale-Huguenot-Prince's Bay-Eltingville \u2502 \u2502 Cambria Heights \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u250c\u2500pickup_ntaname\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502 Mariner's Harbor-Arlington-Port Ivory-Graniteville \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u250c\u2500pickup_ntaname\u2500\u2500\u2510 \u2502 Oakland Gardens \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u250c\u2500pickup_ntaname\u2500\u2510 \u2502 Starrett City \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u250c\u2500pickup_ntaname\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502 Todt Hill-Emerson Hill-Heartland Village-Lighthouse Hill \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u250c\u2500pickup_ntaname\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502 Far Rockaway-Bayswater \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u250c\u2500pickup_ntaname\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502 New Brighton-Silver Lake \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u250c\u2500pickup_ntaname\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502 Grymes Hill-Clifton-Fox Hills \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 190 rows in set. Elapsed: 0.039 sec. Processed 2.00 million rows, 60.32 MB (51.59 million rows\/s., 1.56 GB\/s.) Peak memory usage: 12.67 MiB. #chi-demo-01-demo-01-0-0-0.chi-demo-01-demo-01-0-0.demo.svc.cluster.local :) SELECT round(avg(tip_amount), 2) FROM trips SELECT round(avg(tip_amount), 2) FROM trips Query id: 483688f5-7c70-4fde-ae8e-5fcd7c99a179 \u250c\u2500round(avg(tip_amount), 2)\u2500\u2510 \u2502 1.68 \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 1 row in set. Elapsed: 0.018 sec. Processed 2.00 million rows, 8.00 MB (113.75 million rows\/s., 455.00 MB\/s.) Peak memory usage: 129.33 KiB. #chi-demo-01-demo-01-0-0-0.chi-demo-01-demo-01-0-0.demo.svc.cluster.local :) SELECT passenger_count, ceil(avg(total_amount),2) AS average_total_amount FROM trips GROUP BY passenger_count SELECT passenger_count, ceil(avg(total_amount), 2) AS average_total_amount FROM trips GROUP BY passenger_count Query id: c60c9f21-c370-4c11-bd34-ae4a53008010 \u250c\u2500passenger_count\u2500\u252c\u2500average_total_amount\u2500\u2510 \u2502 0 \u2502 22.69 \u2502 \u2502 1 \u2502 15.97 \u2502 \u2502 2 \u2502 17.15 \u2502 \u2502 3 \u2502 16.76 \u2502 \u2502 4 \u2502 17.33 \u2502 \u2502 5 \u2502 16.35 \u2502 \u2502 6 \u2502 16.04 \u2502 \u2502 7 \u2502 59.8 \u2502 \u2502 8 \u2502 36.41 \u2502 \u2502 9 \u2502 9.81 \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 10 rows in set. Elapsed: 0.021 sec. Processed 2.00 million rows, 10.00 MB (97.00 million rows\/s., 484.98 MB\/s.) Peak memory usage: 1.06 MiB. #chi-demo-01-demo-01-0-0-0.chi-demo-01-demo-01-0-0.demo.svc.cluster.local :) CREATE DICTIONARY taxi_zone_dictionary(LocationID UInt16 DEFAULT 0,Borough String,Zone String,service_zone String) PRIMARY KEY LocationID SOURCE(HTTP(URL \u2018https:\/\/datasets-documentation.s3.eu-west-3.amazonaws.com\/nyc-taxi\/taxi_zone_lookup.csv\u2019 FORMAT \u2018CSVWithNames\u2019)) LIFETIME(MIN 0 MAX 0) LAYOUT(HASHED_ARRAY()) CREATE DICTIONARY taxi_zone_dictionary ( `LocationID` UInt16 DEFAULT 0, `Borough` String, `Zone` String, `service_zone` String ) PRIMARY KEY LocationID SOURCE(HTTP(URL 'https:\/\/datasets-documentation.s3.eu-west-3.amazonaws.com\/nyc-taxi\/taxi_zone_lookup.csv' FORMAT 'CSVWithNames')) LIFETIME(MIN 0 MAX 0) LAYOUT(HASHED_ARRAY()) Query id: 95f77c45-6815-4a5c-b17b-8fb1d318b9c2 Ok. 0 rows in set. Elapsed: 0.005 sec. #chi-demo-01-demo-01-0-0-0.chi-demo-01-demo-01-0-0.demo.svc.cluster.local :) SELECT dictGet(\u2018taxi_zone_dictionary\u2019, \u2018Borough\u2019, 132) SELECT dictGet('taxi_zone_dictionary', 'Borough', 132) Query id: 4497c71a-9bd5-4a1d-b189-2a0f637a54d0 \u250c\u2500dictGet('taxi_zone_dictionary', 'Borough', 132)\u2500\u2510 \u2502 Queens \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 1 row in set. Elapsed: 0.002 sec. #chi-demo-01-demo-01-0-0-0.chi-demo-01-demo-01-0-0.demo.svc.cluster.local :) SELECT dictGet(\u2018taxi_zone_dictionary\u2019, \u2018Borough\u2019, 132) SELECT dictGet('taxi_zone_dictionary', 'Borough', 132) Query id: 4fee18cd-3c94-4288-9234-48607279f482 \u250c\u2500dictGet('taxi_zone_dictionary', 'Borough', 132)\u2500\u2510 \u2502 Queens \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 1 row in set. Elapsed: 0.002 sec. #chi-demo-01-demo-01-0-0-0.chi-demo-01-demo-01-0-0.demo.svc.cluster.local :) SELECT count(1) AS total, dictGetOrDefault(\u2018taxi_zone_dictionary\u2019,\u2018Borough\u2019, toUInt64(pickup_nyct2010_gid), \u2018Unknown\u2019) AS borough_name FROM trips WHERE dropoff_nyct2010_gid = 132 OR dropoff_nyct2010_gid = 138 GROUP BY borough_name ORDER BY total DESC SELECT count(1) AS total, dictGetOrDefault('taxi_zone_dictionary', 'Borough', toUInt64(pickup_nyct2010_gid), 'Unknown') AS borough_name FROM trips WHERE (dropoff_nyct2010_gid = 132) OR (dropoff_nyct2010_gid = 138) GROUP BY borough_name ORDER BY total DESC Query id: 91476f58-cd09-45cb-bb7a-11806edbe6bf \u250c\u2500total\u2500\u252c\u2500borough_name\u2500\u2500\u2510 \u2502 23683 \u2502 Unknown \u2502 \u2502 7053 \u2502 Manhattan \u2502 \u2502 6828 \u2502 Brooklyn \u2502 \u2502 4458 \u2502 Queens \u2502 \u2502 2670 \u2502 Bronx \u2502 \u2502 554 \u2502 Staten Island \u2502 \u2502 53 \u2502 EWR \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 7 rows in set. Elapsed: 0.015 sec. Processed 2.00 million rows, 4.00 MB (130.46 million rows\/s., 260.91 MB\/s.) Peak memory usage: 804.58 KiB. #chi-demo-01-demo-01-0-0-0.chi-demo-01-demo-01-0-0.demo.svc.cluster.local :) SELECT count(1) AS total, Borough FROM trips JOIN taxi_zone_dictionary ON toUInt64(trips.pickup_nyct2010_gid) = taxi_zone_dictionary.LocationID WHERE dropoff_nyct2010_gid = 132 OR dropoff_nyct2010_gid = 138 GROUP BY Borough ORDER BY total DESC SELECT count(1) AS total, Borough FROM trips INNER JOIN taxi_zone_dictionary ON toUInt64(trips.pickup_nyct2010_gid) = taxi_zone_dictionary.LocationID WHERE (dropoff_nyct2010_gid = 132) OR (dropoff_nyct2010_gid = 138) GROUP BY Borough ORDER BY total DESC Query id: 0c387dd7-c25e-4b62-a9d3-71981c21f2c0 \u250c\u2500total\u2500\u252c\u2500Borough\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502 7053 \u2502 Manhattan \u2502 \u2502 6828 \u2502 Brooklyn \u2502 \u2502 4458 \u2502 Queens \u2502 \u2502 2670 \u2502 Bronx \u2502 \u2502 554 \u2502 Staten Island \u2502 \u2502 53 \u2502 EWR \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 6 rows in set. Elapsed: 0.049 sec. Processed 2.00 million rows, 4.00 MB (41.12 million rows\/s., 82.25 MB\/s.) Peak memory usage: 496.75 KiB.","tags":"","url":"clickhouse\/kubernetes_operator.html"},{"title":"next cloud","text":"Table of Contents Next Cloud References #Next Cloud #References nextcloud-microk8s Make your Nextcloud ready for access over the internet How to Create and Deploy Your Own Cloud Server with NextCloud Comprehensive NextCloud installation using Docker Compose the smart way","tags":"","url":"cloud\/next_cloud.html"},{"title":"deltalake","text":"Table of Contents Data engineering with delta lake References #Data engineering with delta lake #References Create Your Local Object Storage with MiniO, PySpark, and Delta Lake https:\/\/github.com\/IhorLuk","tags":"","url":"data_engineering\/deltalake.html"},{"title":"cockroachDB","text":"Table of Contents Cockroach References #Cockroach #References Deploying CockroachDB on a Raspberry Pi\u2019s Kubernetes Cluster Deploy CockroachDB in a Single Kubernetes Cluster CockroachDB Core Free and Open Source github","tags":"","url":"databases\/cockroachDB.html"},{"title":"mongodb","text":"Table of Contents Mongo DB References Client #Mongo DB #References How To Deploy MongoDB on Kubernetes \u2013 Beginners Guide #Client","tags":"","url":"databases\/mongodb.html"},{"title":"mysql","text":"Table of Contents MySQL References Python Setup Python (3.12.0-venv) #( 05\/17\/24@10:07PM )( donbuddenbaum@donbs-imac ):~\/Documents\/pollapp\/mysite@main\u2717\u2717\u2717 (3.12.0-venv) #( 05\/17\/24@10:42PM )( donbuddenbaum@donbs-imac ):~\/Documents\/pollapp\/mysite@main\u2717\u2717\u2717 #MySQL #References #Python mysqlclient 2.2.4 #Setup #Python #(3.12.0-venv) #( 05\/17\/24@10:07PM )( donbuddenbaum@donbs-imac ):~\/Documents\/pollapp\/mysite@main\u2717\u2717\u2717 brew install mysql-client pkg-config #(3.12.0-venv) #( 05\/17\/24@10:42PM )( donbuddenbaum@donbs-imac ):~\/Documents\/pollapp\/mysite@main\u2717\u2717\u2717 pip install mysqlclient Collecting mysqlclient Downloading mysqlclient-2.2.4.tar.gz (90 kB) \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 90.4\/90.4 kB 1.4 MB\/s eta 0:00:00 Installing build dependencies ... done Getting requirements to build wheel ... done Installing backend dependencies ... done Preparing metadata (pyproject.toml) ... done Building wheels for collected packages: mysqlclient Building wheel for mysqlclient (pyproject.toml) ... done Created wheel for mysqlclient: filename=mysqlclient-2.2.4-cp312-cp312-macosx_13_0_x86_64.whl size=75307 sha256=36d7ca6e368506be94a17f3e9f8b105cfcd6e92de96bd16cf82c6c85a079caab Stored in directory: \/Users\/donbuddenbaum\/Library\/Caches\/pip\/wheels\/20\/6f\/c3\/3b23bb01988b1c0bea0668e2116315ce43ced2179724ab593e Successfully built mysqlclient Installing collected packages: mysqlclient Successfully installed mysqlclient-2.2.4","tags":"","url":"databases\/mysql.html"},{"title":"performant datamodels","text":"Table of Contents Performant Data Models References Options Views Often-Refreshed Tables Materialized Views Lambda View #Performant Data Models #References A Guide to Building Performant Real-Time Data Models #Options #Views #Often-Refreshed Tables #Materialized Views #Lambda View","tags":"","url":"databases\/performant_datamodels.html"},{"title":"documentation","text":"Table of Contents Daux Documentation Automatic Generation Generate Manually #( 05\/03\/22@ 2:00PM )( dbuddenbaum@donb-mbp4 ):~\/Documents\/rpi4\/kalaxy@main\u2717\u2717\u2717 Hosting site in a file in NGINX Multi Arc Build NGINX with static site #( 01\/10\/23@ 3:50PM )( donbuddenbaum@donbs-imac ):~\/Documents\/rPi4\/kalaxy@main\u2717\u2717\u2717 Single Arch Build NGINX with static site #( 07\/29\/22@ 5:23PM )( donbuddenbaum@donbs-imac ):~\/Documents\/rPi4\/kalaxy@main\u2717\u2717\u2717 #( 08\/22\/22@ 5:07PM )( donbuddenbaum@donbs-imac ):~\/Documents\/rPi4\/kalaxy\/yaml\/nginx\/k8s-doc-to-nginx@main\u2717\u2717\u2717 #( 08\/22\/22@ 5:19PM )( donbuddenbaum@donbs-imac ):~\/Documents\/rPi4\/kalaxy\/yaml\/nginx\/k8s-doc-to-nginx@main\u2717\u2717\u2717 #( 08\/22\/22@ 5:20PM )( donbuddenbaum@donbs-imac ):~\/Documents\/rPi4\/kalaxy\/yaml\/nginx\/k8s-doc-to-nginx@main\u2717\u2717\u2717 #( 08\/22\/22@ 5:31PM )( donbuddenbaum@donbs-imac ):~\/Documents\/rPi4\/kalaxy@main\u2717\u2717\u2717 Updating documentation #Daux Documentation daux.io #Automatic Generation git actions #Generate Manually ##( 05\/03\/22@ 2:00PM )( dbuddenbaum@donb-mbp4 ):~\/Documents\/rpi4\/kalaxy@main\u2717\u2717\u2717 docker run \u2013rm -it -w \/build -v \u201c$PWD\u201d:\/build daux\/daux.io daux generate -s markdown -d docs Copying Static assets ... [ OK ] Generating ... - alvearie\/alvearie.html [ OK ] - alvearie\/cohort_integration_docker.html [ OK ] - alvearie\/cohort_fhir_integration.html [ OK ] - alvearie\/cohorting.html [ OK ] - alvearie\/fhirserver.html [ OK ] - alvearie\/jupyter.html [ OK ] - ansible\/ansible_automation.html [ OK ] - ansible\/blog.html [ OK ] - ansible\/storage.html [ OK ] - boinc\/boinc.html [ OK ] - docker\/docker_cmds.html [ OK ] - docker\/multi_arch_docker.html [ OK ] - docker\/rpi4_docker.html [ OK ] - file_system\/ceph.html [ OK ] - file_system\/crd.html [ OK ] - file_system\/longhorn.html [ OK ] - file_system\/nfs.html [ OK ] - file_system\/rook_ceph.html [ OK ] - file_system\/samba.html [ OK ] - helm\/helm.html [ OK ] - images\/cluster-initial-up.png [ OK ] - images\/cohort-controllers.png [ OK ] - images\/dashboard.png [ OK ] - images\/fhir-server_context.png [ OK ] - images\/k8s-dashboard-1110x0694.png [ OK ] - images\/kubernetes-dashboard-args.png [ OK ] - images\/kubernetes-dashboard-ttl.png [ OK ] - images\/nodej_to_nginx.png [ OK ] - images\/raspi-array-0510x0905.jpg [ OK ] - images\/set_prometheus_server_datasource.png [ OK ] - images\/traeficdashboard.png [ OK ] - k8s\/containerd.html [ OK ] - k8s\/k8s.html [ OK ] - k8s\/kube_upgrade.html [ OK ] - k8s\/microk8s.html [ OK ] - k8s\/podnodeselector.html [ OK ] - k8s\/upgrade_nodes.html [ OK ] - knative\/knative.html [ OK ] - knative\/knative_examples.html [ OK ] - microk8s\/ansible\/microk8s_setup.html [ OK ] - microk8s\/certificates\/certmanager.html [ OK ] - microk8s\/dashboard\/dashboard.html [ OK ] - microk8s\/dashboard\/k8s_dashboard.html [ OK ] - microk8s\/dashboard\/microk8s_dashboard.html [ OK ] - microk8s\/metallb\/k8s_metallb.html [ OK ] - microk8s\/metallb\/metalLb.html [ OK ] - monitoring\/monitoring.html [ OK ] - mysite\/mysite.html [ OK ] - new_relic\/newrelic.html [ OK ] - public_IP\/publicUrls.html [ OK ] - README.html [ OK ] - references\/documentation.html [ OK ] - references\/mediumlinks.html [ OK ] - references\/youtube.html [ OK ] - setup\/bonded_NIC.html [ OK ] - setup\/notes.html [ OK ] - setup\/README.html [ OK ] - setup\/rpi_usb_ubuntu.html [ OK ] - setup\/rPi4_usb.html [ OK ] - sql\/mysql.html [ OK ] - sql\/progressSQL.html [ OK ] - traefik\/traefik.html [ OK ] - utilities\/k9s.html [ OK ] - utilities\/krew.html [ OK ] - utilities\/kube_setup.html [ OK ] - utilities\/kube_visualizer.html [ OK ] - utilities\/kube_cmds.html [ OK ] - utilities\/kubescrape.html [ OK ] - utilities\/python.html [ OK ] - utilities\/ssh.html #Hosting site in a file in NGINX #Multi Arc Build NGINX with static site ##( 01\/10\/23@ 3:50PM )( donbuddenbaum@donbs-imac ):~\/Documents\/rPi4\/kalaxy@main\u2717\u2717\u2717 docker buildx create \u2013use docker buildx build \u2013platform linux\/amd64,linux\/arm64 -f yaml\/nginx-docs\/k8s-doc-to-nginx\/nginx\/Dockerfile -t donb4iu\/mynginx_docs \u2013push . [+] Building 92.2s (12\/12) FINISHED =&gt; [internal] load build definition from Dockerfile 0.0s =&gt; =&gt; transferring dockerfile: 80B 0.0s =&gt; [internal] load .dockerignore 0.0s =&gt; =&gt; transferring context: 157B 0.0s =&gt; [linux\/arm64 internal] load metadata for docker.io\/library\/nginx:latest 2.6s =&gt; [linux\/amd64 internal] load metadata for docker.io\/library\/nginx:latest 2.6s =&gt; [auth] library\/nginx:pull token for registry-1.docker.io 0.0s =&gt; [linux\/arm64 1\/2] FROM docker.io\/library\/nginx@sha256:0047b729188a15da49380d9506d65959cce6d40291ccfb4e039f5dc7efd33286 12.4s =&gt; =&gt; resolve docker.io\/library\/nginx@sha256:0047b729188a15da49380d9506d65959cce6d40291ccfb4e039f5dc7efd33286 0.1s =&gt; =&gt; sha256:395a946c3309e7c3158fd712d7168056e3b7824fd7dfe6fdac53a82bc3fef8f5 772B \/ 772B 0.2s =&gt; =&gt; sha256:d48994bc2006b3d4a992f0435d3da2406ec5b789b66f67b2707c102bc9d2e99c 1.41kB \/ 1.41kB 0.3s =&gt; =&gt; sha256:b576e4a56718c7c91c2324bebaeb3a27819b1dc55a7854f2549c9ae53e3fc8f9 957B \/ 957B 0.3s =&gt; =&gt; sha256:b9e33cc8aa8c7049ee74b17da1b0121bbee92b33dd70beddb9e7afd745a3cd69 626B \/ 626B 0.2s =&gt; =&gt; sha256:3c419414ca9e1744a592d3379a913e0b03f596cba3cbb9e48e544931ac8e1d93 25.39MB \/ 25.39MB 8.0s =&gt; =&gt; sha256:4b7f5b2a311310809ab89d92f6f71b0462722fe855d3b92c93098a528aa08791 30.04MB \/ 30.04MB 8.9s =&gt; =&gt; extracting sha256:4b7f5b2a311310809ab89d92f6f71b0462722fe855d3b92c93098a528aa08791 2.0s =&gt; =&gt; extracting sha256:3c419414ca9e1744a592d3379a913e0b03f596cba3cbb9e48e544931ac8e1d93 1.1s =&gt; =&gt; extracting sha256:b9e33cc8aa8c7049ee74b17da1b0121bbee92b33dd70beddb9e7afd745a3cd69 0.0s =&gt; =&gt; extracting sha256:b576e4a56718c7c91c2324bebaeb3a27819b1dc55a7854f2549c9ae53e3fc8f9 0.0s =&gt; =&gt; extracting sha256:395a946c3309e7c3158fd712d7168056e3b7824fd7dfe6fdac53a82bc3fef8f5 0.0s =&gt; =&gt; extracting sha256:d48994bc2006b3d4a992f0435d3da2406ec5b789b66f67b2707c102bc9d2e99c 0.0s =&gt; [linux\/amd64 1\/2] FROM docker.io\/library\/nginx@sha256:0047b729188a15da49380d9506d65959cce6d40291ccfb4e039f5dc7efd33286 0.1s =&gt; =&gt; resolve docker.io\/library\/nginx@sha256:0047b729188a15da49380d9506d65959cce6d40291ccfb4e039f5dc7efd33286 0.1s =&gt; [internal] load build context 0.1s =&gt; =&gt; transferring context: 13.18kB 0.1s =&gt; CACHED [linux\/amd64 2\/2] COPY \/docs \/usr\/share\/nginx\/html 0.0s =&gt; [linux\/arm64 2\/2] COPY \/docs \/usr\/share\/nginx\/html 0.7s =&gt; exporting to image 76.4s =&gt; =&gt; exporting layers 0.9s =&gt; =&gt; exporting manifest sha256:5de25b6df58dc43d36675f3d193f2612262690ac31773bd5ea88b3410a39c79f 0.0s =&gt; =&gt; exporting config sha256:ecbd04a1f6f460526ad56f17c81ccdee945c8ad71e25dafe02f402a51e7da0c3 0.0s =&gt; =&gt; exporting manifest sha256:d2017164c15212fef955de57f96d4462e85ebf78f3e6cc5ec0758fad14ee22ad 0.0s =&gt; =&gt; exporting config sha256:ed6af09d02b9ea2aa099e1422cf05d91ad0f3b8da89b9ceb93b54c7da8f2cc3d 0.0s =&gt; =&gt; exporting manifest list sha256:fa8130d2f4322d2c5305210c036c79fa2422ca7f03d9e1fd0ecc15eb143472b5 0.0s =&gt; =&gt; pushing layers 74.2s =&gt; =&gt; pushing manifest for docker.io\/donb4iu\/mynginx_docs:latest@sha256:fa8130d2f4322d2c5305210c036c79fa2422ca7f03d9e1fd0ecc15eb143472b5 1.3s =&gt; [auth] donb4iu\/mynginx_docs:pull,push token for registry-1.docker.io #Single Arch Build NGINX with static site ##( 07\/29\/22@ 5:23PM )( donbuddenbaum@donbs-imac ):~\/Documents\/rPi4\/kalaxy@main\u2717\u2717\u2717 docker build -f yaml\/nginx-docs\/k8s-doc-to-nginx\/nginx\/Dockerfile -t donb4iu\/mynginx_docs . [+] Building 0.5s (7\/7) FINISHED =&gt; [internal] load build definition from Dockerfile 0.0s =&gt; =&gt; transferring dockerfile: 36B 0.0s =&gt; [internal] load .dockerignore 0.0s =&gt; =&gt; transferring context: 126B 0.0s =&gt; [internal] load metadata for docker.io\/library\/nginx:latest 0.4s =&gt; [internal] load build context 0.0s =&gt; =&gt; transferring context: 8.10kB 0.0s =&gt; [1\/2] FROM docker.io\/library\/nginx@sha256:bd06dfe1f8f7758debd49d3876023992d41842fd8921565aed315a678a309982 0.0s =&gt; CACHED [2\/2] COPY \/docs \/usr\/share\/nginx\/html 0.0s =&gt; exporting to image 0.0s =&gt; =&gt; exporting layers 0.0s =&gt; =&gt; writing image sha256:676ea3c57ea7bf2d3a49cbba8f9069f2d18e751a42779a2a9e3a367b0233252f 0.0s =&gt; =&gt; naming to docker.io\/donb4iu\/mynginx_docs 0.0s Use 'docker scan' to run Snyk tests against images to find vulnerabilities and learn how to fix them ##( 08\/22\/22@ 5:07PM )( donbuddenbaum@donbs-imac ):~\/Documents\/rPi4\/kalaxy\/yaml\/nginx\/k8s-doc-to-nginx@main\u2717\u2717\u2717 kubectl apply -f ns.yaml namespace\/documentation created ##( 08\/22\/22@ 5:19PM )( donbuddenbaum@donbs-imac ):~\/Documents\/rPi4\/kalaxy\/yaml\/nginx\/k8s-doc-to-nginx@main\u2717\u2717\u2717 kubectl apply -f nginx-doc-deployment.yaml deployment.apps\/nginx created ##( 08\/22\/22@ 5:20PM )( donbuddenbaum@donbs-imac ):~\/Documents\/rPi4\/kalaxy\/yaml\/nginx\/k8s-doc-to-nginx@main\u2717\u2717\u2717 kubectl apply -f nginx-doc-service.yaml service\/nginx created ##( 08\/22\/22@ 5:31PM )( donbuddenbaum@donbs-imac ):~\/Documents\/rPi4\/kalaxy@main\u2717\u2717\u2717 kubectl get services -n documentation NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE nginx LoadBalancer 10.152.183.178 192.168.2.25 3001:32512\/TCP 16m #Updating documentation kubectl scale -n documentation deployment nginx \u2013replicas=0 kubectl scale -n documentation deployment nginx \u2013replicas=1","tags":"","url":"documentation\/documentation.html"},{"title":"face recognition attendance system","text":"Table of Contents Face Recognition Attendance System References Setup MongoDB Cluster #Face Recognition Attendance System #References https:\/\/github.com\/CodeShareCW\/Attendlytical https:\/\/attendlytical.netlify.app\/ Part I: Implement a Face Recognition Attendance System with face-api.js Part II: Implement a Face Recognition Attendance System with face-api.js Part III: Implement a Face Recognition Attendance System with face-api.js Part IV: Serverless Deployment with Netlify Lambda (ReactJS FE + GraphQL BE) Part V: Kubernetes Deployment with Minikube For A Full Stack Application (React + NodeJS + GraphQL) #Setup #MongoDB Cluster https:\/\/cloud.mongodb.com\/v2\/666246014c572b50af60d3d3#\/overview","tags":"","url":"documentation\/nodejs\/face_recognition_attendance_system.html"},{"title":"node","text":"Table of Contents Node References Setup #( 06\/06\/24@ 5:04PM )( donbuddenbaum@donbs-imac ):~ #( 06\/06\/24@ 5:04PM )( donbuddenbaum@donbs-imac ):~ #Node #References Implement a Face Recognition Attendance System with face-api.js \u2014 Part III #Setup ##( 06\/06\/24@ 5:04PM )( donbuddenbaum@donbs-imac ):~ nvm Node Version Manager (v0.39.7) Note: &lt;version&gt; refers to any version-like string nvm understands. This includes: - full or partial version numbers, starting with an optional &quot;v&quot; (0.10, v0.1.2, v1) - default (built-in) aliases: node, stable, unstable, iojs, system - custom aliases you define with `nvm alias foo` Any options that produce colorized output should respect the `--no-colors` option. Usage: nvm --help Show this message --no-colors Suppress colored output nvm --version Print out the installed version of nvm nvm install [&lt;version&gt;] Download and install a &lt;version&gt;. Uses .nvmrc if available and version is omitted. The following optional arguments, if provided, must appear directly after `nvm install`: -s Skip binary download, install from source only. -b Skip source download, install from binary only. --reinstall-packages-from=&lt;version&gt; When installing, reinstall packages installed in &lt;node|iojs|node version number&gt; --lts When installing, only select from LTS (long-term support) versions --lts=&lt;LTS name&gt; When installing, only select from versions for a specific LTS line --skip-default-packages When installing, skip the default-packages file if it exists --latest-npm After installing, attempt to upgrade to the latest working npm on the given node version --no-progress Disable the progress bar on any downloads --alias=&lt;name&gt; After installing, set the alias specified to the version specified. (same as: nvm alias &lt;name&gt; &lt;version&gt;) --default After installing, set default alias to the version specified. (same as: nvm alias default &lt;version&gt;) nvm uninstall &lt;version&gt; Uninstall a version nvm uninstall --lts Uninstall using automatic LTS (long-term support) alias `lts\/*`, if available. nvm uninstall --lts=&lt;LTS name&gt; Uninstall using automatic alias for provided LTS line, if available. nvm use [&lt;version&gt;] Modify PATH to use &lt;version&gt;. Uses .nvmrc if available and version is omitted. The following optional arguments, if provided, must appear directly after `nvm use`: --silent Silences stdout\/stderr output --lts Uses automatic LTS (long-term support) alias `lts\/*`, if available. --lts=&lt;LTS name&gt; Uses automatic alias for provided LTS line, if available. nvm exec [&lt;version&gt;] [&lt;command&gt;] Run &lt;command&gt; on &lt;version&gt;. Uses .nvmrc if available and version is omitted. The following optional arguments, if provided, must appear directly after `nvm exec`: --silent Silences stdout\/stderr output --lts Uses automatic LTS (long-term support) alias `lts\/*`, if available. --lts=&lt;LTS name&gt; Uses automatic alias for provided LTS line, if available. nvm run [&lt;version&gt;] [&lt;args&gt;] Run `node` on &lt;version&gt; with &lt;args&gt; as arguments. Uses .nvmrc if available and version is omitted. The following optional arguments, if provided, must appear directly after `nvm run`: --silent Silences stdout\/stderr output --lts Uses automatic LTS (long-term support) alias `lts\/*`, if available. --lts=&lt;LTS name&gt; Uses automatic alias for provided LTS line, if available. nvm current Display currently activated version of Node nvm ls [&lt;version&gt;] List installed versions, matching a given &lt;version&gt; if provided --no-colors Suppress colored output --no-alias Suppress `nvm alias` output nvm ls-remote [&lt;version&gt;] List remote versions available for install, matching a given &lt;version&gt; if provided --lts When listing, only show LTS (long-term support) versions --lts=&lt;LTS name&gt; When listing, only show versions for a specific LTS line --no-colors Suppress colored output nvm version &lt;version&gt; Resolve the given description to a single local version nvm version-remote &lt;version&gt; Resolve the given description to a single remote version --lts When listing, only select from LTS (long-term support) versions --lts=&lt;LTS name&gt; When listing, only select from versions for a specific LTS line nvm deactivate Undo effects of `nvm` on current shell --silent Silences stdout\/stderr output nvm alias [&lt;pattern&gt;] Show all aliases beginning with &lt;pattern&gt; --no-colors Suppress colored output nvm alias &lt;name&gt; &lt;version&gt; Set an alias named &lt;name&gt; pointing to &lt;version&gt; nvm unalias &lt;name&gt; Deletes the alias named &lt;name&gt; nvm install-latest-npm Attempt to upgrade to the latest working `npm` on the current node version nvm reinstall-packages &lt;version&gt; Reinstall global `npm` packages contained in &lt;version&gt; to current version nvm unload Unload `nvm` from shell nvm which [current | &lt;version&gt;] Display path to installed node version. Uses .nvmrc if available and version is omitted. --silent Silences stdout\/stderr output when a version is omitted nvm cache dir Display path to the cache directory for nvm nvm cache clear Empty cache directory for nvm nvm set-colors [&lt;color codes&gt;] Set five text colors using format &quot;yMeBg&quot;. Available when supported. Initial colors are: bygre Color codes: r\/R = red \/ bold red g\/G = green \/ bold green b\/B = blue \/ bold blue c\/C = cyan \/ bold cyan m\/M = magenta \/ bold magenta y\/Y = yellow \/ bold yellow k\/K = black \/ bold black e\/W = light grey \/ white Example: nvm install 8.0.0 Install a specific version number nvm use 8.0 Use the latest available 8.0.x release nvm run 6.10.3 app.js Run app.js using node 6.10.3 nvm exec 4.8.3 node app.js Run `node app.js` with the PATH pointing to node 4.8.3 nvm alias default 8.1.0 Set default node version on a shell nvm alias default node Always default to the latest available node version on a shell nvm install node Install the latest available version nvm use node Use the latest version nvm install --lts Install the latest LTS version nvm use --lts Use the latest LTS version nvm set-colors cgYmW Set text colors to cyan, green, bold yellow, magenta, and white Note: to remove, delete, or uninstall nvm - just remove the `$NVM_DIR` folder (usually `~\/.nvm`) ##( 06\/06\/24@ 5:04PM )( donbuddenbaum@donbs-imac ):~ nvm install node Downloading and installing node v22.2.0... Downloading https:\/\/nodejs.org\/dist\/v22.2.0\/node-v22.2.0-darwin-x64.tar.xz... ######################################################################### 100.0% Computing checksum with shasum -a 256 Checksums matched! Now using node v22.2.0 (npm v10.7.0) Creating default alias: default -&gt; node (-&gt; v22.2.0)","tags":"","url":"documentation\/nodejs\/node.html"},{"title":"resume","text":"Table of Contents Resume Build #( 04\/30\/24@ 8:18PM )( donbuddenbaum@donbs-imac ):~\/Documents\/Kalaxy2@main\u2717\u2717\u2717 #Resume #Build ##( 04\/30\/24@ 8:18PM )( donbuddenbaum@donbs-imac ):~\/Documents\/Kalaxy2@main\u2717\u2717\u2717 docker buildx create \u2013use docker buildx build \u2013platform linux\/amd64,linux\/arm64 -f yaml\/nginx-docs\/k8s-resume-to-nginx\/nginx\/Dockerfile -t donb4iu\/mynginx_resume \u2013push . recursing_wescoff [+] Building 28.9s (13\/13) FINISHED docker-container:recursing_wescoff =&gt; [internal] booting buildkit 2.5s =&gt; =&gt; pulling image moby\/buildkit:buildx-stable-1 1.7s =&gt; =&gt; creating container buildx_buildkit_recursing_wescoff0 0.8s =&gt; [internal] load build definition from Dockerfile 0.1s =&gt; =&gt; transferring dockerfile: 323B 0.0s =&gt; [linux\/arm64 internal] load metadata for docker.io\/library\/nginx:latest 1.8s =&gt; [linux\/amd64 internal] load metadata for docker.io\/library\/nginx:latest 1.8s =&gt; [auth] library\/nginx:pull token for registry-1.docker.io 0.0s =&gt; [internal] load .dockerignore 0.0s =&gt; =&gt; transferring context: 2B 0.0s =&gt; [internal] load build context 0.3s =&gt; =&gt; transferring context: 106.56kB 0.1s =&gt; [linux\/arm64 1\/2] FROM docker.io\/library\/nginx:latest@sha256:ed6d2c43c8fbcd3eaa44c9dab6d94cb346234476230dc1681227aa72d07181ee 18.8s =&gt; =&gt; resolve docker.io\/library\/nginx:latest@sha256:ed6d2c43c8fbcd3eaa44c9dab6d94cb346234476230dc1681227aa72d07181ee 0.2s =&gt; =&gt; sha256:68b681650ba331f6f2aaa2d02b22553d1617ef337ea7b3d8d813cba3c30e6478 1.40kB \/ 1.40kB 0.3s =&gt; =&gt; sha256:b3678f371bddfc5d9c0778c5b91b023d322156a9c1aa0a33e338383f9496f0eb 396B \/ 396B 0.3s =&gt; =&gt; sha256:b4b06232e7eb4c182d44f3097b5663321c39f38de320e31aac410f44c5f1e3ca 1.21kB \/ 1.21kB 0.2s =&gt; =&gt; sha256:6a5cdb238fe4270ae006016ecf23e6786648a54b46bf7b8df1ba05dd0c9e12ee 959B \/ 959B 0.2s =&gt; =&gt; sha256:986afc5da1579073a4dfd06291753c109d6560b0da47fa06a7a3aef2144a0d83 629B \/ 629B 0.2s =&gt; =&gt; sha256:21f638c63a61c6f4eee13edc329c79aa304474af8825ca01c9133c36e6bdafe8 38.46MB \/ 38.46MB 7.2s =&gt; =&gt; sha256:22d97f6a5d13532e867231d23d92620a81874d51a456196be50154eeb32edc08 29.18MB \/ 29.18MB 12.1s =&gt; =&gt; extracting sha256:22d97f6a5d13532e867231d23d92620a81874d51a456196be50154eeb32edc08 3.2s =&gt; =&gt; extracting sha256:21f638c63a61c6f4eee13edc329c79aa304474af8825ca01c9133c36e6bdafe8 1.8s =&gt; =&gt; extracting sha256:986afc5da1579073a4dfd06291753c109d6560b0da47fa06a7a3aef2144a0d83 0.0s =&gt; =&gt; extracting sha256:6a5cdb238fe4270ae006016ecf23e6786648a54b46bf7b8df1ba05dd0c9e12ee 0.0s =&gt; =&gt; extracting sha256:b3678f371bddfc5d9c0778c5b91b023d322156a9c1aa0a33e338383f9496f0eb 0.0s =&gt; =&gt; extracting sha256:b4b06232e7eb4c182d44f3097b5663321c39f38de320e31aac410f44c5f1e3ca 0.0s =&gt; =&gt; extracting sha256:68b681650ba331f6f2aaa2d02b22553d1617ef337ea7b3d8d813cba3c30e6478 0.0s =&gt; [linux\/amd64 1\/2] FROM docker.io\/library\/nginx:latest@sha256:ed6d2c43c8fbcd3eaa44c9dab6d94cb346234476230dc1681227aa72d07181ee 17.5s =&gt; =&gt; resolve docker.io\/library\/nginx:latest@sha256:ed6d2c43c8fbcd3eaa44c9dab6d94cb346234476230dc1681227aa72d07181ee 0.1s =&gt; =&gt; sha256:93295add984dbd114a6f43401f08e6faf4510809e33e8f8a2e6485399fa0e03c 1.21kB \/ 1.21kB 0.2s =&gt; =&gt; sha256:ebde0aa1d1aaad9d43da96b7f0e4a4ebccde16cc4d785944629f02406cd54b44 1.40kB \/ 1.40kB 0.2s =&gt; =&gt; sha256:7102627a7a6e4da3b80e192b686d57139b8c6d4ff405918dd508e784a4abc639 393B \/ 393B 0.2s =&gt; =&gt; sha256:988b92d96970464ab9435aa6af3077e283c1c8eacaee200f8c123315486066ec 954B \/ 954B 0.2s =&gt; =&gt; sha256:5252b206aac298fb004dbe62210d127533f8aeb6a5eb0b8f79e28ddc01bd2419 629B \/ 629B 0.1s =&gt; =&gt; sha256:8ddb1e6cdf341aca028fb6fc4cbd9c2ba9e9a1cae1b186a587f2dffe33c0d587 41.82MB \/ 41.82MB 13.2s =&gt; =&gt; sha256:b0a0cf830b12453b7e15359a804215a7bcccd3788e2bcecff2a03af64bbd4df7 29.15MB \/ 29.15MB 10.8s =&gt; =&gt; extracting sha256:b0a0cf830b12453b7e15359a804215a7bcccd3788e2bcecff2a03af64bbd4df7 3.7s =&gt; =&gt; extracting sha256:8ddb1e6cdf341aca028fb6fc4cbd9c2ba9e9a1cae1b186a587f2dffe33c0d587 2.2s =&gt; =&gt; extracting sha256:5252b206aac298fb004dbe62210d127533f8aeb6a5eb0b8f79e28ddc01bd2419 0.0s =&gt; =&gt; extracting sha256:988b92d96970464ab9435aa6af3077e283c1c8eacaee200f8c123315486066ec 0.0s =&gt; =&gt; extracting sha256:7102627a7a6e4da3b80e192b686d57139b8c6d4ff405918dd508e784a4abc639 0.0s =&gt; =&gt; extracting sha256:93295add984dbd114a6f43401f08e6faf4510809e33e8f8a2e6485399fa0e03c 0.0s =&gt; =&gt; extracting sha256:ebde0aa1d1aaad9d43da96b7f0e4a4ebccde16cc4d785944629f02406cd54b44 0.0s =&gt; [linux\/amd64 2\/2] COPY \/resume \/usr\/share\/nginx\/html 0.4s =&gt; [linux\/arm64 2\/2] COPY \/resume \/usr\/share\/nginx\/html 0.2s =&gt; exporting to image 4.2s =&gt; =&gt; exporting layers 0.1s =&gt; =&gt; exporting manifest sha256:70fa60260336a9f33c9e25d98d0fa40aa9a30b44a6d921568ec5a69ac74e65f8 0.0s =&gt; =&gt; exporting config sha256:d98db752eb22451a1a2a6bef242452b6db2a5e9b2c47d501f7af129cbeaf9d47 0.0s =&gt; =&gt; exporting attestation manifest sha256:9d9b596c7a1001746b3410bb688d40cdce718504fe9be6a779b9162cea9856a3 0.0s =&gt; =&gt; exporting manifest sha256:3da92eb88f1316129e30019e51d234848f7169e062a9d7408a35e29f81c3c0d4 0.0s =&gt; =&gt; exporting config sha256:2286ed219022e0f2d4fcf5e04f019c2208ae917120b33b44ec15e525c7d12d06 0.0s =&gt; =&gt; exporting attestation manifest sha256:a2f3dc58b0c33c3674161618c11a8a02ee589adc70917ccc5c84629d4bff8d1d 0.0s =&gt; =&gt; exporting manifest list sha256:a637ccd80b585a718b0fd864e905aaa5ccbe558783f9f0c207bf033211c90d30 0.0s =&gt; =&gt; pushing layers 2.4s =&gt; =&gt; pushing manifest for docker.io\/donb4iu\/mynginx_resume:latest@sha256:a637ccd80b585a718b0fd864e905aaa5ccbe558783f9f0c207bf033211c90d30 1.5s =&gt; [auth] donb4iu\/mynginx_resume:pull,push token for registry-1.docker.io 0.0s Build multi-platform images faster with Docker Build Cloud: https:\/\/docs.docker.com\/go\/docker-build-cloud #","tags":"","url":"documentation\/resume.html"},{"title":"backup","text":"Table of Contents Backup #Backup Backup a cluster with Velero Files upload from Kubeless on MicroK8s to Minio minio Cloud Native Deployment of Minio using Kubernetes","tags":"","url":"file_system\/backup.html"},{"title":"ceph","text":"Table of Contents CEPH Setup storage devices - New dbuddenbaum@arm64-worker-04:~$** dbuddenbaum@arm64-worker-04:~$ Setup for rPi4 Old If the FSTYPE field is not empty, there is a filesystem on top of the corresponding device. In this case, you can use sda for Ceph partitions. dbuddenbaum@amd64-06:~$** sudo vi \/etc\/fstab disk clean up Rook\/Ceph Rook Tools CRD Deletion gets stuck Remove storage Host-based cluster To stop the Rook Operator, run Start the Rook operator run: Purge the OSD from the Ceph cluster Remove the OSD Replace an OSD Block Storage Deploy MongoDB Community Edition on CEPH block storage #CEPH #Setup storage devices - New #dbuddenbaum@arm64-worker-04:~$** sudo fdisk \/dev\/sda Welcome to fdisk (util-linux 2.34). Changes will remain in memory only, until you decide to write them. Be careful before using the write command. Command (m for help): p Disk \/dev\/sda: 931.53 GiB, 1000204886016 bytes, 1953525168 sectors Disk model: 002-1SD102 Units: sectors of 1 * 512 = 512 bytes Sector size (logical\/physical): 512 bytes \/ 4096 bytes I\/O size (minimum\/optimal): 4096 bytes \/ 4096 bytes Disklabel type: gpt Disk identifier: 4565B06D-9C14-48AC-ADCF-EDF03DD62518 Command (m for help): n Partition number (1-128, default 1): First sector (34-1953525134, default 2048): Last sector, +\/-sectors or +\/-size{K,M,G,T,P} (2048-1953525134, default 1953525134): +32G Created a new partition 1 of type 'Linux filesystem' and of size 32 GiB. Partition #1 contains a signature. Do you want to remove the signature? [Y]es\/[N]o: y The signature will be removed by a write command. Command (m for help): n Partition number (2-128, default 2): First sector (67110912-1953525134, default 67110912): Last sector, +\/-sectors or +\/-size{K,M,G,T,P} (67110912-1953525134, default 1953525134): +68G Created a new partition 2 of type 'Linux filesystem' and of size 68 GiB. Command (m for help): n Partition number (3-128, default 3): First sector (209717248-1953525134, default 209717248): Last sector, +\/-sectors or +\/-size{K,M,G,T,P} (209717248-1953525134, default 1953525134): Created a new partition 3 of type 'Linux filesystem' and of size 831.5 GiB. Command (m for help): w The partition table has been altered. Calling ioctl() to re-read partition table. Syncing disks. #dbuddenbaum@arm64-worker-04:~$ lsblk -f NAME FSTYPE LABEL UUID FSAVAIL FSUSE% MOUNTPOINT loop0 squashfs 0 100% \/snap\/core18\/1990 loop1 squashfs 0 100% \/snap\/core18\/2002 loop2 squashfs 0 100% \/snap\/snapd\/11408 loop3 squashfs 0 100% \/snap\/snapd\/11584 loop5 squashfs 0 100% \/snap\/lxd\/19648 loop6 squashfs 0 100% \/snap\/lxd\/20330 sda \u251c\u2500sda1 \u251c\u2500sda2 \u2514\u2500sda3 mmcblk0 \u251c\u2500mmcblk0p1 vfat system-boot B726-57E2 132.8M 47% \/boot\/firmware \u2514\u2500mmcblk0p2 ext4 writable 483efb12-d682-4daf-9b34-6e2f774b56f7 6.1G 75% \/ #Setup for rPi4 ###dbuddenbaum@arm64-worker-04:~$ sudo mkfs.xfs \/dev\/sda1 -f meta-data=\/dev\/sda1 isize=512 agcount=4, agsize=2097152 blks = sectsz=4096 attr=2, projid32bit=1 = crc=1 finobt=1, sparse=1, rmapbt=0 = reflink=1 data = bsize=4096 blocks=8388608, imaxpct=25 = sunit=0 swidth=0 blks naming =version 2 bsize=4096 ascii-ci=0, ftype=1 log =internal log bsize=4096 blocks=4096, version=2 = sectsz=4096 sunit=1 blks, lazy-count=1 realtime =none extsz=4096 blocks=0, rtextents=0 ###dbuddenbaum@arm64-worker-04:~$ sudo mkfs.ext4 \/dev\/sda2 mke2fs 1.45.5 (07-Jan-2020) Creating filesystem with 17825792 4k blocks and 4456448 inodes Filesystem UUID: 78ab6377-d48b-4e4e-bd45-765505f600dd Superblock backups stored on blocks: 32768, 98304, 163840, 229376, 294912, 819200, 884736, 1605632, 2654208, 4096000, 7962624, 11239424 Allocating group tables: done Writing inode tables: done Creating journal (131072 blocks): done Writing superblocks and filesystem accounting information: done ###dbuddenbaum@arm64-worker-04:~$** sudo mkdir \/mnt\/ssd ###dbuddenbaum@arm64-worker-04:~$** sudo mount \/dev\/sdb1 \/mnt\/ssd ###dbuddenbaum@arm64-worker-04:~$** sudo mkdir \/mnt\/var ###dbuddenbaum@arm64-worker-04:~$** sudo mount \/dev\/sda2 \/mnt\/var ###buddenbaum@arm64-worker-04:~$** sudo vi \/etc\/fstab UUID=7aa06485-7262-4bfb-beb2-db61fe70b3bf \/mnt\/ssd xfs defaults 0 0 UUID=78ab6377-d48b-4e4e-bd45-765505f600dd \/var ext4 defaults 0 2 ###dbuddenbaum@arm64-worker-04:~$** sudo rsync -aqxP \/var\/* \/mnt\/var ###dbuddenbaum@arm64-worker-04:~$** sudo umount \/mnt\/var sudo shutdown -r #Old sudo parted -l ###dbuddenbaum@arm64-worker-02:~$** sudo parted \/dev\/sda GNU Parted 3.3 Using \/dev\/sda Welcome to GNU Parted! Type 'help' to view a list of commands. (parted) mklabel gpt Warning: The existing disk label on \/dev\/sda will be destroyed and all data on this disk will be lost. Do you want to continue? Yes\/No? yes (parted) print Model: APPLE HD D ST1000DM003 (scsi) Disk \/dev\/sda: 1000GB Sector size (logical\/physical): 512B\/4096B Partition Table: gpt Disk Flags: Number Start End Size File system Name Flags (parted) mkpart primary ext4 1MB 31.9GB (parted) print Model: APPLE HD D ST1000DM003 (scsi) Disk \/dev\/sda: 1000GB Sector size (logical\/physical): 512B\/4096B Partition Table: gpt Disk Flags: Number Start End Size File system Name Flags 1 1049kB 31.9GB 31.9GB ext4 primary (parted) quit Information: You may need to update \/etc\/fstab. ###dbuddenbaum@arm64-worker-02:~$** sudo fdisk \/dev\/sda Welcome to fdisk (util-linux 2.34). Changes will remain in memory only, until you decide to write them. Be careful before using the write command. Command (m for help): n Partition number (2-128, default 2): First sector (62304256-1953525134, default 62304256): Last sector, +\/-sectors or +\/-size{K,M,G,T,P} (62304256-1953525134, default 1953525134): Created a new partition 2 of type 'Linux filesystem' and of size 901.8 GiB. Command (m for help): w The partition table has been altered. Calling ioctl() to re-read partition table. Syncing disks. #If the FSTYPE field is not empty, there is a filesystem on top of the corresponding device. In this case, you can use sda for Ceph partitions. ###dbuddenbaum@arm64-worker-02:\/var\/lib$** lsblk -f NAME FSTYPE LABEL UUID FSAVAIL FSUSE% MOUNTPOINT loop0 squashfs 0 100% \/snap\/core18\/1990 loop1 squashfs 0 100% \/snap\/core18\/2002 loop2 squashfs 0 100% \/snap\/lxd\/19206 loop3 squashfs 0 100% \/snap\/lxd\/19648 loop4 squashfs 0 100% \/snap\/snapd\/11584 loop5 squashfs 0 100% \/snap\/snapd\/11408 sda mmcblk0 \u251c\u2500mmcblk0p1 vfat system-boot B726-57E2 132.8M 47% \/boot\/firmware \u2514\u2500mmcblk0p2 ext4 writable 483efb12-d682-4daf-9b34-6e2f774b56f7 10G 61% \/ ##Preparing the external SSD - Attach the SSD drive to the Raspberry Pi with USB. The SSD will probably show up as \u2018\/dev\/sda\u2019. sudo mkfs.xfs \/dev\/sdb1 -f ( this will erase all contents of the SSD ). sudo mkdir \/mnt\/ssd sudo mount \/dev\/sdb1 \/mnt\/ssd #dbuddenbaum@amd64-06:~$** sudo vi \/etc\/fstab # \/etc\/fstab: static file system information. # # Use 'blkid' to print the universally unique identifier for a # device; this may be used with UUID= as a more robust way to name devices # that works even if disks are added and removed. See fstab(5). # # &lt;file system&gt; &lt;mount point&gt; &lt;type&gt; &lt;options&gt; &lt;dump&gt; &lt;pass&gt; # \/ was on \/dev\/sda5 during installation UUID=d736fb02-8e7a-42ce-948b-2321a0691b0c \/ ext4 errors=remount-ro 0 1 # \/boot\/efi was on \/dev\/sda1 during installation UUID=EA10-B595 \/boot\/efi vfat umask=0077 0 1 \/dev\/sdb1 \/mnt\/ssd xfs defaults 0 0 ##\/swapfile none swap sw 0 0 #disk clean up ###dbuddenbaum@arm64-worker-02:~$** DISK=\u201c\/dev\/sda\u201c ###dbuddenbaum@arm64-worker-02:~$** sudo sgdisk \u2013zap-all $DISK GPT data structures destroyed! You may now partition the disk using fdisk or other utilities. ###dbuddenbaum@arm64-worker-02:\/var\/lib$** sudo dd if=\/dev\/zero of=\u201c$DISK\u201c bs=1M count=100 oflag=direct,dsync 100+0 records in 100+0 records out 104857600 bytes (105 MB, 100 MiB) copied, 6.19267 s, 16.9 MB\/s dbuddenbaum@arm64-worker-02:\/var\/lib$ rm -rf \/dev\/ceph-* dbuddenbaum@arm64-worker-02:\/var\/lib$ rm -rf \/dev\/mapper\/ceph\u2013* #Rook\/Ceph How to deploy ROOK with CEPH in Kubernetes The Ultimate Rook and Ceph Survival Guide Build Ceph and Kubernetes Based Distributed File Storage System Quick Start Rook Documentation cluster.yaml v1.6 Example https:\/\/github.com\/rook\/rook\/branches https:\/\/github.com\/rook\/rook\/tree\/release-1.6 #( 04\/23\/21@ 1:28PM )( dbuddenbaum@dbuddenbaum-mbp ):~\/Documents\/rPi4\/kalaxy\/yaml\/rook-ceph@master\u2717\u2717\u2717 kubectl create -f crds.yaml customresourcedefinition.apiextensions.k8s.io\/cephblockpools.ceph.rook.io created customresourcedefinition.apiextensions.k8s.io\/cephclients.ceph.rook.io created customresourcedefinition.apiextensions.k8s.io\/cephclusters.ceph.rook.io created customresourcedefinition.apiextensions.k8s.io\/cephfilesystemmirrors.ceph.rook.io created customresourcedefinition.apiextensions.k8s.io\/cephfilesystems.ceph.rook.io created customresourcedefinition.apiextensions.k8s.io\/cephnfses.ceph.rook.io created customresourcedefinition.apiextensions.k8s.io\/cephobjectrealms.ceph.rook.io created customresourcedefinition.apiextensions.k8s.io\/cephobjectstores.ceph.rook.io created customresourcedefinition.apiextensions.k8s.io\/cephobjectstoreusers.ceph.rook.io created customresourcedefinition.apiextensions.k8s.io\/cephobjectzonegroups.ceph.rook.io created customresourcedefinition.apiextensions.k8s.io\/cephobjectzones.ceph.rook.io created customresourcedefinition.apiextensions.k8s.io\/cephrbdmirrors.ceph.rook.io created customresourcedefinition.apiextensions.k8s.io\/objectbucketclaims.objectbucket.io created customresourcedefinition.apiextensions.k8s.io\/objectbuckets.objectbucket.io created customresourcedefinition.apiextensions.k8s.io\/volumereplicationclasses.replication.storage.openshift.io created customresourcedefinition.apiextensions.k8s.io\/volumereplications.replication.storage.openshift.io created customresourcedefinition.apiextensions.k8s.io\/volumes.rook.io created #( 04\/23\/21@12:51PM )( dbuddenbaum@dbuddenbaum-mbp ):~\/Documents\/rPi4\/kalaxy\/yaml\/rook-ceph@master\u2717\u2717\u2717 kubectl create -f common.yaml namespace\/rook-ceph created clusterrolebinding.rbac.authorization.k8s.io\/rook-ceph-object-bucket created serviceaccount\/rook-ceph-admission-controller created clusterrole.rbac.authorization.k8s.io\/rook-ceph-admission-controller-role created clusterrolebinding.rbac.authorization.k8s.io\/rook-ceph-admission-controller-rolebinding created clusterrole.rbac.authorization.k8s.io\/rook-ceph-cluster-mgmt created role.rbac.authorization.k8s.io\/rook-ceph-system created clusterrole.rbac.authorization.k8s.io\/rook-ceph-global created clusterrole.rbac.authorization.k8s.io\/rook-ceph-mgr-cluster created clusterrole.rbac.authorization.k8s.io\/rook-ceph-object-bucket created serviceaccount\/rook-ceph-system created rolebinding.rbac.authorization.k8s.io\/rook-ceph-system created clusterrolebinding.rbac.authorization.k8s.io\/rook-ceph-global created serviceaccount\/rook-ceph-osd created serviceaccount\/rook-ceph-mgr created serviceaccount\/rook-ceph-cmd-reporter created role.rbac.authorization.k8s.io\/rook-ceph-osd created clusterrole.rbac.authorization.k8s.io\/rook-ceph-osd created clusterrole.rbac.authorization.k8s.io\/rook-ceph-mgr-system created role.rbac.authorization.k8s.io\/rook-ceph-mgr created role.rbac.authorization.k8s.io\/rook-ceph-cmd-reporter created rolebinding.rbac.authorization.k8s.io\/rook-ceph-cluster-mgmt created rolebinding.rbac.authorization.k8s.io\/rook-ceph-osd created rolebinding.rbac.authorization.k8s.io\/rook-ceph-mgr created rolebinding.rbac.authorization.k8s.io\/rook-ceph-mgr-system created clusterrolebinding.rbac.authorization.k8s.io\/rook-ceph-mgr-cluster created clusterrolebinding.rbac.authorization.k8s.io\/rook-ceph-osd created rolebinding.rbac.authorization.k8s.io\/rook-ceph-cmd-reporter created podsecuritypolicy.policy\/00-rook-privileged created clusterrole.rbac.authorization.k8s.io\/psp:rook created clusterrolebinding.rbac.authorization.k8s.io\/rook-ceph-system-psp created rolebinding.rbac.authorization.k8s.io\/rook-ceph-default-psp created rolebinding.rbac.authorization.k8s.io\/rook-ceph-osd-psp created rolebinding.rbac.authorization.k8s.io\/rook-ceph-mgr-psp created rolebinding.rbac.authorization.k8s.io\/rook-ceph-cmd-reporter-psp created serviceaccount\/rook-csi-cephfs-plugin-sa created serviceaccount\/rook-csi-cephfs-provisioner-sa created role.rbac.authorization.k8s.io\/cephfs-external-provisioner-cfg created rolebinding.rbac.authorization.k8s.io\/cephfs-csi-provisioner-role-cfg created clusterrole.rbac.authorization.k8s.io\/cephfs-csi-nodeplugin created clusterrole.rbac.authorization.k8s.io\/cephfs-external-provisioner-runner created clusterrolebinding.rbac.authorization.k8s.io\/rook-csi-cephfs-plugin-sa-psp created clusterrolebinding.rbac.authorization.k8s.io\/rook-csi-cephfs-provisioner-sa-psp created clusterrolebinding.rbac.authorization.k8s.io\/cephfs-csi-nodeplugin created clusterrolebinding.rbac.authorization.k8s.io\/cephfs-csi-provisioner-role created serviceaccount\/rook-csi-rbd-plugin-sa created serviceaccount\/rook-csi-rbd-provisioner-sa created role.rbac.authorization.k8s.io\/rbd-external-provisioner-cfg created rolebinding.rbac.authorization.k8s.io\/rbd-csi-provisioner-role-cfg created clusterrole.rbac.authorization.k8s.io\/rbd-csi-nodeplugin created clusterrole.rbac.authorization.k8s.io\/rbd-external-provisioner-runner created clusterrolebinding.rbac.authorization.k8s.io\/rook-csi-rbd-plugin-sa-psp created clusterrolebinding.rbac.authorization.k8s.io\/rook-csi-rbd-provisioner-sa-psp created clusterrolebinding.rbac.authorization.k8s.io\/rbd-csi-nodeplugin created clusterrolebinding.rbac.authorization.k8s.io\/rbd-csi-provisioner-role created #( 04\/23\/21@12:52PM )( dbuddenbaum@dbuddenbaum-mbp ):~\/Documents\/rPi4\/kalaxy\/yaml\/rook-ceph@master\u2717\u2717\u2717 kubectl create -f operator.yaml configmap\/rook-ceph-operator-config created deployment.apps\/rook-ceph-operator created #( 04\/27\/21@11:33AM )( dbuddenbaum@dbuddenbaum-mbp ):~\/Documents\/rPi4\/kalaxy\/yaml\/rook-ceph@master\u2717\u2717\u2717 kubectl -n rook-ceph get pod NAME READY STATUS RESTARTS AGE rook-ceph-operator-855f844cf4-hdltl 1\/1 Running 0 58s rook-discover-8vq5g 1\/1 Running 0 56s rook-discover-hlbj2 1\/1 Running 0 56s rook-discover-ktmgk 1\/1 Running 0 57s rook-discover-n28xn 1\/1 Running 0 57s rook-discover-nmtft 1\/1 Running 0 56s rook-discover-pczgp 1\/1 Running 0 56s rook-discover-ph5cc 1\/1 Running 0 56s rook-discover-vlz89 1\/1 Running 0 57s rook-discover-zdqzd 1\/1 Running 0 56s #( 04\/23\/21@ 1:31PM )( dbuddenbaum@dbuddenbaum-mbp ):~\/Documents\/rPi4\/kalaxy\/yaml\/rook-ceph@master\u2717\u2717\u2717 kubectl create -f cluster.yaml cephcluster.ceph.rook.io\/rook-ceph created #( 04\/23\/21@ 3:33PM )( dbuddenbaum@dbuddenbaum-mbp ):~\/Documents\/rPi4\/kalaxy\/yaml\/rook-ceph@master\u2717\u2717\u2717 kubectl create -f toolbox.yaml deployment.apps\/rook-ceph-tools created #Rook Tools [root@rook-ceph-tools-5b4b587f6b-f6kxc \/]# ceph status cluster: id: 4540e5a9-4563-4bc7-95da-1494b6a32132 health: HEALTH_WARN mons are allowing insecure global_id reclaim services: mon: 3 daemons, quorum a,b,c (age 3m) mgr: a(active, since 101s) osd: 8 osds: 8 up (since 2m), 8 in (since 2m) data: pools: 1 pools, 1 pgs objects: 3 objects, 0 B usage: 8.0 GiB used, 5.7 TiB \/ 5.7 TiB avail pgs: 1 active+clean [root@rook-ceph-tools-5b4b587f6b-f6kxc \/]# ceph health detail HEALTH_WARN mons are allowing insecure global_id reclaim; Reduced data availability: 1 pg inactive; OSD count 0 &lt; osd_pool_default_size 3 [WRN] AUTH_INSECURE_GLOBAL_ID_RECLAIM_ALLOWED: mons are allowing insecure global_id reclaim mon.a has auth_allow_insecure_global_id_reclaim set to true mon.b has auth_allow_insecure_global_id_reclaim set to true mon.c has auth_allow_insecure_global_id_reclaim set to true [WRN] PG_AVAILABILITY: Reduced data availability: 1 pg inactive pg 1.0 is stuck inactive for 100m, current state unknown, last acting [] [WRN] TOO_FEW_OSDS: OSD count 0 &lt; osd_pool_default_size 3 [root@rook-ceph-tools-5b4b587f6b-f6kxc \/]# ceph osd status ID HOST USED AVAIL WR OPS WR DATA RD OPS RD DATA STATE 0 arm64-worker-03 1027M 900G 0 0 0 0 exists,up 1 amd64-05 1027M 434G 0 0 0 0 exists,up 2 amd64-03 1027M 434G 0 0 0 0 exists,up 3 amd64-04 1027M 434G 0 0 0 0 exists,up 4 amd64-02 1027M 900G 0 0 0 0 exists,up 5 arm64-master-01 1027M 900G 0 0 0 0 exists,up 6 arm64-worker-02 1027M 900G 0 0 0 0 exists,up 7 arm64-worker-04 1027M 900G 0 0 0 0 exists,up [root@rook-ceph-tools-5b4b587f6b-f6kxc \/]# ceph osd pool ls detail pool 1 'device_health_metrics' replicated size 3 min_size 2 crush_rule 0 object_hash rjenkins pg_num 1 pgp_num 1 autoscale_mode on last_change 29 flags hashpspool stripe_width 0 pg_num_min 1 application mgr_devicehealth``` [root@rook-ceph-tools-5b4b587f6b-f6kxc \/]# rados df POOL_NAME USED OBJECTS CLONES COPIES MISSING_ON_PRIMARY UNFOUND DEGRADED RD_OPS RD WR_OPS WR USED COMPR UNDER COMPR device_health_metrics 0 B 3 0 9 0 0 0 0 0 B 3 58 KiB 0 B 0 B total_objects 3 total_used 8.0 GiB total_avail 5.7 TiB total_space 5.7 TiB ceph status ceph osd tree ceph osd status ceph osd df ceph osd utilization ##Dashboard #( 04\/23\/21@ 4:14PM )( dbuddenbaum@dbuddenbaum-mbp ):~\/Documents\/rPi4\/kalaxy\/yaml\/rook-ceph@master\u2717\u2717\u2717 kubectl create -f dashboard-loadbalancer.yaml service\/rook-ceph-mgr-dashboard-loadbalancer created #( 04\/23\/21@ 4:30PM )( dbuddenbaum@dbuddenbaum-mbp ):~\/Documents\/rPi4\/kalaxy\/yaml\/rook-ceph@master\u2717\u2717\u2717 kubectl -n rook-ceph get service NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE csi-cephfsplugin-metrics ClusterIP 10.100.195.171 &lt;none&gt; 8080\/TCP,8081\/TCP 170m csi-rbdplugin-metrics ClusterIP 10.108.25.77 &lt;none&gt; 8080\/TCP,8081\/TCP 170m rook-ceph-mgr ClusterIP 10.108.34.158 &lt;none&gt; 9283\/TCP 151m rook-ceph-mgr-dashboard ClusterIP 10.96.193.144 &lt;none&gt; 8443\/TCP 151m rook-ceph-mgr-dashboard-loadbalancer LoadBalancer 10.104.104.117 192.168.2.16 8443:30942\/TCP 12m rook-ceph-mon-a ClusterIP 10.96.20.22 &lt;none&gt; 6789\/TCP,3300\/TCP 153m rook-ceph-mon-b ClusterIP 10.107.3.18 &lt;none&gt; 6789\/TCP,3300\/TCP 151m rook-ceph-mon-c ClusterIP 10.107.168.135 &lt;none&gt; 6789\/TCP,3300\/TCP 151m rook-ceph-rgw-my-store ClusterIP 10.98.124.217 &lt;none&gt; 80\/TCP 19m Login Credentials After you connect to the dashboard you will need to login for secure access. Rook creates a default user named admin and generates a secret called rook-ceph-dashboard-admin-password in the namespace where the Rook Ceph cluster is running. To retrieve the generated password, you can run the following: #( 04\/23\/21@ 4:24PM )( dbuddenbaum@dbuddenbaum-mbp ):~\/Documents\/rPi4\/kalaxy\/yaml\/rook-ceph@master\u2717\u2717\u2717 kubectl -n rook-ceph get secret rook-ceph-dashboard-password -o jsonpath=\u201c{[\u2018data\u2019][\u2018password\u2019]}\u201c | base64 \u2013decode &amp;&amp; echo y.lkHZmMQbH7'VM-&gt;J$_ ceph dashboard #CRD Deletion gets stuck #( 04\/24\/21@ 6:09PM )( dbuddenbaum@dbuddenbaum-mbp ):~\/Documents\/rPi4\/kalaxy\/yaml\/rook-ceph@master\u2717\u2717\u2717 kubectl patch crd\/cephclusters.ceph.rook.io -p \u2018{\u201cmetadata\u201d:{\u201cfinalizers\u201d:[]}}\u2019 \u2013type=merge customresourcedefinition.apiextensions.k8s.io\/cephclusters.ceph.rook.io patched #( 04\/24\/21@ 6:15PM )( dbuddenbaum@dbuddenbaum-mbp ):~\/Documents\/rPi4\/kalaxy\/yaml\/rook-ceph@master\u2717\u2717\u2717 kubectl patch crd\/cephobjectstores.ceph.rook.io -p \u2018{\u201cmetadata\u201d:{\u201cfinalizers\u201d:[]}}\u2019 \u2013type=merge customresourcedefinition.apiextensions.k8s.io\/cephobjectstores.ceph.rook.io patched #( 04\/24\/21@ 6:16PM )( dbuddenbaum@dbuddenbaum-mbp ):~\/Documents\/rPi4\/kalaxy\/yaml\/rook-ceph@master\u2717\u2717\u2717 kubectl patch crd\/cephobjectstoreusers.ceph.rook.io -p \u2018{\u201cmetadata\u201d:{\u201cfinalizers\u201d:[]}}\u2019 \u2013type=merge customresourcedefinition.apiextensions.k8s.io\/cephobjectstoreusers.ceph.rook.io patched #Remove storage Host-based cluster Ceph OSD Management Update your CephCluster CR. Depending on your CR settings, you may need to remove the device from the list or update the device filter. If you are using useAllDevices: true, no change to the CR is necessary. IMPORTANT: On host-based clusters, you may need to stop the Rook Operator while performing OSD removal steps in order to prevent Rook from detecting the old OSD and trying to re-create it before the disk is wiped or removed. #To stop the Rook Operator, run kubectl -n rook-ceph scale deployment rook-ceph-operator --replicas=0 IMPORTANT: You must perform steps below to (1) purge the OSD and either (2.a) delete the underlying data (2.b)replace the disk before starting the Rook Operator again. #Start the Rook operator run: kubectl -n rook-ceph scale deployment rook-ceph-operator --replicas=1. #Purge the OSD from the Ceph cluster OSD removal can be automated with the example found in the [rook-ceph-purge-osd job](https:\/\/github.com\/rook\/rook\/blob\/{{ branchName }}\/cluster\/examples\/kubernetes\/ceph\/osd-purge.yaml). IMPORTANT: In the osd-purge.yaml, change the &lt;OSD-IDs&gt; to the ID(s) of the OSDs you want to remove. Run the job: kubectl create -f osd-purge.yaml When the job is completed, review the logs to ensure success: kubectl -n rook-ceph logs -l app=rook-ceph-purge-osd When finished, you can delete the job: kubectl delete -f osd-purge.yaml If you want to remove OSDs by hand, continue with the following sections. However, we recommend you to use the above-mentioned job to avoid operation errors. #Remove the OSD kubectl -n rook-ceph scale deployment rook-ceph-operator \u2013replicas=0 kubectl -n rook-ceph scale deployment rook-ceph-osd-&lt;ID&gt; \u2013replicas=0 kubectl create -f osd-purge.yaml kubectl -n rook-ceph logs -l app=rook-ceph-purge-osd kubectl delete -f osd-purge.yaml kubectl delete deployment -n rook-ceph rook-ceph-osd-&lt;ID&gt; kubectl -n rook-ceph scale deployment rook-ceph-operator \u2013replicas=1 #Replace an OSD To replace a disk that has failed: Run the steps in the previous section to Remove an OSD. Replace the physical device and verify the new device is attached. Check if your cluster CR will find the new device. If you are using useAllDevices: true you can skip this step. If your cluster CR lists individual devices or uses a device filter you may need to update the CR. The operator ideally will automatically create the new OSD within a few minutes of adding the new device or updating the CR. If you don\u2019t see a new OSD automatically created, restart the operator (by deleting the operator pod) to trigger the OSD creation. Verify if the OSD is created on the node by running ceph osd tree from the toolbox. Note that the OSD might have a different ID than the previous OSD that was replaced. #Block Storage Get block storage from Ceph #( 05\/02\/21@ 5:24PM )( dbuddenbaum@dbuddenbaum-mbp ):~\/Documents\/rPi4\/kalaxy\/yaml\/rook-ceph@master\u2717\u2717\u2717 kubectl apply -f .\/rbd\/storageclass.yaml cephblockpool.ceph.rook.io\/replicapool created storageclass.storage.k8s.io\/rook-ceph-block created #( 05\/02\/21@ 5:29PM )( dbuddenbaum@dbuddenbaum-mbp ):~\/Documents\/rPi4\/kalaxy\/yaml\/rook-ceph\/rbd@master\u2717\u2717\u2717 kubectl get pvc,pv NAME STATUS VOLUME CAPACITY ACCESS MODES STORAGECLASS AGE persistentvolumeclaim\/mongo-pvc Bound pvc-84409028-a00e-4936-bcf0-63ff36068893 5Gi RWO rook-ceph-block 32s NAME CAPACITY ACCESS MODES RECLAIM POLICY STATUS CLAIM STORAGECLASS REASON AGE persistentvolume\/pvc-6396501d-8a0b-46aa-a576-a6218908683e 8Gi RWO Delete Bound monitor\/prometheus-server nfs-ssd1 131d persistentvolume\/pvc-786f572c-e95c-4556-839a-5081bfe1a0af 2Gi RWO Delete Bound monitor\/prometheus-alertmanager nfs-ssd1 131d persistentvolume\/pvc-84409028-a00e-4936-bcf0-63ff36068893 5Gi RWO Delete Bound amd64default\/mongo-pvc rook-ceph-block 29s persistentvolume\/pvc-f5ddda65-eeef-41c3-b9c4-da2715b5ac33 1Gi RWO Delete Bound community-grid\/rosettaathomedata nfs-ssd1 48d #Deploy MongoDB Community Edition on CEPH block storage #( 05\/02\/21@ 5:54PM )( dbuddenbaum@dbuddenbaum-mbp ):~\/Documents\/rPi4\/kalaxy\/yaml\/rook-ceph\/rbd@master\u2717\u2717\u2717 kubectl apply -f mongo.yaml deployment.apps\/mongo created service\/mongo created #( 05\/02\/21@ 5:54PM )( dbuddenbaum@dbuddenbaum-mbp ):~\/Documents\/rPi4\/kalaxy\/yaml\/rook-ceph\/rbd@master\u2717\u2717\u2717 kubectl get pods,svc NAME READY STATUS RESTARTS AGE pod\/bear-67fd7744bf-f6t9f 1\/1 Running 1 4d23h pod\/hare-5446fcff89-jb5zx 1\/1 Running 0 4d23h pod\/mongo-5d7ff54f7d-qh67w 1\/1 Running 0 32s pod\/moose-57b7db48cb-mx7jc 1\/1 Running 1 4d23h NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE service\/bear ClusterIP 10.105.36.211 &lt;none&gt; 80\/TCP 20d service\/hare ClusterIP 10.101.99.44 &lt;none&gt; 80\/TCP 20d service\/mongo NodePort 10.100.234.50 &lt;none&gt; 27017:31017\/TCP 31s service\/moose ClusterIP 10.108.246.110 &lt;none&gt; 80\/TCP 20d #( 05\/02\/21@ 5:55PM )( dbuddenbaum@dbuddenbaum-mbp ):~\/Documents\/rPi4\/kalaxy\/yaml\/rook-ceph\/rbd@master\u2717\u2717\u2717 kubectl get pods -o wide NAME READY STATUS RESTARTS AGE IP NODE NOMINATED NODE READINESS GATES bear-67fd7744bf-f6t9f 1\/1 Running 1 4d23h 10.244.0.104 amd64-02 &lt;none&gt; &lt;none&gt; hare-5446fcff89-jb5zx 1\/1 Running 0 4d23h 10.244.0.99 amd64-02 &lt;none&gt; &lt;none&gt; mongo-5d7ff54f7d-qh67w 1\/1 Running 0 9m28s 10.244.12.121 amd64-06 &lt;none&gt; &lt;none&gt; moose-57b7db48cb-mx7jc 1\/1 Running 1 4d23h 10.244.0.96 amd64-02 &lt;none&gt; &lt;none&gt; #( 05\/02\/21@ 5:54PM )( dbuddenbaum@dbuddenbaum-mbp ):~\/Documents\/rPi4\/kalaxy\/yaml\/rook-ceph\/rbd@master\u2717\u2717\u2717 kubectl get nodes -o wide NAME STATUS ROLES AGE VERSION INTERNAL-IP EXTERNAL-IP OS-IMAGE KERNEL-VERSION CONTAINER-RUNTIME amd64-02 Ready master 188d v1.17.11 192.168.2.56 &lt;none&gt; Ubuntu 20.04.2 LTS 5.4.0-72-generic docker:\/\/19.3.12 amd64-03 Ready &lt;none&gt; 188d v1.17.11 192.168.2.57 &lt;none&gt; Ubuntu 20.04.2 LTS 5.4.0-72-generic docker:\/\/19.3.12 amd64-04 Ready &lt;none&gt; 180d v1.17.11 192.168.2.58 &lt;none&gt; Ubuntu 20.04.2 LTS 5.4.0-72-generic docker:\/\/19.3.12 amd64-05 Ready &lt;none&gt; 158d v1.17.11 192.168.2.59 &lt;none&gt; Ubuntu 20.04.2 LTS 5.4.0-72-generic docker:\/\/19.3.12 amd64-06 Ready &lt;none&gt; 50d v1.17.11 192.168.2.60 &lt;none&gt; Ubuntu 20.04.2 LTS 5.4.0-72-generic docker:\/\/19.3.12 arm64-master-01 Ready &lt;none&gt; 69d v1.17.11 192.168.2.50 &lt;none&gt; Ubuntu 20.04.2 LTS 5.4.0-1034-raspi docker:\/\/19.3.12 arm64-worker-02 Ready &lt;none&gt; 69d v1.17.11 192.168.2.52 &lt;none&gt; Ubuntu 20.04.2 LTS 5.4.0-1034-raspi docker:\/\/19.3.12 arm64-worker-03 Ready &lt;none&gt; 84d v1.17.11 192.168.2.53 &lt;none&gt; Ubuntu 20.04.2 LTS 5.4.0-1034-raspi docker:\/\/19.3.12 arm64-worker-04 Ready &lt;none&gt; 69d v1.17.11 192.168.2.54 &lt;none&gt; Ubuntu 20.04.2 LTS 5.4.0-1034-raspi docker:\/\/19.3.12 MongoDB Compass 192.168.2.60:31017","tags":"","url":"file_system\/ceph.html"},{"title":"crd","text":"kubectl patch crd\/settings.longhorn.io -p \u2018{\u201cmetadata\u201d:{\u201cfinalizers\u201d:[]}}\u2019 \u2013type=merge kubectl patch crd\/nodes.longhorn.io -p \u2018{\u201cmetadata\u201d:{\u201cfinalizers\u201d:[]}}\u2019 \u2013type=merge kubectl patch crd\/jobs.longhorn.io -p \u2018{\u201cmetadata\u201d:{\u201cfinalizers\u201d:[]}}\u2019 \u2013type=merge kubectl patch crd\/backingimages.longhorn.io -p \u2018{\u201cmetadata\u201d:{\u201cfinalizers\u201d:[]}}\u2019 \u2013type=merge kubectl patch crd\/engines.longhorn.io -p \u2018{\u201cmetadata\u201d:{\u201cfinalizers\u201d:[]}}\u2019 \u2013type=merge kubectl patch crd\/replicas.longhorn.io -p \u2018{\u201cmetadata\u201d:{\u201cfinalizers\u201d:[]}}\u2019 \u2013type=merge kubectl patch crd\/sharemanagers.longhorn.io -p \u2018{\u201cmetadata\u201d:{\u201cfinalizers\u201d:[]}}\u2019 \u2013type=merge kubectl patch crd\/volumes.longhorn.io -p \u2018{\u201cmetadata\u201d:{\u201cfinalizers\u201d:[]}}\u2019 \u2013type=merge kubectl patch crd\/backuptargets.longhorn.io -p \u2018{\u201cmetadata\u201d:{\u201cfinalizers\u201d:[]}}\u2019 \u2013type=merge kubectl patch crd\/engineimages.longhorn.io -p \u2018{\u201cmetadata\u201d:{\u201cfinalizers\u201d:[]}}\u2019 \u2013type=merge kubectl patch crd\/backups.longhorn.io -p \u2018{\u201cmetadata\u201d:{\u201cfinalizers\u201d:[]}}\u2019 \u2013type=merge kubectl patch crd\/backingimagedatasources.longhorn.io -p \u2018{\u201cmetadata\u201d:{\u201cfinalizers\u201d:[]}}\u2019 \u2013type=merge kubectl patch crd\/backupvolumes.longhorn.io -p \u2018{\u201cmetadata\u201d:{\u201cfinalizers\u201d:[]}}\u2019 \u2013type=merge kubectl patch crd\/instancemanagers.longhorn.io -p \u2018{\u201cmetadata\u201d:{\u201cfinalizers\u201d:[]}}\u2019 \u2013type=merge kubectl patch crd\/backingimagemanagers.longhorn.io -p \u2018{\u201cmetadata\u201d:{\u201cfinalizers\u201d:[]}}\u2019 \u2013type=merge kubectl delete crd\/settings.longhorn.io kubectl delete crd\/nodes.longhorn.io kubectl delete crd\/recurringjobs.longhorn.io kubectl delete crd\/backingimages.longhorn.io kubectl delete crd\/engines.longhorn.io kubectl delete crd\/replicas.longhorn.io kubectl delete crd\/sharemanagers.longhorn.io kubectl delete crd\/volumes.longhorn.io kubectl delete crd\/backuptargets.longhorn.io kubectl delete crd\/engineimages.longhorn.io kubectl delete crd\/backups.longhorn.io kubectl delete crd\/backingimagedatasources.longhorn.io kubectl delete crd\/backupvolumes.longhorn.io kubectl delete crd\/instancemanagers.longhorn.io kubectl delete crd\/backingimagemanagers.longhorn.io","tags":"","url":"file_system\/crd.html"},{"title":"longhorn","text":"Table of Contents Longhorn Validate Install Prerequisites Install Yaml Install Helm Uninstall #Longhorn https:\/\/longhorn.io\/docs\/ How to install Longhorn (distributed block storage system) for Kubernetes. (Kubernetes Series Part 2) How to Install Rancher Longhorn on Microk8s, Ubuntu 20.04 How to Make Rancher Longhorn Work with MicroK8S Using Longhorn Storage #Validate ###dbuddenbaum@arm64-01:~$ sudo microk8s kubectl config view \u2013raw &gt; $HOME\/.kube\/config ###dbuddenbaum@arm64-01:~$ sudo snap install kubectl \u2013classic kubectl 1.23.5 from Canonical\u2713 installed ###dbuddenbaum@arm64-01:~$ sudo apt install jq Reading package lists... Done Building dependency tree Reading state information... Done The following additional packages will be installed: libjq1 libonig5 The following NEW packages will be installed: jq libjq1 libonig5 0 upgraded, 3 newly installed, 0 to remove and 27 not upgraded. Need to get 291 kB of archives. After this operation, 1022 kB of additional disk space will be used. Do you want to continue? [Y\/n] y Get:1 http:\/\/ports.ubuntu.com\/ubuntu-ports focal\/universe arm64 libonig5 arm64 6.9.4-1 [134 kB] Get:2 http:\/\/ports.ubuntu.com\/ubuntu-ports focal-updates\/universe arm64 libjq1 arm64 1.6-1ubuntu0.20.04.1 [107 kB] Get:3 http:\/\/ports.ubuntu.com\/ubuntu-ports focal-updates\/universe arm64 jq arm64 1.6-1ubuntu0.20.04.1 [49.6 kB] Fetched 291 kB in 1s (369 kB\/s) Selecting previously unselected package libonig5:arm64. (Reading database ... 133088 files and directories currently installed.) Preparing to unpack ...\/libonig5_6.9.4-1_arm64.deb ... Unpacking libonig5:arm64 (6.9.4-1) ... Selecting previously unselected package libjq1:arm64. Preparing to unpack ...\/libjq1_1.6-1ubuntu0.20.04.1_arm64.deb ... Unpacking libjq1:arm64 (1.6-1ubuntu0.20.04.1) ... Selecting previously unselected package jq. Preparing to unpack ...\/jq_1.6-1ubuntu0.20.04.1_arm64.deb ... Unpacking jq (1.6-1ubuntu0.20.04.1) ... Setting up libonig5:arm64 (6.9.4-1) ... Setting up libjq1:arm64 (1.6-1ubuntu0.20.04.1) ... Setting up jq (1.6-1ubuntu0.20.04.1) ... Processing triggers for man-db (2.9.1-1) ... Processing triggers for libc-bin (2.31-0ubuntu9.7) ... Files have not changed, Decompression not needed ###dbuddenbaum@arm64-01:~$ curl -sSfL https:\/\/raw.githubusercontent.com\/longhorn\/longhorn\/v1.2.4\/scripts\/environment_check.sh | bash daemonset.apps\/longhorn-environment-check created waiting for pods to become ready (0\/0) waiting for pods to become ready (0\/6) all pods ready (6\/6) MountPropagation is enabled! cleaning up... daemonset.apps &quot;longhorn-environment-check&quot; deleted clean up complete #Install Prerequisites ###dbuddenbaum@arm64-01:~$ sudo apt install nfs-common open-iscsi -y Reading package lists... Done Building dependency tree Reading state information... Done nfs-common is already the newest version (1:1.3.4-2.5ubuntu3.4). open-iscsi is already the newest version (2.0.874-7.1ubuntu6.2). 0 upgraded, 0 newly installed, 0 to remove and 27 not upgraded. ###dbuddenbaum@arm64-01:~$ sudo rm -f \/lib\/systemd\/system\/nfs-common.service ###dbuddenbaum@arm64-01:~$ sudo systemctl daemon-reload ###dbuddenbaum@arm64-01:~$ sudo systemctl start nfs-common ###dbuddenbaum@arm64-01:~$ sudo systemctl enable nfs-common nfs-common.service is not a native service, redirecting to systemd-sysv-install. Executing: \/lib\/systemd\/systemd-sysv-install enable nfs-common ###dbuddenbaum@arm64-01:~$ sudo systemctl start open-iscsi ###dbuddenbaum@arm64-01:~$ sudo systemctl enable open-iscsi Synchronizing state of open-iscsi.service with SysV service script with \/lib\/systemd\/systemd-sysv-install. Executing: \/lib\/systemd\/systemd-sysv-install enable open-iscsi #Install Yaml #( 04\/10\/22@10:39PM )( dbuddenbaum@donb-mbp4 ):~\/Documents\/rpi4\/kalaxy@main\u2717\u2717\u2717 kubectl ns longhorn-system Context \u201cmicrok8s\u201d modified. Active namespace is \u201clonghorn-system\u201d. #( 04\/10\/22@10:39PM )( dbuddenbaum@donb-mbp4 ):~\/Documents\/rpi4\/kalaxy@main\u2717\u2717\u2717 kubectl -n longhorn-system apply -f https:\/\/raw.githubusercontent.com\/longhorn\/longhorn\/v1.2.4\/deploy\/prerequisite\/longhorn-iscsi-installation.yaml daemonset.apps\/longhorn-iscsi-installation created #( 04\/10\/22@10:40PM )( dbuddenbaum@donb-mbp4 ):~\/Documents\/rpi4\/kalaxy@main\u2717\u2717\u2717 kubectl -n longhorn-system apply -f https:\/\/raw.githubusercontent.com\/longhorn\/longhorn\/v1.2.4\/deploy\/prerequisite\/longhorn-nfs-installation.yaml daemonset.apps\/longhorn-nfs-installation created #( 04\/10\/22@10:42PM )( dbuddenbaum@donb-mbp4 ):~\/Documents\/rpi4\/kalaxy@main\u2717\u2717\u2717 kubectl apply -f https:\/\/raw.githubusercontent.com\/longhorn\/longhorn\/v1.2.4\/deploy\/longhorn.yaml Warning: resource namespaces\/longhorn-system is missing the kubectl.kubernetes.io\/last-applied-configuration annotation which is required by kubectl apply. kubectl apply should only be used on resources created declaratively by either kubectl create \u2013save-config or kubectl apply. The missing annotation will be patched automatically. namespace\/longhorn-system configured Warning: resource serviceaccounts\/longhorn-service-account is missing the kubectl.kubernetes.io\/last-applied-configuration annotation which is required by kubectl apply. kubectl apply should only be used on resources created declaratively by either kubectl create \u2013save-config or kubectl apply. The missing annotation will be patched automatically. serviceaccount\/longhorn-service-account configured Warning: resource clusterroles\/longhorn-role is missing the kubectl.kubernetes.io\/last-applied-configuration annotation which is required by kubectl apply. kubectl apply should only be used on resources created declaratively by either kubectl create \u2013save-config or kubectl apply. The missing annotation will be patched automatically. clusterrole.rbac.authorization.k8s.io\/longhorn-role configured Warning: resource clusterrolebindings\/longhorn-bind is missing the kubectl.kubernetes.io\/last-applied-configuration annotation which is required by kubectl apply. kubectl apply should only be used on resources created declaratively by either kubectl create \u2013save-config or kubectl apply. The missing annotation will be patched automatically. clusterrolebinding.rbac.authorization.k8s.io\/longhorn-bind configured customresourcedefinition.apiextensions.k8s.io\/engines.longhorn.io created customresourcedefinition.apiextensions.k8s.io\/replicas.longhorn.io created customresourcedefinition.apiextensions.k8s.io\/settings.longhorn.io created customresourcedefinition.apiextensions.k8s.io\/volumes.longhorn.io created customresourcedefinition.apiextensions.k8s.io\/engineimages.longhorn.io created customresourcedefinition.apiextensions.k8s.io\/nodes.longhorn.io created customresourcedefinition.apiextensions.k8s.io\/instancemanagers.longhorn.io created customresourcedefinition.apiextensions.k8s.io\/sharemanagers.longhorn.io created customresourcedefinition.apiextensions.k8s.io\/backingimages.longhorn.io created customresourcedefinition.apiextensions.k8s.io\/backingimagemanagers.longhorn.io created customresourcedefinition.apiextensions.k8s.io\/backingimagedatasources.longhorn.io created customresourcedefinition.apiextensions.k8s.io\/backuptargets.longhorn.io created customresourcedefinition.apiextensions.k8s.io\/backupvolumes.longhorn.io created customresourcedefinition.apiextensions.k8s.io\/backups.longhorn.io created customresourcedefinition.apiextensions.k8s.io\/recurringjobs.longhorn.io created Warning: resource configmaps\/longhorn-default-setting is missing the kubectl.kubernetes.io\/last-applied-configuration annotation which is required by kubectl apply. kubectl apply should only be used on resources created declaratively by either kubectl create \u2013save-config or kubectl apply. The missing annotation will be patched automatically. configmap\/longhorn-default-setting configured Warning: policy\/v1beta1 PodSecurityPolicy is deprecated in v1.21+, unavailable in v1.25+ Warning: resource podsecuritypolicies\/longhorn-psp is missing the kubectl.kubernetes.io\/last-applied-configuration annotation which is required by kubectl apply. kubectl apply should only be used on resources created declaratively by either kubectl create \u2013save-config or kubectl apply. The missing annotation will be patched automatically. podsecuritypolicy.policy\/longhorn-psp configured Warning: resource roles\/longhorn-psp-role is missing the kubectl.kubernetes.io\/last-applied-configuration annotation which is required by kubectl apply. kubectl apply should only be used on resources created declaratively by either kubectl create \u2013save-config or kubectl apply. The missing annotation will be patched automatically. role.rbac.authorization.k8s.io\/longhorn-psp-role configured Warning: resource rolebindings\/longhorn-psp-binding is missing the kubectl.kubernetes.io\/last-applied-configuration annotation which is required by kubectl apply. kubectl apply should only be used on resources created declaratively by either kubectl create \u2013save-config or kubectl apply. The missing annotation will be patched automatically. rolebinding.rbac.authorization.k8s.io\/longhorn-psp-binding configured Warning: resource configmaps\/longhorn-storageclass is missing the kubectl.kubernetes.io\/last-applied-configuration annotation which is required by kubectl apply. kubectl apply should only be used on resources created declaratively by either kubectl create \u2013save-config or kubectl apply. The missing annotation will be patched automatically. configmap\/longhorn-storageclass configured daemonset.apps\/longhorn-manager created Warning: resource services\/longhorn-backend is missing the kubectl.kubernetes.io\/last-applied-configuration annotation which is required by kubectl apply. kubectl apply should only be used on resources created declaratively by either kubectl create \u2013save-config or kubectl apply. The missing annotation will be patched automatically. service\/longhorn-backend configured Warning: resource services\/longhorn-engine-manager is missing the kubectl.kubernetes.io\/last-applied-configuration annotation which is required by kubectl apply. kubectl apply should only be used on resources created declaratively by either kubectl create \u2013save-config or kubectl apply. The missing annotation will be patched automatically. service\/longhorn-engine-manager configured Warning: resource services\/longhorn-replica-manager is missing the kubectl.kubernetes.io\/last-applied-configuration annotation which is required by kubectl apply. kubectl apply should only be used on resources created declaratively by either kubectl create \u2013save-config or kubectl apply. The missing annotation will be patched automatically. service\/longhorn-replica-manager configured deployment.apps\/longhorn-ui created Warning: resource services\/longhorn-frontend is missing the kubectl.kubernetes.io\/last-applied-configuration annotation which is required by kubectl apply. kubectl apply should only be used on resources created declaratively by either kubectl create \u2013save-config or kubectl apply. The missing annotation will be patched automatically. service\/longhorn-frontend configured deployment.apps\/longhorn-driver-deployer created # #Install Helm ###( 04\/02\/22@ 7:31PM )( dbuddenbaum@donb-mbp4 ):~\/Documents\/rpi4\/KubeScrape_PrometheusManifests@main\u2717\u2717\u2717** helm repo add longhorn https:\/\/charts.longhorn.io WARNING: Kubernetes configuration file is group-readable. This is insecure. Location: \/Users\/dbuddenbaum\/.kube\/config WARNING: Kubernetes configuration file is world-readable. This is insecure. Location: \/Users\/dbuddenbaum\/.kube\/config &quot;longhorn&quot; has been added to your repositories ###( 04\/02\/22@ 7:37PM )( dbuddenbaum@donb-mbp4 ):~\/Documents\/rpi4\/KubeScrape_PrometheusManifests@main\u2717\u2717\u2717** helm repo update WARNING: Kubernetes configuration file is group-readable. This is insecure. Location: \/Users\/dbuddenbaum\/.kube\/config WARNING: Kubernetes configuration file is world-readable. This is insecure. Location: \/Users\/dbuddenbaum\/.kube\/config Hang tight while we grab the latest from your chart repositories... ...Successfully got an update from the &quot;longhorn&quot; chart repository Update Complete. \u2388Happy Helming!\u2388 ###( 04\/02\/22@ 7:38PM )( dbuddenbaum@donb-mbp4 ):~\/Documents\/rpi4\/KubeScrape_PrometheusManifests@main\u2717\u2717\u2717** kubectl create namespace longhorn-system namespace\/longhorn-system created ###( 04\/02\/22@ 7:38PM )( dbuddenbaum@donb-mbp4 ):~\/Documents\/rpi4\/KubeScrape_PrometheusManifests@main\u2717\u2717\u2717** helm install longhorn longhorn\/longhorn \u2013namespace longhorn-system WARNING: Kubernetes configuration file is group-readable. This is insecure. Location: \/Users\/dbuddenbaum\/.kube\/config WARNING: Kubernetes configuration file is world-readable. This is insecure. Location: \/Users\/dbuddenbaum\/.kube\/config W0402 19:38:53.691241 2463 warnings.go:70] policy\/v1beta1 PodSecurityPolicy is deprecated in v1.21+, unavailable in v1.25+ W0402 19:38:54.421354 2463 warnings.go:70] policy\/v1beta1 PodSecurityPolicy is deprecated in v1.21+, unavailable in v1.25+ NAME: longhorn LAST DEPLOYED: Sat Apr 2 19:38:50 2022 NAMESPACE: longhorn-system STATUS: deployed REVISION: 1 TEST SUITE: None NOTES: Longhorn is now installed on the cluster! Please wait a few minutes for other Longhorn components such as CSI deployments, Engine Images, and Instance Managers to be initialized. Visit our documentation at https:\/\/longhorn.io\/docs\/ ###( 04\/02\/22@11:50PM )( dbuddenbaum@donb-mbp4 ):~\/Documents\/rpi4\/kalaxy\/yaml\/longhorn@main\u2717\u2717\u2717** kubectl -n longhorn-system apply -f https:\/\/raw.githubusercontent.com\/longhorn\/longhorn\/v1.2.4\/deploy\/prerequisite\/longhorn-iscsi-installation.yaml daemonset.apps\/longhorn-iscsi-installation created ###( 04\/03\/22@ 2:26PM )( dbuddenbaum@donb-mbp4 ):~\/Documents\/rpi4\/kalaxy\/yaml\/longhorn@main\u2717\u2717\u2717** kubectl -n longhorn-system apply -f https:\/\/raw.githubusercontent.com\/longhorn\/longhorn\/v1.2.4\/deploy\/prerequisite\/longhorn-nfs-installation.yaml #Uninstall ###( 04\/10\/22@ 7:41PM )( dbuddenbaum@donb-mbp4 ):~\/Documents\/rpi4\/kalaxy@main\u2717\u2717\u2717 kubectl delete customresourcedefinition nodes.longhorn.io ###( 04\/10\/22@ 7:54PM )( dbuddenbaum@donb-mbp4 ):~\/Documents\/rpi4\/kalaxy@main\u2717\u2717\u2717 kubectl patch crd\/nodes.longhorn.io -p \u2018{\u201cmetadata\u201d:{\u201cfinalizers\u201d:[]}}\u2019 \u2013type=merge customresourcedefinition.apiextensions.k8s.io\/nodes.longhorn.io patched ###( 04\/10\/22@ 7:54PM )( dbuddenbaum@donb-mbp4 ):~\/Documents\/rpi4\/kalaxy@main\u2717\u2717\u2717 kubectl patch crd\/engineimages.longhorn.io -p \u2018{\u201cmetadata\u201d:{\u201cfinalizers\u201d:[]}}\u2019 \u2013type=merge customresourcedefinition.apiextensions.k8s.io\/engineimages.longhorn.io patched helm uninstall longhorn \u2013namespace longhorn-system","tags":"","url":"file_system\/longhorn.html"},{"title":"minio","text":"Table of Contents Minio #Minio Minio deployment in Microk8s","tags":"","url":"file_system\/minio.html"},{"title":"nfs","text":"Table of Contents NFS MicroK8s NFS NFS Server ubuntu server mac osx client unbuntu 20.04 client persistent volume persistent volume persistent volume claim mount commands storage logs Service accounts and cluster roles #NFS Turn your Raspberry Pi homelab into a network filesystem How To Set Up an NFS Mount on Ubuntu 20.04 macOS X Mount NFS Share \/ Set an NFS Client Dynamic NFS Provisioning in Kubernetes How to install NFS Dynamic Provisioner for Kubernetes. (Kubernetes Series Part 3) Use NFS for Persistent Volumes #MicroK8s NFS #NFS Server sudo mkdir -p \/media\/dbuddenbaum\/nfs\/nfs-server sudo chown nobody:nogroup \/media\/dbuddenbaum\/nfs\/nfs-server sudo chmod 0777 \/media\/dbuddenbaum\/nfs\/nfs-server sudo systemctl restart nfs-server.service ###dbuddenbaum@arm64-01:~$ microk8s helm3 install csi-driver-nfs csi-driver-nfs\/csi-driver-nfs \\ --namespace kube-system \\ --set kubeletDir=\/var\/snap\/microk8s\/common\/var\/lib\/kubelet WARNING: Kubernetes configuration file is group-readable. This is insecure. Location: \/var\/snap\/microk8s\/3054\/credentials\/client.config NAME: csi-driver-nfs LAST DEPLOYED: Sun Apr 10 03:35:04 2022 NAMESPACE: kube-system STATUS: deployed REVISION: 1 TEST SUITE: None NOTES: The CSI NFS Driver is getting deployed to your cluster. To check CSI NFS Driver pods status, please run: kubectl --namespace=kube-system get pods --selector=&quot;release=csi-driver-nfs&quot; --watch ###dbuddenbaum@arm64-01:~$ microk8s kubectl wait pod \u2013selector app.kubernetes.io\/name=csi-driver-nfs \u2013for condition=ready \u2013namespace kube-system pod\/csi-nfs-node-57rgr condition met pod\/csi-nfs-node-qmbrg condition met pod\/csi-nfs-node-78k86 condition met pod\/csi-nfs-node-qmtbq condition met pod\/csi-nfs-controller-c6b7b4dd5-7grgf condition met pod\/csi-nfs-node-2fwsw condition met pod\/csi-nfs-node-bjwld condition met ###dbuddenbaum@arm64-01:~$ microk8s kubectl get csidrivers NAME ATTACHREQUIRED PODINFOONMOUNT STORAGECAPACITY TOKENREQUESTS REQUIRESREPUBLISH MODES AGE nfs.csi.k8s.io false false false &lt;unset&gt; false Persistent 2m36s dbuddenbaum@arm64-01:~$ sudo vim sc-nfs.yaml dbuddenbaum@arm64-01:~$ microk8s kubectl apply -f - &lt; sc-nfs.yaml storageclass.storage.k8s.io\/nfs-csi created dbuddenbaum@arm64-01:~$ sudo vim pvc-nfs.yaml dbuddenbaum@arm64-01:~$ microk8s kubectl apply -f - &lt; pvc-nfs.yaml persistentvolumeclaim\/my-pvc created ###dbuddenbaum@arm64-01:~$ microk8s kubectl describe pvc my-pvc Name: my-pvc Namespace: default StorageClass: nfs-csi Status: Pending Volume: Labels: &lt;none&gt; Annotations: volume.beta.kubernetes.io\/storage-provisioner: nfs.csi.k8s.io volume.kubernetes.io\/storage-provisioner: nfs.csi.k8s.io Finalizers: [kubernetes.io\/pvc-protection] Capacity: Access Modes: VolumeMode: Filesystem Used By: &lt;none&gt; Events: Type Reason Age From Message ---- ------ ---- ---- ------- Normal ExternalProvisioning 10s (x3 over 21s) persistentvolume-controller waiting for a volume to be created, either by external provisioner &quot;nfs.csi.k8s.io&quot; or manually created by system administrator Normal Provisioning 10s (x2 over 21s) nfs.csi.k8s.io_arm64-05_5f8a51df-3222-4ba3-b5c4-3dbd6f300619 External provisioner is provisioning volume for claim &quot;default\/my-pvc&quot; Warning ProvisioningFailed 0s (x2 over 11s) nfs.csi.k8s.io_arm64-05_5f8a51df-3222-4ba3-b5c4-3dbd6f300619 failed to provision volume with StorageClass &quot;nfs-csi&quot;: rpc error: code = DeadlineExceeded desc = context deadline exceeded #ubuntu server sudo apt update sudo apt install nfs-kernel-server sudo mkdir \/media\/dbuddenbaum\/nfs\/nfs-server sudo chmod -R 0777 \/media\/dbuddenbaum\/nfs\/nfs-server sudo chown nobody:nogroup \/media\/dbuddenbaum\/nfs\/nfs-server dbuddenbaum@DONB-ET1831:\/media\/dbuddenbaum\/Sabrent-2tb-nfs$ sudo vi \/etc\/exports \/media\/dbuddenbaum\/nfs\/nfs-server *(rw,sync,no_subtree_check,no_root_squash,no_all_squash,insecure,anonuid=1000,anongid=1000) sudo systemctl restart nfs-server.service dbuddenbaum@donb-ms7821:~$ sudo \/etc\/init.d\/rpcbind start Starting rpcbind (via systemctl): rpcbind.service. #mac osx client #( 03\/19\/22@10:56PM )( dbuddenbaum@donb-mbp4 ):~\/nfs-dir sudo vi \/etc\/nfs.conf nfs.client.mount.options = vers=4 #( 11\/16\/20@ 1:53AM )( dbuddenbaum@dbuddenbaum-mbp ):~ mkdir ~\/nfs-dir #( 11\/16\/20@ 1:53AM )( dbuddenbaum@dbuddenbaum-mbp ):~ mount -t nfs 192.168.2.112:\/media\/dbuddenbaum\/Sabrent-2tb-nfs\/nfs-server ~\/nfs-dir #( 11\/16\/20@ 1:53AM )( dbuddenbaum@dbuddenbaum-mbp ):~ ls nfs-dir lost+found nfs-server [21:38:24]donbuddenbaum@donbs-iMac:\/private\/nfs$ showmount -e donb-et1831 Exports list on donb-et1831: \/media\/dbuddenbaum\/Sabrent-2tb-nfs\/nfs-server * #unbuntu 20.04 client sudo apt update sudo apt install nfs-common sudo mkdir -p \/mnt\/nfs\/home sudo mount -v 192.168.2.112:\/media\/dbuddenbaum\/Sabrent-2tb-nfs\/nfs-server \/mnt\/nfs\/home -o nfsvers=3 #persistent volume #( 10\/26\/20@ 6:32PM )( donbuddenbaum@donbs-iMac ): ~\/Documents\/rPi4\/kalaxy\/yaml@master\u2717\u2717\u2717 kubectl create -f nfs-pv.yaml persistentvolume\/nfs-pv created #persistent volume #( 10\/26\/20@ 6:32PM )( donbuddenbaum@donbs-iMac ):~\/Documents\/rPi4\/kalaxy\/yaml@master\u2717\u2717\u2717 kubectl get pv NAME CAPACITY ACCESS MODES RECLAIM POLICY STATUS CLAIM STORAGECLASS REASON AGE nfs-pv 10Gi RWX Recycle Available nfs 3m30s #persistent volume claim ** #( 10\/26\/20@ 6:36PM )( donbuddenbaum@donbs-iMac ):~\/Documents\/rPi4\/kalaxy\/yaml@master\u2717\u2717\u2717 ** kubectl create -f nfs-pvc.yaml persistentvolumeclaim\/nfs-pvc created #( 10\/26\/20@ 6:38PM )( donbuddenbaum@donbs-iMac ):~\/Documents\/rPi4\/kalaxy\/yaml@master\u2717\u2717\u2717 kubectl get pvc nfs-pvc NAME STATUS VOLUME CAPACITY ACCESS MODES STORAGECLASS AGE nfs-pvc Bound nfs-pv 10Gi RWX nfs 2m6s #( 10\/26\/20@ 6:39PM )( donbuddenbaum@donbs-iMac ):~\/Documents\/rPi4\/kalaxy\/yaml@master\u2717\u2717\u2717 kubectl get pv nfs-pv NAME CAPACITY ACCESS MODES RECLAIM POLICY STATUS CLAIM STORAGECLASS REASON AGE nfs-pv 10Gi RWX Recycle Bound default\/nfs-pvc nfs 7m33s #mount commands #( 11\/16\/20@12:43AM )( dbuddenbaum@dbuddenbaum-mbp ):~ showmount -e 192.168.2.112 Exports list on 192.168.2.112: \/media\/dbuddenbaum\/Sabrent-2tb-nfs\/nfs-server * #storage logs #( 11\/23\/20@12:49AM )( dbuddenbaum@dbuddenbaum-mbp ):~\/Documents\/rPi4\/kalaxy\/yaml@master\u2717\u2717\u2717 kubectl logs -f nfs-client-provisioner-8cbd9d67c-svl2d -n nfs-storage I1116 17:21:41.038864 1 leaderelection.go:185] attempting to acquire leader lease nfs-storage\/nfs-provisioner-nfs-ssd1... I1116 17:21:41.050908 1 leaderelection.go:194] successfully acquired lease nfs-storage\/nfs-provisioner-nfs-ssd1 I1116 17:21:41.051718 1 controller.go:631] Starting provisioner controller nfs-provisioner\/nfs-ssd1_nfs-client-provisioner-8cbd9d67c-svl2d_30fd60f6-2830-11eb-8250-9af622c5b843! I1116 17:21:41.051778 1 event.go:221] Event(v1.ObjectReference{Kind:&quot;Endpoints&quot;, Namespace:&quot;nfs-storage&quot;, Name:&quot;nfs-provisioner-nfs-ssd1&quot;, UID:&quot;a7601751-1136-4424-bd05-c263d481da65&quot;, APIVersion:&quot;v1&quot;, ResourceVersion:&quot;5569734&quot;, FieldPath:&quot;&quot;}): type: 'Normal' reason: 'LeaderElection' nfs-client-provisioner-8cbd9d67c-svl2d_30fd60f6-2830-11eb-8250-9af622c5b843 became leader I1116 17:21:41.151948 1 controller.go:680] Started provisioner controller nfs-provisioner\/nfs-ssd1_nfs-client-provisioner-8cbd9d67c-svl2d_30fd60f6-2830-11eb-8250-9af622c5b843! #Service accounts and cluster roles #( 11\/23\/20@ 1:36AM )( dbuddenbaum@dbuddenbaum-mbp ):~\/Documents\/rPi4\/kalaxy\/yaml@master\u2717\u2717\u2717 kubectl describe sa -n nfs-storage Name: default Namespace: nfs-storage Labels: &lt;none&gt; Annotations: &lt;none&gt; Image pull secrets: &lt;none&gt; Mountable secrets: default-token-nwz62 Tokens: default-token-nwz62 Events: &lt;none&gt; Name: nfs-client-provisioner Namespace: nfs-storage Labels: &lt;none&gt; Annotations: kubectl.kubernetes.io\/last-applied-configuration: {&quot;apiVersion&quot;:&quot;v1&quot;,&quot;kind&quot;:&quot;ServiceAccount&quot;,&quot;metadata&quot;:{&quot;annotations&quot;:{},&quot;name&quot;:&quot;nfs-client-provisioner&quot;,&quot;namespace&quot;:&quot;nfs-storage&quot;}} Image pull secrets: &lt;none&gt; Mountable secrets: nfs-client-provisioner-token-8cjn8 Tokens: nfs-client-provisioner-token-8cjn8 Events: &lt;none&gt; #( 11\/23\/20@ 1:39AM )( dbuddenbaum@dbuddenbaum-mbp ):~\/Documents\/rPi4\/kalaxy\/yaml@master\u2717\u2717\u2717 kubectl describe clusterrole nfs-client-provisioner Name: nfs-client-provisioner-runner Labels: &lt;none&gt; Annotations: kubectl.kubernetes.io\/last-applied-configuration: {&quot;apiVersion&quot;:&quot;rbac.authorization.k8s.io\/v1&quot;,&quot;kind&quot;:&quot;ClusterRole&quot;,&quot;metadata&quot;:{&quot;annotations&quot;:{},&quot;name&quot;:&quot;nfs-client-provisioner-runner&quot;},&quot;ru... PolicyRule: Resources Non-Resource URLs Resource Names Verbs --------- ----------------- -------------- ----- events [] [] [create update patch] persistentvolumes [] [] [get list watch create delete] persistentvolumeclaims [] [] [get list watch update] storageclasses.storage.k8s.io [] [] [get list watch]","tags":"","url":"file_system\/nfs.html"},{"title":"openebs","text":"Table of Contents OpenEBS Install dbuddenbaum@arm64-01:~$ openEBS setup #( 05\/26\/22@ 7:17PM )( dbuddenbaum@donb-mbp4 ):~\/Documents\/rpi4\/kalaxy\/yaml\/microk8s\/openEBS@main\u2717\u2717\u2717 #( 05\/26\/22@ 7:26PM )( dbuddenbaum@donb-mbp4 ):~\/Documents\/rpi4\/kalaxy\/yaml\/microk8s\/openEBS@main\u2717\u2717\u2717 #OpenEBS OpenEBS Documentation #Install #dbuddenbaum@arm64-01:~$ microk8s enable openebs Addon dns is already enabled. Addon helm3 is already enabled. WARNING: Kubernetes configuration file is group-readable. This is insecure. Location: \/var\/snap\/microk8s\/3207\/credentials\/client.config &quot;openebs&quot; has been added to your repositories WARNING: Kubernetes configuration file is group-readable. This is insecure. Location: \/var\/snap\/microk8s\/3207\/credentials\/client.config Hang tight while we grab the latest from your chart repositories... ...Successfully got an update from the &quot;csi-driver-nfs&quot; chart repository ...Successfully got an update from the &quot;longhorn&quot; chart repository ...Successfully got an update from the &quot;openebs&quot; chart repository Update Complete. \u2388Happy Helming!\u2388 WARNING: Kubernetes configuration file is group-readable. This is insecure. Location: \/var\/snap\/microk8s\/3207\/credentials\/client.config NAME: openebs LAST DEPLOYED: Thu May 26 23:13:50 2022 NAMESPACE: openebs STATUS: deployed REVISION: 1 TEST SUITE: None NOTES: Successfully installed OpenEBS. Check the status by running: kubectl get pods -n openebs The default values will install NDM and enable OpenEBS hostpath and device storage engines along with their default StorageClasses. Use `kubectl get sc` to see the list of installed OpenEBS StorageClasses. **Note**: If you are upgrading from the older helm chart that was using cStor and Jiva (non-csi) volumes, you will have to run the following command to include the older provisioners: helm upgrade openebs openebs\/openebs \\ --namespace openebs \\ --set legacy.enabled=true \\ --reuse-values For other engines, you will need to perform a few more additional steps to enable the engine, configure the engines (e.g. creating pools) and create StorageClasses. For example, cStor can be enabled using commands like: helm upgrade openebs openebs\/openebs \\ --namespace openebs \\ --set cstor.enabled=true \\ --reuse-values For more information, - view the online documentation at https:\/\/openebs.io\/ or - connect with an active community on Kubernetes slack #openebs channel. OpenEBS is installed ----------------------- When using OpenEBS with a single node MicroK8s, it is recommended to use the openebs-hostpath StorageClass An example of creating a PersistentVolumeClaim utilizing the openebs-hostpath StorageClass kind: PersistentVolumeClaim apiVersion: v1 metadata: name: local-hostpath-pvc spec: storageClassName: openebs-hostpath accessModes: - ReadWriteOnce resources: requests: storage: 5G ----------------------- If you are planning to use OpenEBS with multi nodes, you can use the openebs-jiva-csi-default StorageClass. An example of creating a PersistentVolumeClaim utilizing the openebs-jiva-csi-default StorageClass kind: PersistentVolumeClaim apiVersion: v1 metadata: name: jiva-volume-claim spec: storageClassName: openebs-jiva-csi-default accessModes: - ReadWriteOnce resources: requests: storage: 5G #openEBS setup ##( 05\/26\/22@ 7:17PM )( dbuddenbaum@donb-mbp4 ):~\/Documents\/rpi4\/kalaxy\/yaml\/microk8s\/openEBS@main\u2717\u2717\u2717 kubectl apply -f openebs_pvc.yaml persistentvolumeclaim\/jiva-volume-claim created ##( 05\/26\/22@ 7:26PM )( dbuddenbaum@donb-mbp4 ):~\/Documents\/rpi4\/kalaxy\/yaml\/microk8s\/openEBS@main\u2717\u2717\u2717 kubectl get pvc NAME STATUS VOLUME CAPACITY ACCESS MODES STORAGECLASS AGE my-pvc Bound pvc-6177950b-c008-4ad1-aaa1-c0f06a529b69 5Gi RWO nfs-csi 46d jiva-volume-claim Bound pvc-8939719d-c33f-46a4-99b2-b8a49c41c1bd 5G RWO openebs-jiva-csi-default 9m30s","tags":"","url":"file_system\/openebs.html"},{"title":"rook ceph","text":"Table of Contents Setup Notes #Rook Ceph https:\/\/medium.com\/swlh\/build-ceph-and-kubernetes-based-distributed-file-storage-system-943da3dd0d24 https:\/\/platform9.com\/blog\/how-to-set-up-rook-to-manage-a-ceph-cluster-within-kubernetes\/ #Setup #( 04\/01\/21@ 6:31PM )( donbuddenbaum@donbs-iMac ):~\/Documents\/rPi4\/kalaxy\/yaml\/rook-ceph@master\u2717\u2717\u2717 kubectl apply -f common.yaml namespace\/rook-ceph created customresourcedefinition.apiextensions.k8s.io\/cephclusters.ceph.rook.io created customresourcedefinition.apiextensions.k8s.io\/cephclients.ceph.rook.io created customresourcedefinition.apiextensions.k8s.io\/cephfilesystems.ceph.rook.io created customresourcedefinition.apiextensions.k8s.io\/cephnfses.ceph.rook.io created customresourcedefinition.apiextensions.k8s.io\/cephobjectstores.ceph.rook.io created customresourcedefinition.apiextensions.k8s.io\/cephobjectstoreusers.ceph.rook.io created customresourcedefinition.apiextensions.k8s.io\/cephblockpools.ceph.rook.io created customresourcedefinition.apiextensions.k8s.io\/volumes.rook.io created customresourcedefinition.apiextensions.k8s.io\/objectbuckets.objectbucket.io created customresourcedefinition.apiextensions.k8s.io\/objectbucketclaims.objectbucket.io created clusterrolebinding.rbac.authorization.k8s.io\/rook-ceph-object-bucket created clusterrole.rbac.authorization.k8s.io\/rook-ceph-cluster-mgmt created clusterrole.rbac.authorization.k8s.io\/rook-ceph-cluster-mgmt-rules created role.rbac.authorization.k8s.io\/rook-ceph-system created clusterrole.rbac.authorization.k8s.io\/rook-ceph-global created clusterrole.rbac.authorization.k8s.io\/rook-ceph-global-rules created clusterrole.rbac.authorization.k8s.io\/rook-ceph-mgr-cluster created clusterrole.rbac.authorization.k8s.io\/rook-ceph-mgr-cluster-rules created clusterrole.rbac.authorization.k8s.io\/rook-ceph-object-bucket created serviceaccount\/rook-ceph-system created rolebinding.rbac.authorization.k8s.io\/rook-ceph-system created clusterrolebinding.rbac.authorization.k8s.io\/rook-ceph-global created serviceaccount\/rook-ceph-osd created serviceaccount\/rook-ceph-mgr created serviceaccount\/rook-ceph-cmd-reporter created role.rbac.authorization.k8s.io\/rook-ceph-osd created clusterrole.rbac.authorization.k8s.io\/rook-ceph-osd created clusterrole.rbac.authorization.k8s.io\/rook-ceph-mgr-system created clusterrole.rbac.authorization.k8s.io\/rook-ceph-mgr-system-rules created role.rbac.authorization.k8s.io\/rook-ceph-mgr created role.rbac.authorization.k8s.io\/rook-ceph-cmd-reporter created rolebinding.rbac.authorization.k8s.io\/rook-ceph-cluster-mgmt created rolebinding.rbac.authorization.k8s.io\/rook-ceph-osd created rolebinding.rbac.authorization.k8s.io\/rook-ceph-mgr created rolebinding.rbac.authorization.k8s.io\/rook-ceph-mgr-system created clusterrolebinding.rbac.authorization.k8s.io\/rook-ceph-mgr-cluster created clusterrolebinding.rbac.authorization.k8s.io\/rook-ceph-osd created rolebinding.rbac.authorization.k8s.io\/rook-ceph-cmd-reporter created podsecuritypolicy.policy\/rook-privileged created clusterrole.rbac.authorization.k8s.io\/psp:rook created clusterrolebinding.rbac.authorization.k8s.io\/rook-ceph-system-psp created rolebinding.rbac.authorization.k8s.io\/rook-ceph-default-psp created rolebinding.rbac.authorization.k8s.io\/rook-ceph-osd-psp created rolebinding.rbac.authorization.k8s.io\/rook-ceph-mgr-psp created rolebinding.rbac.authorization.k8s.io\/rook-ceph-cmd-reporter-psp created serviceaccount\/rook-csi-cephfs-plugin-sa created serviceaccount\/rook-csi-cephfs-provisioner-sa created role.rbac.authorization.k8s.io\/cephfs-external-provisioner-cfg created rolebinding.rbac.authorization.k8s.io\/cephfs-csi-provisioner-role-cfg created clusterrole.rbac.authorization.k8s.io\/cephfs-csi-nodeplugin created clusterrole.rbac.authorization.k8s.io\/cephfs-csi-nodeplugin-rules created clusterrole.rbac.authorization.k8s.io\/cephfs-external-provisioner-runner created clusterrole.rbac.authorization.k8s.io\/cephfs-external-provisioner-runner-rules created clusterrolebinding.rbac.authorization.k8s.io\/rook-csi-cephfs-plugin-sa-psp created clusterrolebinding.rbac.authorization.k8s.io\/rook-csi-cephfs-provisioner-sa-psp created clusterrolebinding.rbac.authorization.k8s.io\/cephfs-csi-nodeplugin created clusterrolebinding.rbac.authorization.k8s.io\/cephfs-csi-provisioner-role created serviceaccount\/rook-csi-rbd-plugin-sa created serviceaccount\/rook-csi-rbd-provisioner-sa created role.rbac.authorization.k8s.io\/rbd-external-provisioner-cfg created rolebinding.rbac.authorization.k8s.io\/rbd-csi-provisioner-role-cfg created clusterrole.rbac.authorization.k8s.io\/rbd-csi-nodeplugin created clusterrole.rbac.authorization.k8s.io\/rbd-csi-nodeplugin-rules created clusterrole.rbac.authorization.k8s.io\/rbd-external-provisioner-runner created clusterrole.rbac.authorization.k8s.io\/rbd-external-provisioner-runner-rules created clusterrolebinding.rbac.authorization.k8s.io\/rook-csi-rbd-plugin-sa-psp created clusterrolebinding.rbac.authorization.k8s.io\/rook-csi-rbd-provisioner-sa-psp created clusterrolebinding.rbac.authorization.k8s.io\/rbd-csi-nodeplugin created clusterrolebinding.rbac.authorization.k8s.io\/rbd-csi-provisioner-role created #( 04\/01\/21@ 6:31PM )( donbuddenbaum@donbs-iMac ):~\/Documents\/rPi4\/kalaxy\/yaml\/rook-ceph@master\u2717\u2717\u2717 kubectl apply -f operator.yaml configmap\/rook-ceph-operator-config created deployment.apps\/rook-ceph-operator created #( 04\/01\/21@ 6:34PM )( donbuddenbaum@donbs-iMac ):~\/Documents\/rPi4\/kalaxy\/yaml\/rook-ceph@master\u2717\u2717\u2717 kubectl get pod -n rook-ceph NAME READY STATUS RESTARTS AGE rook-ceph-operator-b676fc78d-pttxr 0\/1 ContainerCreating 0 3m27s #Notes","tags":"","url":"file_system\/rook_ceph.html"},{"title":"samba","text":"Table of Contents Samba #Samba How to configure Samba Server share on Ubuntu 20.04 Focal Fossa Linux","tags":"","url":"file_system\/samba.html"},{"title":"cloudflare","text":"Table of Contents CloudFlare References Add tunnel Install on FileServer dbuddenbaum@donb-ms7821:~$ dbuddenbaum@donb-ms7821:~$ Check Cloud Flared Status LinkedIn Authorization #CloudFlare #References EXPOSE your home network to the INTERNET!! (it\u2019s safe) donb4iu.com - squarespace cloudflare dashboard cloudflare docs Enable or Disable systemd Services in Ubuntu #Add tunnel #Install on FileServer #dbuddenbaum@donb-ms7821:~$ curl -L \u2013output cloudflared.deb https:\/\/github.com\/cloudflare\/cloudflared\/releases\/latest\/download\/cloudflared-linux-amd64.deb &amp;&amp; sudo dpkg -i cloudflared.deb &amp;&amp; sudo cloudflared service install eyJhIjoiNjRmMWNiOTYwN2EyZTA2YzU4YTM2ZjUwNzMxN2E0NTciLCJ0IjoiZDliZGU5OTUtZjVhMy00MDVmLWJhZGYtM2ZhYWNkZGFhMDlhIiwicyI6IllUUTNNR1E1TVdJdE4yUTFOeTAwTjJSa0xUZ3lOemd0WkdNME1HSmtNR00xTURabCJ9 % Total % Received % Xferd Average Speed Time Time Time Current Dload Upload Total Spent Left Speed 0 0 0 0 0 0 0 0 --:--:-- --:--:-- --:--:-- 0 0 0 0 0 0 0 0 0 --:--:-- --:--:-- --:--:-- 0 100 16.9M 100 16.9M 0 0 8224k 0 0:00:02 0:00:02 --:--:-- 10.6M [sudo] password for dbuddenbaum: (Reading database ... 189635 files and directories currently installed.) Preparing to unpack cloudflared.deb ... Unpacking cloudflared (2024.4.1) over (2024.4.1) ... Setting up cloudflared (2024.4.1) ... Processing triggers for man-db (2.9.1-1) ... 2024-05-01T00:26:31Z INF Using Systemd 2024-05-01T00:26:31Z ERR error generating service template error=&quot;cloudflared service is already installed at \/etc\/systemd\/system\/cloudflared.service; if you are running a cloudflared tunnel, you can point it to multiple origins, avoiding the need to run more than one cloudflared service in the same machine; otherwise if you are really sure, you can do `cloudflared service uninstall` to clean up the existing service and then try again this command&quot; cloudflared service is already installed at \/etc\/systemd\/system\/cloudflared.service; if you are running a cloudflared tunnel, you can point it to multiple origins, avoiding the need to run more than one cloudflared service in the same machine; otherwise if you are really sure, you can do `cloudflared service uninstall` to clean up the existing service and then try again this command #dbuddenbaum@donb-ms7821:~$ systemctl enable cloudflared ==== AUTHENTICATING FOR org.freedesktop.systemd1.manage-unit-files === Authentication is required to manage system service or unit files. Authenticating as: Don Buddenbaum,,, (dbuddenbaum) Password: ==== AUTHENTICATION COMPLETE === Created symlink \/etc\/systemd\/system\/multi-user.target.wants\/cloudflared.service \u2192 \/etc\/systemd\/system\/cloudflared.service. ==== AUTHENTICATING FOR org.freedesktop.systemd1.reload-daemon === Authentication is required to reload the systemd state. Authenticating as: Don Buddenbaum,,, (dbuddenbaum) Password: ==== AUTHENTICATION COMPLETE === #Check Cloud Flared Status 385 systemctl status cloudflared 386 sudo cloudflared service uninstall #LinkedIn Authorization","tags":"","url":"hosting_homelab_on_internet\/cloudflare.html"},{"title":"pulumi","text":"Table of Contents Pulumi References Setup #( 06\/01\/24@ 5:36PM )( donbuddenbaum@donbs-imac ):~\/Documents #( 06\/03\/24@ 3:26PM )( donbuddenbaum@donbs-imac ):~\/Documents #Pulumi #References Learning Pulumi by using microk8s and adding basic services to cluster. Pulumi Kubernetes: Installation &amp; Configuration #Setup ##( 06\/01\/24@ 5:36PM )( donbuddenbaum@donbs-imac ):~\/Documents brew install pulumi\/tap\/pulumi ==&gt; Auto-updating Homebrew... Adjust how often this is run with HOMEBREW_AUTO_UPDATE_SECS or disable with HOMEBREW_NO_AUTO_UPDATE. Hide these hints with HOMEBREW_NO_ENV_HINTS (see `man brew`). ==&gt; Downloading https:\/\/ghcr.io\/v2\/homebrew\/portable-ruby\/portable-ruby\/blobs\/sha256:5c86a23e0e3caee1a4cfd958ed7d50a38e752ebaf2e7c5717e5c8eabaa6e9f12 #=#=- # # #=O#- # # -#O=- # # # -=O#- # # # ######################################################################################################################################################################################################################################################### 100.0% ==&gt; Pouring portable-ruby-3.3.2.el_capitan.bottle.tar.gz ==&gt; Auto-updated Homebrew! Updated 2 taps (homebrew\/core and homebrew\/cask). ==&gt; New Formulae haproxy@2.8 oils-for-unix openfa pedump rustls-ffi span-lite yara-x ==&gt; New Casks anchor-wallet font-anton-sc font-baskervville-sc font-bona-nova-sc font-playwrite-nl font-playwrite-pl font-playwrite-ro naps2 font-alumni-sans-collegiate-one-sc font-arsenal-sc font-bodoni-moda-sc font-playwrite-is font-playwrite-no font-playwrite-pt font-playwrite-sk qlzipinfo Error: Unexpected method 'appcast' called on Cask minikube. Follow the instructions here: https:\/\/github.com\/Homebrew\/homebrew-cask#reporting-bugs You have 60 outdated formulae and 7 outdated casks installed. Error: Unexpected method 'appcast' called on Cask minikube. Follow the instructions here: https:\/\/github.com\/Homebrew\/homebrew-cask#reporting-bugs Error: Unexpected method 'appcast' called on Cask minikube. Follow the instructions here: https:\/\/github.com\/Homebrew\/homebrew-cask#reporting-bugs ==&gt; Tapping pulumi\/tap Cloning into '\/usr\/local\/Homebrew\/Library\/Taps\/pulumi\/homebrew-tap'... remote: Enumerating objects: 1938, done. remote: Counting objects: 100% (113\/113), done. remote: Compressing objects: 100% (66\/66), done. remote: Total 1938 (delta 76), reused 64 (delta 43), pack-reused 1825 Receiving objects: 100% (1938\/1938), 287.49 KiB | 2.28 MiB\/s, done. Resolving deltas: 100% (1384\/1384), done. Tapped 9 formulae (25 files, 376.5KB). pulumi 3.77.1 is already installed but outdated (so it will be upgraded). ==&gt; Fetching pulumi\/tap\/pulumi ==&gt; Downloading https:\/\/github.com\/pulumi\/pulumi\/releases\/download\/v3.118.0\/pulumi-v3.118.0-darwin-x64.tar.gz ==&gt; Downloading from https:\/\/objects.githubusercontent.com\/github-production-release-asset-2e65be\/72477752\/dfa1996f-4ca0-446a-8335-4de566dd5612?X-Amz-Algorithm=AWS4-HMAC-SHA256&amp;X-Amz-Credential=releaseassetproduction%2F20240603%2Fus-east-1%2Fs3%2Faws4_request&amp;X-Amz-Date=20240603T192520Z&amp;X-A ######################################################################################################################################################################################################################################################### 100.0% ==&gt; Upgrading pulumi\/tap\/pulumi 3.77.1 -&gt; 3.118.0 ==&gt; Caveats zsh completions have been installed to: \/usr\/local\/share\/zsh\/site-functions ==&gt; Summary \ud83c\udf7a \/usr\/local\/Cellar\/pulumi\/3.118.0: 19 files, 354.9MB, built in 1 minute 1 second ==&gt; Running `brew cleanup pulumi`... Disable this behaviour by setting HOMEBREW_NO_INSTALL_CLEANUP. Hide these hints with HOMEBREW_NO_ENV_HINTS (see `man brew`). Removing: \/usr\/local\/Cellar\/pulumi\/3.77.1... (21 files, 305.2MB) ##( 06\/03\/24@ 3:26PM )( donbuddenbaum@donbs-imac ):~\/Documents pulumi login Manage your Pulumi stacks by logging in. Run `pulumi login --help` for alternative login options. Enter your access token from https:\/\/app.pulumi.com\/account\/tokens or hit &lt;ENTER&gt; to log in using your browser :","tags":"","url":"iac\/pulumi.html"},{"title":"zitadel","text":"Table of Contents Zitadel References #Zitadel #References Zitadel","tags":"","url":"id_auth\/zitadel.html"},{"title":"AI ideas","text":"Table of Contents AI Ideas References #AI Ideas #References Andrew Ng On AI Agentic Workflows And Their Potential For Driving AI Progress Vision Agent is a library that helps you utilize agent frameworks to generate code to solve your vision task. Many current vision problems can easily take hours or days to solve, you need to find the right model, figure out how to use it and program it to accomplish the task you want. Vision Agent aims to provide an in-seconds experience by allowing users to describe their problem in text and have the agent framework generate code to solve the task for them. Check out our discord for updates and roadmaps! Reference architectures for Internal Developer Platforms","tags":"","url":"ideas\/AI_ideas.html"},{"title":"sources","text":"Table of Contents Sources References Kube Campus Medium #Sources #References #Kube Campus Demystifying Persistent Volumes and Persistent Volume Claims #Medium Richard Youngkin","tags":"","url":"ideas\/sources.html"},{"title":"restapi","text":"Table of Contents IRIS Rest API Reference API Swagger Individual APIs Management API Transactions (Postman) Put Get #IRIS Rest API #Reference github template intersystems - iris-rest-api-template - tutorial iris-rest-api-template - template Building a REST API with InterSystem IRIS #API #Swagger http:\/\/localhost:52773\/swagger-ui\/index.html _SYSTEM SYS #Individual APIs #Management API #Transactions (Postman) #Put #Get","tags":"","url":"iris\/restapi.html"},{"title":"knotes","text":"Table of Contents Springboot Notes App for Kubernetes Reference Start MongoDB #( 05\/09\/24@ 3:20PM )( donbuddenbaum@donbs-imac ):~ #( 05\/09\/24@ 3:31PM )( donbuddenbaum@donbs-imac ):\/usr #( 05\/09\/24@ 3:33PM )( donbuddenbaum@donbs-imac ):\/usr Build &amp; Test #( 05\/08\/24@ 3:31PM )( donbuddenbaum@donbs-imac ):~\/Documents\/knote-java\/01@master\u2717\u2717\u2717 #( 05\/09\/24@ 5:18PM )( donbuddenbaum@donbs-imac ):~\/Documents\/knote-java\/02@master\u2717\u2717\u2717 #( 05\/09\/24@ 5:21PM )( donbuddenbaum@donbs-imac ):~\/Documents\/knote-java\/02@master\u2717\u2717\u2717 Run knote in a Docker Network #( 05\/09\/24@ 5:21PM )( donbuddenbaum@donbs-imac ):~\/Documents\/knote-java\/02@master\u2717\u2717\u2717 #( 05\/09\/24@ 5:25PM )( donbuddenbaum@donbs-imac ):~\/Documents\/knote-java\/02@master\u2717\u2717\u2717 #( 05\/09\/24@ 5:31PM )( donbuddenbaum@donbs-imac ):~ #( 05\/09\/24@ 5:35PM )( donbuddenbaum@donbs-imac ):~ #( 05\/09\/24@ 5:35PM )( donbuddenbaum@donbs-imac ):~ #( 05\/09\/24@ 5:38PM )( donbuddenbaum@donbs-imac ):~ #( 05\/09\/24@ 5:41PM )( donbuddenbaum@donbs-imac ):~ #( 05\/09\/24@ 5:42PM )( donbuddenbaum@donbs-imac ):~ Docker Buiild Multi-Arch (AMD64\/ARM64) #( 05\/09\/24@ 5:43PM )( donbuddenbaum@donbs-imac ):~ #( 05\/09\/24@ 5:50PM )( donbuddenbaum@donbs-imac ):~ MicroK8s Deployment Stateful - NFS #( 05\/10\/24@ 8:57PM )( donbuddenbaum@donbs-imac ):~\/Documents\/Kalaxy2\/yaml\/knotes@main\u2717\u2717\u2717 #( 05\/10\/24@ 9:26PM )( donbuddenbaum@donbs-imac ):~\/Documents\/Kalaxy2\/yaml\/knotes@main\u2717\u2717\u2717 #( 05\/10\/24@ 9:32PM )( donbuddenbaum@donbs-imac ):~\/Documents\/Kalaxy2\/yaml\/knotes@main\u2717\u2717\u2717 Build &amp; Test Minio #( 05\/10\/24@ 9:51PM )( donbuddenbaum@donbs-imac ):~\/Documents\/Kalaxy2\/yaml\/knotes\/nfs@main\u2717\u2717\u2717 #( 05\/10\/24@10:22PM )( donbuddenbaum@donbs-imac ):~ #( 05\/10\/24@10:21PM )( donbuddenbaum@donbs-imac ):~\/Documents\/knote-java\/04-05@master\u2717\u2717\u2717 #( 05\/10\/24@10:48PM )( donbuddenbaum@donbs-imac ):~\/Documents\/knote-java\/04-05@master\u2717\u2717\u2717 Build mArch Containers #( 05\/10\/24@10:59PM )( donbuddenbaum@donbs-imac ):~\/Documents\/knote-java\/04-05@master\u2714 #( 05\/10\/24@10:48PM )( donbuddenbaum@donbs-imac ):~\/Documents\/knote-java\/04-05@master\u2717\u2717\u2717 #( 05\/10\/24@11:03PM )( donbuddenbaum@donbs-imac ):~\/Documents\/knote-java\/04-05@master\u2717\u2717\u2717 Build &amp; Test Minio with mArch image #( 05\/10\/24@11:09PM )( donbuddenbaum@donbs-imac ):~\/Documents\/Kalaxy2\/yaml\/knotes\/nfs@main\u2717\u2717\u2717 #( 05\/10\/24@11:27PM )( donbuddenbaum@donbs-imac ):~\/Documents\/knote-java@master\u2717\u2717\u2717 #( 05\/10\/24@11:27PM )( donbuddenbaum@donbs-imac ):~\/Documents\/knote-java\/04-05@master\u2717\u2717\u2717 #Springboot Notes App for Kubernetes #Reference Developing and deploying Spring Boot microservices on Kubernetes https:\/\/github.com\/learnk8s\/knote-java #Start MongoDB ##( 05\/09\/24@ 3:20PM )( donbuddenbaum@donbs-imac ):~ mongod \u2013config \/usr\/local\/etc\/mongod.conf ##( 05\/09\/24@ 3:31PM )( donbuddenbaum@donbs-imac ):\/usr brew install mongosh ##( 05\/09\/24@ 3:33PM )( donbuddenbaum@donbs-imac ):\/usr mongosh \u201cmongodb:\/\/localhost:27017\u201d Current Mongosh Log ID: 663d25540c41d43aadb09c44 Connecting to: mongodb:\/\/localhost:27017\/?directConnection=true&amp;serverSelectionTimeoutMS=2000&amp;appName=mongosh+2.2.5 Using MongoDB: 7.0.8 Using Mongosh: 2.2.5 For mongosh info see: https:\/\/docs.mongodb.com\/mongodb-shell\/ To help improve our products, anonymous usage data is collected and sent to MongoDB periodically (https:\/\/www.mongodb.com\/legal\/privacy-policy). You can opt-out by running the disableTelemetry() command. ------ The server generated these startup warnings when booting 2024-05-08T14:20:25.975-04:00: Access control is not enabled for the database. Read and write access to data and configuration is unrestricted 2024-05-08T14:20:25.975-04:00: Soft rlimits for open file descriptors too low ------ test&gt; db test #Build &amp; Test ##( 05\/08\/24@ 3:31PM )( donbuddenbaum@donbs-imac ):~\/Documents\/knote-java\/01@master\u2717\u2717\u2717 mvn clean install spring-boot:run [INFO] Scanning for projects... [INFO] [INFO] -----------------------&lt; io.learnk8s:knote-java &gt;----------------------- [INFO] Building knote 1.0.0 [INFO] --------------------------------[ jar ]--------------------------------- [INFO] [INFO] --- maven-clean-plugin:3.1.0:clean (default-clean) @ knote-java --- [INFO] Deleting \/Users\/donbuddenbaum\/Documents\/knote-java\/01\/target [INFO] [INFO] --- maven-resources-plugin:3.1.0:resources (default-resources) @ knote-java --- [INFO] Using 'UTF-8' encoding to copy filtered resources. [INFO] Copying 1 resource [INFO] Copying 2 resources [INFO] [INFO] --- maven-compiler-plugin:3.8.1:compile (default-compile) @ knote-java --- [INFO] Changes detected - recompiling the module! [INFO] Compiling 1 source file to \/Users\/donbuddenbaum\/Documents\/knote-java\/01\/target\/classes [INFO] [INFO] --- maven-resources-plugin:3.1.0:testResources (default-testResources) @ knote-java --- [INFO] Using 'UTF-8' encoding to copy filtered resources. [INFO] skip non existing resourceDirectory \/Users\/donbuddenbaum\/Documents\/knote-java\/01\/src\/test\/resources [INFO] [INFO] --- maven-compiler-plugin:3.8.1:testCompile (default-testCompile) @ knote-java --- [INFO] Changes detected - recompiling the module! [INFO] Compiling 1 source file to \/Users\/donbuddenbaum\/Documents\/knote-java\/01\/target\/test-classes [INFO] [INFO] --- maven-surefire-plugin:2.22.2:test (default-test) @ knote-java --- [INFO] [INFO] ------------------------------------------------------- [INFO] T E S T S [INFO] ------------------------------------------------------- [INFO] Running io.learnk8s.knote.KnoteJavaApplicationTests 16:11:39.337 [main] DEBUG org.springframework.test.context.junit4.SpringJUnit4ClassRunner - SpringJUnit4ClassRunner constructor called with [class io.learnk8s.knote.KnoteJavaApplicationTests] 16:11:39.345 [main] DEBUG org.springframework.test.context.BootstrapUtils - Instantiating CacheAwareContextLoaderDelegate from class [org.springframework.test.context.cache.DefaultCacheAwareContextLoaderDelegate] 16:11:39.358 [main] DEBUG org.springframework.test.context.BootstrapUtils - Instantiating BootstrapContext using constructor [public org.springframework.test.context.support.DefaultBootstrapContext(java.lang.Class,org.springframework.test.context.CacheAwareContextLoaderDelegate)] 16:11:39.390 [main] DEBUG org.springframework.test.context.BootstrapUtils - Instantiating TestContextBootstrapper for test class [io.learnk8s.knote.KnoteJavaApplicationTests] from class [org.springframework.boot.test.context.SpringBootTestContextBootstrapper] 16:11:39.411 [main] INFO org.springframework.boot.test.context.SpringBootTestContextBootstrapper - Neither @ContextConfiguration nor @ContextHierarchy found for test class [io.learnk8s.knote.KnoteJavaApplicationTests], using SpringBootContextLoader 16:11:39.416 [main] DEBUG org.springframework.test.context.support.AbstractContextLoader - Did not detect default resource location for test class [io.learnk8s.knote.KnoteJavaApplicationTests]: class path resource [io\/learnk8s\/knote\/KnoteJavaApplicationTests-context.xml] does not exist 16:11:39.417 [main] DEBUG org.springframework.test.context.support.AbstractContextLoader - Did not detect default resource location for test class [io.learnk8s.knote.KnoteJavaApplicationTests]: class path resource [io\/learnk8s\/knote\/KnoteJavaApplicationTestsContext.groovy] does not exist 16:11:39.418 [main] INFO org.springframework.test.context.support.AbstractContextLoader - Could not detect default resource locations for test class [io.learnk8s.knote.KnoteJavaApplicationTests]: no resource found for suffixes {-context.xml, Context.groovy}. 16:11:39.419 [main] INFO org.springframework.test.context.support.AnnotationConfigContextLoaderUtils - Could not detect default configuration classes for test class [io.learnk8s.knote.KnoteJavaApplicationTests]: KnoteJavaApplicationTests does not declare any static, non-private, non-final, nested classes annotated with @Configuration. 16:11:39.504 [main] DEBUG org.springframework.test.context.support.ActiveProfilesUtils - Could not find an 'annotation declaring class' for annotation type [org.springframework.test.context.ActiveProfiles] and class [io.learnk8s.knote.KnoteJavaApplicationTests] 16:11:39.606 [main] DEBUG org.springframework.context.annotation.ClassPathScanningCandidateComponentProvider - Identified candidate component class: file [\/Users\/donbuddenbaum\/Documents\/knote-java\/01\/target\/classes\/io\/learnk8s\/knote\/KnoteJavaApplication.class] 16:11:39.613 [main] INFO org.springframework.boot.test.context.SpringBootTestContextBootstrapper - Found @SpringBootConfiguration io.learnk8s.knote.KnoteJavaApplication for test class io.learnk8s.knote.KnoteJavaApplicationTests 16:11:39.722 [main] DEBUG org.springframework.boot.test.context.SpringBootTestContextBootstrapper - @TestExecutionListeners is not present for class [io.learnk8s.knote.KnoteJavaApplicationTests]: using defaults. 16:11:39.722 [main] INFO org.springframework.boot.test.context.SpringBootTestContextBootstrapper - Loaded default TestExecutionListener class names from location [META-INF\/spring.factories]: [org.springframework.boot.test.mock.mockito.MockitoTestExecutionListener, org.springframework.boot.test.mock.mockito.ResetMocksTestExecutionListener, org.springframework.boot.test.autoconfigure.restdocs.RestDocsTestExecutionListener, org.springframework.boot.test.autoconfigure.web.client.MockRestServiceServerResetTestExecutionListener, org.springframework.boot.test.autoconfigure.web.servlet.MockMvcPrintOnlyOnFailureTestExecutionListener, org.springframework.boot.test.autoconfigure.web.servlet.WebDriverTestExecutionListener, org.springframework.test.context.web.ServletTestExecutionListener, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener, org.springframework.test.context.support.DependencyInjectionTestExecutionListener, org.springframework.test.context.support.DirtiesContextTestExecutionListener, org.springframework.test.context.transaction.TransactionalTestExecutionListener, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener] 16:11:39.743 [main] INFO org.springframework.boot.test.context.SpringBootTestContextBootstrapper - Using TestExecutionListeners: [org.springframework.test.context.web.ServletTestExecutionListener@45ac5f9b, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener@135606db, org.springframework.boot.test.mock.mockito.MockitoTestExecutionListener@518caac3, org.springframework.boot.test.autoconfigure.SpringBootDependencyInjectionTestExecutionListener@68034211, org.springframework.test.context.support.DirtiesContextTestExecutionListener@4f74980d, org.springframework.test.context.transaction.TransactionalTestExecutionListener@6c372fe6, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener@58594a11, org.springframework.boot.test.mock.mockito.ResetMocksTestExecutionListener@2a3888c1, org.springframework.boot.test.autoconfigure.restdocs.RestDocsTestExecutionListener@4167d97b, org.springframework.boot.test.autoconfigure.web.client.MockRestServiceServerResetTestExecutionListener@14fa86ae, org.springframework.boot.test.autoconfigure.web.servlet.MockMvcPrintOnlyOnFailureTestExecutionListener@6e15fe2, org.springframework.boot.test.autoconfigure.web.servlet.WebDriverTestExecutionListener@68f1b17f] 16:11:39.745 [main] DEBUG org.springframework.test.annotation.ProfileValueUtils - Retrieved @ProfileValueSourceConfiguration [null] for test class [io.learnk8s.knote.KnoteJavaApplicationTests] 16:11:39.746 [main] DEBUG org.springframework.test.annotation.ProfileValueUtils - Retrieved ProfileValueSource type [class org.springframework.test.annotation.SystemProfileValueSource] for class [io.learnk8s.knote.KnoteJavaApplicationTests] 16:11:39.747 [main] DEBUG org.springframework.test.annotation.ProfileValueUtils - Retrieved @ProfileValueSourceConfiguration [null] for test class [io.learnk8s.knote.KnoteJavaApplicationTests] 16:11:39.748 [main] DEBUG org.springframework.test.annotation.ProfileValueUtils - Retrieved ProfileValueSource type [class org.springframework.test.annotation.SystemProfileValueSource] for class [io.learnk8s.knote.KnoteJavaApplicationTests] 16:11:39.748 [main] DEBUG org.springframework.test.annotation.ProfileValueUtils - Retrieved @ProfileValueSourceConfiguration [null] for test class [io.learnk8s.knote.KnoteJavaApplicationTests] 16:11:39.748 [main] DEBUG org.springframework.test.annotation.ProfileValueUtils - Retrieved ProfileValueSource type [class org.springframework.test.annotation.SystemProfileValueSource] for class [io.learnk8s.knote.KnoteJavaApplicationTests] 16:11:39.752 [main] DEBUG org.springframework.test.context.support.AbstractDirtiesContextTestExecutionListener - Before test class: context [DefaultTestContext@4b7dc788 testClass = KnoteJavaApplicationTests, testInstance = [null], testMethod = [null], testException = [null], mergedContextConfiguration = [WebMergedContextConfiguration@6304101a testClass = KnoteJavaApplicationTests, locations = '{}', classes = '{class io.learnk8s.knote.KnoteJavaApplication}', contextInitializerClasses = '[]', activeProfiles = '{}', propertySourceLocations = '{}', propertySourceProperties = '{org.springframework.boot.test.context.SpringBootTestContextBootstrapper=true}', contextCustomizers = set[org.springframework.boot.test.context.filter.ExcludeFilterContextCustomizer@2638011, org.springframework.boot.test.json.DuplicateJsonObjectContextCustomizerFactory$DuplicateJsonObjectContextCustomizer@313b2ea6, org.springframework.boot.test.mock.mockito.MockitoContextCustomizer@0, org.springframework.boot.test.web.client.TestRestTemplateContextCustomizer@7c83dc97, org.springframework.boot.test.autoconfigure.properties.PropertyMappingContextCustomizer@0, org.springframework.boot.test.autoconfigure.web.servlet.WebDriverContextCustomizerFactory$Customizer@609db43b], resourceBasePath = 'src\/main\/webapp', contextLoader = 'org.springframework.boot.test.context.SpringBootContextLoader', parent = [null]], attributes = map['org.springframework.test.context.web.ServletTestExecutionListener.activateListener' -&gt; true]], class annotated with @DirtiesContext [false] with mode [null]. 16:11:39.752 [main] DEBUG org.springframework.test.annotation.ProfileValueUtils - Retrieved @ProfileValueSourceConfiguration [null] for test class [io.learnk8s.knote.KnoteJavaApplicationTests] 16:11:39.752 [main] DEBUG org.springframework.test.annotation.ProfileValueUtils - Retrieved ProfileValueSource type [class org.springframework.test.annotation.SystemProfileValueSource] for class [io.learnk8s.knote.KnoteJavaApplicationTests] 16:11:39.779 [main] DEBUG org.springframework.test.context.support.TestPropertySourceUtils - Adding inlined properties to environment: {spring.jmx.enabled=false, org.springframework.boot.test.context.SpringBootTestContextBootstrapper=true, server.port=-1} . ____ _ __ _ _ \/\\\\ \/ ___'_ __ _ _(_)_ __ __ _ \\ \\ \\ \\ ( ( )\\___ | '_ | '_| | '_ \\\/ _` | \\ \\ \\ \\ \\\\\/ ___)| |_)| | | | | || (_| | ) ) ) ) ' |____| .__|_| |_|_| |_\\__, | \/ \/ \/ \/ =========|_|==============|___\/=\/_\/_\/_\/ :: Spring Boot :: (v2.1.6.RELEASE) 2024-05-08 16:11:40.173 INFO 12654 --- [ main] i.l.knote.KnoteJavaApplicationTests : Starting KnoteJavaApplicationTests on donbs-imac.local with PID 12654 (started by donbuddenbaum in \/Users\/donbuddenbaum\/Documents\/knote-java\/01) 2024-05-08 16:11:40.174 INFO 12654 --- [ main] i.l.knote.KnoteJavaApplicationTests : No active profile set, falling back to default profiles: default 2024-05-08 16:11:41.391 INFO 12654 --- [ main] .s.d.r.c.RepositoryConfigurationDelegate : Bootstrapping Spring Data repositories in DEFAULT mode. 2024-05-08 16:11:41.503 INFO 12654 --- [ main] .s.d.r.c.RepositoryConfigurationDelegate : Finished Spring Data repository scanning in 103ms. Found 1 repository interfaces. 2024-05-08 16:11:43.233 INFO 12654 --- [ main] org.mongodb.driver.cluster : Cluster created with settings {hosts=[localhost:27017], mode=SINGLE, requiredClusterType=UNKNOWN, serverSelectionTimeout='30000 ms', maxWaitQueueSize=500} 2024-05-08 16:11:43.392 INFO 12654 --- [localhost:27017] org.mongodb.driver.connection : Opened connection [connectionId{localValue:1}] to localhost:27017 2024-05-08 16:11:43.400 INFO 12654 --- [localhost:27017] org.mongodb.driver.cluster : Monitor thread successfully connected to server with description ServerDescription{address=localhost:27017, type=STANDALONE, state=CONNECTED, ok=true, version=ServerVersion{versionList=[7, 0, 8]}, minWireVersion=0, maxWireVersion=21, maxDocumentSize=16777216, logicalSessionTimeoutMinutes=30, roundTripTimeNanos=5843585} 2024-05-08 16:11:44.586 INFO 12654 --- [ main] o.s.s.concurrent.ThreadPoolTaskExecutor : Initializing ExecutorService 'applicationTaskExecutor' 2024-05-08 16:11:44.807 INFO 12654 --- [ main] o.s.b.a.w.s.WelcomePageHandlerMapping : Adding welcome page template: index 2024-05-08 16:11:45.575 INFO 12654 --- [ main] o.s.b.a.e.web.EndpointLinksResolver : Exposing 2 endpoint(s) beneath base path '\/actuator' 2024-05-08 16:11:45.644 INFO 12654 --- [ main] i.l.knote.KnoteJavaApplicationTests : Started KnoteJavaApplicationTests in 5.856 seconds (JVM running for 7.008) [INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 7.009 s - in io.learnk8s.knote.KnoteJavaApplicationTests 2024-05-08 16:11:46.135 INFO 12654 --- [ Thread-1] o.s.s.concurrent.ThreadPoolTaskExecutor : Shutting down ExecutorService 'applicationTaskExecutor' [INFO] [INFO] Results: [INFO] [INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0 [INFO] [INFO] [INFO] --- maven-jar-plugin:3.1.2:jar (default-jar) @ knote-java --- [INFO] Building jar: \/Users\/donbuddenbaum\/Documents\/knote-java\/01\/target\/knote-java-1.0.0.jar [INFO] [INFO] --- spring-boot-maven-plugin:2.1.6.RELEASE:repackage (repackage) @ knote-java --- [INFO] Replacing main artifact with repackaged archive [INFO] [INFO] --- maven-install-plugin:2.5.2:install (default-install) @ knote-java --- [INFO] Installing \/Users\/donbuddenbaum\/Documents\/knote-java\/01\/target\/knote-java-1.0.0.jar to \/Users\/donbuddenbaum\/.m2\/repository\/io\/learnk8s\/knote-java\/1.0.0\/knote-java-1.0.0.jar [INFO] Installing \/Users\/donbuddenbaum\/Documents\/knote-java\/01\/pom.xml to \/Users\/donbuddenbaum\/.m2\/repository\/io\/learnk8s\/knote-java\/1.0.0\/knote-java-1.0.0.pom [INFO] [INFO] &gt;&gt;&gt; spring-boot-maven-plugin:2.1.6.RELEASE:run (default-cli) &gt; test-compile @ knote-java &gt;&gt;&gt; [INFO] [INFO] --- maven-resources-plugin:3.1.0:resources (default-resources) @ knote-java --- [INFO] Using 'UTF-8' encoding to copy filtered resources. [INFO] Copying 1 resource [INFO] Copying 2 resources [INFO] [INFO] --- maven-compiler-plugin:3.8.1:compile (default-compile) @ knote-java --- [INFO] Changes detected - recompiling the module! [INFO] Compiling 1 source file to \/Users\/donbuddenbaum\/Documents\/knote-java\/01\/target\/classes [INFO] [INFO] --- maven-resources-plugin:3.1.0:testResources (default-testResources) @ knote-java --- [INFO] Using 'UTF-8' encoding to copy filtered resources. [INFO] skip non existing resourceDirectory \/Users\/donbuddenbaum\/Documents\/knote-java\/01\/src\/test\/resources [INFO] [INFO] --- maven-compiler-plugin:3.8.1:testCompile (default-testCompile) @ knote-java --- [INFO] Changes detected - recompiling the module! [INFO] Compiling 1 source file to \/Users\/donbuddenbaum\/Documents\/knote-java\/01\/target\/test-classes [INFO] [INFO] &lt;&lt;&lt; spring-boot-maven-plugin:2.1.6.RELEASE:run (default-cli) &lt; test-compile @ knote-java &lt;&lt;&lt; [INFO] [INFO] [INFO] --- spring-boot-maven-plugin:2.1.6.RELEASE:run (default-cli) @ knote-java --- . ____ _ __ _ _ \/\\\\ \/ ___'_ __ _ _(_)_ __ __ _ \\ \\ \\ \\ ( ( )\\___ | '_ | '_| | '_ \\\/ _` | \\ \\ \\ \\ \\\\\/ ___)| |_)| | | | | || (_| | ) ) ) ) ' |____| .__|_| |_|_| |_\\__, | \/ \/ \/ \/ =========|_|==============|___\/=\/_\/_\/_\/ :: Spring Boot :: (v2.1.6.RELEASE) 2024-05-08 16:11:49.937 INFO 12626 --- [ main] io.learnk8s.knote.KnoteJavaApplication : Starting KnoteJavaApplication on donbs-imac.local with PID 12626 (\/Users\/donbuddenbaum\/Documents\/knote-java\/01\/target\/classes started by donbuddenbaum in \/Users\/donbuddenbaum\/Documents\/knote-java\/01) 2024-05-08 16:11:49.941 INFO 12626 --- [ main] io.learnk8s.knote.KnoteJavaApplication : No active profile set, falling back to default profiles: default 2024-05-08 16:11:51.017 INFO 12626 --- [ main] .s.d.r.c.RepositoryConfigurationDelegate : Bootstrapping Spring Data repositories in DEFAULT mode. 2024-05-08 16:11:51.090 INFO 12626 --- [ main] .s.d.r.c.RepositoryConfigurationDelegate : Finished Spring Data repository scanning in 66ms. Found 1 repository interfaces. 2024-05-08 16:11:51.909 INFO 12626 --- [ main] o.s.b.w.embedded.tomcat.TomcatWebServer : Tomcat initialized with port(s): 8080 (http) 2024-05-08 16:11:51.968 INFO 12626 --- [ main] o.apache.catalina.core.StandardService : Starting service [Tomcat] 2024-05-08 16:11:51.969 INFO 12626 --- [ main] org.apache.catalina.core.StandardEngine : Starting Servlet engine: [Apache Tomcat\/9.0.21] 2024-05-08 16:11:52.089 INFO 12626 --- [ main] o.a.c.c.C.[Tomcat].[localhost].[\/] : Initializing Spring embedded WebApplicationContext 2024-05-08 16:11:52.089 INFO 12626 --- [ main] o.s.web.context.ContextLoader : Root WebApplicationContext: initialization completed in 2087 ms 2024-05-08 16:11:52.655 INFO 12626 --- [ main] org.mongodb.driver.cluster : Cluster created with settings {hosts=[localhost:27017], mode=SINGLE, requiredClusterType=UNKNOWN, serverSelectionTimeout='30000 ms', maxWaitQueueSize=500} 2024-05-08 16:11:52.767 INFO 12626 --- [localhost:27017] org.mongodb.driver.connection : Opened connection [connectionId{localValue:1}] to localhost:27017 2024-05-08 16:11:52.774 INFO 12626 --- [localhost:27017] org.mongodb.driver.cluster : Monitor thread successfully connected to server with description ServerDescription{address=localhost:27017, type=STANDALONE, state=CONNECTED, ok=true, version=ServerVersion{versionList=[7, 0, 8]}, minWireVersion=0, maxWireVersion=21, maxDocumentSize=16777216, logicalSessionTimeoutMinutes=30, roundTripTimeNanos=4322891} 2024-05-08 16:11:53.549 INFO 12626 --- [ main] o.s.s.concurrent.ThreadPoolTaskExecutor : Initializing ExecutorService 'applicationTaskExecutor' 2024-05-08 16:11:53.729 INFO 12626 --- [ main] o.s.b.a.w.s.WelcomePageHandlerMapping : Adding welcome page template: index 2024-05-08 16:11:54.098 INFO 12626 --- [ main] o.s.b.a.e.web.EndpointLinksResolver : Exposing 2 endpoint(s) beneath base path '\/actuator' 2024-05-08 16:11:54.222 INFO 12626 --- [ main] o.s.b.w.embedded.tomcat.TomcatWebServer : Tomcat started on port(s): 8080 (http) with context path '' 2024-05-08 16:11:54.226 INFO 12626 --- [ main] io.learnk8s.knote.KnoteJavaApplication : Started KnoteJavaApplication in 4.672 seconds (JVM running for 23.813) 2024-05-08 16:12:24.421 INFO 12626 --- [nio-8080-exec-1] o.a.c.c.C.[Tomcat].[localhost].[\/] : Initializing Spring DispatcherServlet 'dispatcherServlet' 2024-05-08 16:12:24.421 INFO 12626 --- [nio-8080-exec-1] o.s.web.servlet.DispatcherServlet : Initializing Servlet 'dispatcherServlet' 2024-05-08 16:12:24.437 INFO 12626 --- [nio-8080-exec-1] o.s.web.servlet.DispatcherServlet : Completed initialization in 16 ms 2024-05-08 16:12:24.575 INFO 12626 --- [nio-8080-exec-1] org.mongodb.driver.connection : Opened connection [connectionId{localValue:2}] to localhost:27017 ##( 05\/09\/24@ 5:18PM )( donbuddenbaum@donbs-imac ):~\/Documents\/knote-java\/02@master\u2717\u2717\u2717 docker build -t knote-java . [+] Building 23.2s (9\/9) FINISHED docker:desktop-linux =&gt; [internal] load build definition from Dockerfile 0.1s =&gt; =&gt; transferring dockerfile: 188B 0.0s =&gt; [internal] load metadata for docker.io\/adoptopenjdk\/openjdk11:jdk-11.0.2.9-slim 1.1s =&gt; [auth] adoptopenjdk\/openjdk11:pull token for registry-1.docker.io 0.0s =&gt; [internal] load .dockerignore 0.0s =&gt; =&gt; transferring context: 2B 0.0s =&gt; [internal] load build context 0.8s =&gt; =&gt; transferring context: 26.93MB 0.8s =&gt; [1\/3] FROM docker.io\/adoptopenjdk\/openjdk11:jdk-11.0.2.9-slim@sha256:f08341ea88e6dfae4a8ded768941574ead9b6794730f55afb8f54fe4bf7c1366 19.9s =&gt; =&gt; resolve docker.io\/adoptopenjdk\/openjdk11:jdk-11.0.2.9-slim@sha256:f08341ea88e6dfae4a8ded768941574ead9b6794730f55afb8f54fe4bf7c1366 0.0s =&gt; =&gt; sha256:f08341ea88e6dfae4a8ded768941574ead9b6794730f55afb8f54fe4bf7c1366 1.36kB \/ 1.36kB 0.0s =&gt; =&gt; sha256:69b6516a1bb3c148c6c85f01dbf948d507190dcc5ccacca63335e8af63ea50da 1.40kB \/ 1.40kB 0.0s =&gt; =&gt; sha256:9a223081d1a1b0b6b0f135a911e42dacc2573f4e9abeefff5634e2cf42877fa9 6.96kB \/ 6.96kB 0.0s =&gt; =&gt; sha256:898c46f3b1a1f39827ed135f020c32e2038c87ae0690a8fe73d94e5df9e6a2d6 32.47MB \/ 32.47MB 5.7s =&gt; =&gt; sha256:63366dfa0a5076458e37ebae948bc7823bab256ca27e09ab94d298e37df4c2a3 851B \/ 851B 0.1s =&gt; =&gt; sha256:041d4cd74a929bc4b66ee955ab5b229de098fa389d1a1fb9565e536d8878e15f 545B \/ 545B 0.2s =&gt; =&gt; sha256:8fb802d85d6035613dd0a630fbdb918b3eaf76c9dc920c2aa77ccca537b0121d 8.81MB \/ 8.81MB 3.0s =&gt; =&gt; sha256:6e1bee0f8701f0ae53a5129dc82115967ae36faa30d7701b195dfc6ec317a51d 162B \/ 162B 0.3s =&gt; =&gt; sha256:08a0d02a4ea8b9d7d36cdcb90325c5b3b8ebe76fe091c71d9786474ba544646e 4.74kB \/ 4.74kB 0.6s =&gt; =&gt; sha256:ae546bb81870d0906e710d6ffd7179f802580de1c654dca3e8cb0ef4db998253 121.40MB \/ 121.40MB 15.2s =&gt; =&gt; extracting sha256:898c46f3b1a1f39827ed135f020c32e2038c87ae0690a8fe73d94e5df9e6a2d6 6.1s =&gt; =&gt; extracting sha256:63366dfa0a5076458e37ebae948bc7823bab256ca27e09ab94d298e37df4c2a3 0.0s =&gt; =&gt; extracting sha256:041d4cd74a929bc4b66ee955ab5b229de098fa389d1a1fb9565e536d8878e15f 0.0s =&gt; =&gt; extracting sha256:6e1bee0f8701f0ae53a5129dc82115967ae36faa30d7701b195dfc6ec317a51d 0.0s =&gt; =&gt; extracting sha256:8fb802d85d6035613dd0a630fbdb918b3eaf76c9dc920c2aa77ccca537b0121d 1.7s =&gt; =&gt; extracting sha256:08a0d02a4ea8b9d7d36cdcb90325c5b3b8ebe76fe091c71d9786474ba544646e 0.0s =&gt; =&gt; extracting sha256:ae546bb81870d0906e710d6ffd7179f802580de1c654dca3e8cb0ef4db998253 4.5s =&gt; [2\/3] COPY target\/*.jar \/opt\/app.jar 1.5s =&gt; [3\/3] WORKDIR \/opt 0.0s =&gt; exporting to image 0.3s =&gt; =&gt; exporting layers 0.3s =&gt; =&gt; writing image sha256:6bae88c7592ecf78844ab3cc85a141b3fe5ba3cd5bc529100080a75c79a24f54 0.0s =&gt; =&gt; naming to docker.io\/library\/knote-java 0.0s What's Next? View a summary of image vulnerabilities and recommendations \u2192 docker scout quickview ##( 05\/09\/24@ 5:21PM )( donbuddenbaum@donbs-imac ):~\/Documents\/knote-java\/02@master\u2717\u2717\u2717 docker images REPOSITORY TAG IMAGE ID CREATED SIZE knote-java latest 6bae88c7592e 43 seconds ago 385MB #Run knote in a Docker Network ##( 05\/09\/24@ 5:21PM )( donbuddenbaum@donbs-imac ):~\/Documents\/knote-java\/02@master\u2717\u2717\u2717 docker network create knote 59989d228459bd1c73a0ba0446517014338423950e52a1a71031314cf6ca7ac8 ##( 05\/09\/24@ 5:25PM )( donbuddenbaum@donbs-imac ):~\/Documents\/knote-java\/02@master\u2717\u2717\u2717 docker run \u2013name=mongo \u2013rm \u2013network=knote mongo ##( 05\/09\/24@ 5:31PM )( donbuddenbaum@donbs-imac ):~ docker run \u2013name=knote-java \u2013rm \u2013network=knote -p 8080:8080 -e MONGO_URL=mongodb:\/\/mongo:27017\/dev knote-java Picked up JAVA_TOOL_OPTIONS: . ____ _ __ _ _ \/\\\\ \/ ___'_ __ _ _(_)_ __ __ _ \\ \\ \\ \\ ( ( )\\___ | '_ | '_| | '_ \\\/ _` | \\ \\ \\ \\ \\\\\/ ___)| |_)| | | | | || (_| | ) ) ) ) ' |____| .__|_| |_|_| |_\\__, | \/ \/ \/ \/ =========|_|==============|___\/=\/_\/_\/_\/ :: Spring Boot :: (v2.1.6.RELEASE) 2024-05-09 21:32:00.954 INFO 1 --- [ main] io.learnk8s.knote.KnoteJavaApplication : Starting KnoteJavaApplication v1.0.0 on d91fbed43ec5 with PID 1 (\/opt\/app.jar started by root in \/opt) 2024-05-09 21:32:00.959 INFO 1 --- [ main] io.learnk8s.knote.KnoteJavaApplication : No active profile set, falling back to default profiles: default 2024-05-09 21:32:02.548 INFO 1 --- [ main] .s.d.r.c.RepositoryConfigurationDelegate : Bootstrapping Spring Data repositories in DEFAULT mode. 2024-05-09 21:32:02.651 INFO 1 --- [ main] .s.d.r.c.RepositoryConfigurationDelegate : Finished Spring Data repository scanning in 92ms. Found 1 repository interfaces. 2024-05-09 21:32:04.066 INFO 1 --- [ main] o.s.b.w.embedded.tomcat.TomcatWebServer : Tomcat initialized with port(s): 8080 (http) 2024-05-09 21:32:04.139 INFO 1 --- [ main] o.apache.catalina.core.StandardService : Starting service [Tomcat] 2024-05-09 21:32:04.140 INFO 1 --- [ main] org.apache.catalina.core.StandardEngine : Starting Servlet engine: [Apache Tomcat\/9.0.21] 2024-05-09 21:32:04.284 INFO 1 --- [ main] o.a.c.c.C.[Tomcat].[localhost].[\/] : Initializing Spring embedded WebApplicationContext 2024-05-09 21:32:04.284 INFO 1 --- [ main] o.s.web.context.ContextLoader : Root WebApplicationContext: initialization completed in 3236 ms 2024-05-09 21:32:05.006 INFO 1 --- [ main] org.mongodb.driver.cluster : Cluster created with settings {hosts=[mongo:27017], mode=SINGLE, requiredClusterType=UNKNOWN, serverSelectionTimeout='30000 ms', maxWaitQueueSize=500} 2024-05-09 21:32:05.156 INFO 1 --- [l'}-mongo:27017] org.mongodb.driver.connection : Opened connection [connectionId{localValue:1}] to mongo:27017 2024-05-09 21:32:05.167 INFO 1 --- [l'}-mongo:27017] org.mongodb.driver.cluster : Monitor thread successfully connected to server with description ServerDescription{address=mongo:27017, type=STANDALONE, state=CONNECTED, ok=true, version=ServerVersion{versionList=[7, 0, 9]}, minWireVersion=0, maxWireVersion=21, maxDocumentSize=16777216, logicalSessionTimeoutMinutes=30, roundTripTimeNanos=7128081} 2024-05-09 21:32:06.073 INFO 1 --- [ main] o.s.s.concurrent.ThreadPoolTaskExecutor : Initializing ExecutorService 'applicationTaskExecutor' 2024-05-09 21:32:06.312 INFO 1 --- [ main] o.s.b.a.w.s.WelcomePageHandlerMapping : Adding welcome page template: index 2024-05-09 21:32:06.897 INFO 1 --- [ main] o.s.b.a.e.web.EndpointLinksResolver : Exposing 2 endpoint(s) beneath base path '\/actuator' 2024-05-09 21:32:07.035 INFO 1 --- [ main] o.s.b.w.embedded.tomcat.TomcatWebServer : Tomcat started on port(s): 8080 (http) with context path '' 2024-05-09 21:32:07.042 INFO 1 --- [ main] io.learnk8s.knote.KnoteJavaApplication : Started KnoteJavaApplication in 7.355 seconds (JVM running for 8.484) ##( 05\/09\/24@ 5:35PM )( donbuddenbaum@donbs-imac ):~ docker ps CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES d91fbed43ec5 knote-java &quot;\/bin\/sh -c 'exec ja\u2026&quot; 3 minutes ago Up 3 minutes 0.0.0.0:8080-&gt;8080\/tcp knote-java 518f46eebf77 mongo &quot;docker-entrypoint.s\u2026&quot; 8 minutes ago Up 8 minutes 27017\/tcp mongo ##( 05\/09\/24@ 5:35PM )( donbuddenbaum@donbs-imac ):~ docker stop mongo knote-java mongo knote-java ##( 05\/09\/24@ 5:38PM )( donbuddenbaum@donbs-imac ):~ docker ps CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 80c2cf8b2964 moby\/buildkit:buildx-stable-1 &quot;buildkitd --allow-i\u2026&quot; 11 days ago Up 31 minutes buildx_buildkit_amazing_robinson0 86883f4b5ca1 moby\/buildkit:buildx-stable-1 &quot;buildkitd --allow-i\u2026&quot; 11 days ago Up 31 minutes buildx_buildkit_thirsty_kare0 ee3de8ed0ec8 moby\/buildkit:buildx-stable-1 &quot;buildkitd --allow-i\u2026&quot; 11 days ago Up 31 minutes buildx_buildkit_adoring_heisenberg0 ##( 05\/09\/24@ 5:41PM )( donbuddenbaum@donbs-imac ):~ docker tag knote-java donb4iu\/knote-java:1.0.0 ##( 05\/09\/24@ 5:42PM )( donbuddenbaum@donbs-imac ):~ docker push donb4iu\/knote-java:1.0.0 The push refers to repository [docker.io\/donb4iu\/knote-java] 5f70bf18a086: Mounted from donb4iu\/http-fhir-server 4420e06dee4d: Pushed 8b338a10df53: Mounted from adoptopenjdk\/openjdk11 238b684bbac1: Mounted from adoptopenjdk\/openjdk11 faed2c48e448: Mounted from adoptopenjdk\/openjdk11 b57c79f4a9f3: Mounted from adoptopenjdk\/openjdk11 d60e01b37e74: Mounted from adoptopenjdk\/openjdk11 e45cfbc98a50: Mounted from adoptopenjdk\/openjdk11 762d8e1a6054: Mounted from adoptopenjdk\/openjdk11 1.0.0: digest: sha256:4cc667b809d23e8e9eb7f583c1a6f5b3af1db451c649b2502f8b7d2ed9fce588 size: 2200 #Docker Buiild Multi-Arch (AMD64\/ARM64) ##( 05\/09\/24@ 5:43PM )( donbuddenbaum@donbs-imac ):~ docker buildx create \u2013use epic_nightingale ##( 05\/09\/24@ 5:50PM )( donbuddenbaum@donbs-imac ):~ docker buildx build \u2013platform linux\/amd64,linux\/arm64 -t donb4iu\/knote-java:1.0.1 \u2013push . #( 05\/09\/24@ 5:53PM )( donbuddenbaum@donbs-imac ):~\/Documents\/knote-java\/02@master\u2717\u2717\u2717 docker buildx build --platform linux\/amd64,linux\/arm64 -t donb4iu\/knote-java:1.0.1 --push . [+] Building 113.2s (14\/14) FINISHED docker-container:epic_nightingale =&gt; [internal] load build definition from Dockerfile 0.0s =&gt; =&gt; transferring dockerfile: 188B 0.0s =&gt; [linux\/arm64 internal] load metadata for docker.io\/adoptopenjdk\/openjdk11:jdk-11.0.2.9-slim 1.6s =&gt; [linux\/amd64 internal] load metadata for docker.io\/adoptopenjdk\/openjdk11:jdk-11.0.2.9-slim 1.4s =&gt; [auth] adoptopenjdk\/openjdk11:pull token for registry-1.docker.io 0.0s =&gt; [internal] load .dockerignore 0.0s =&gt; =&gt; transferring context: 2B 0.0s =&gt; [internal] load build context 0.7s =&gt; =&gt; transferring context: 26.93MB 0.7s =&gt; [linux\/arm64 1\/3] FROM docker.io\/adoptopenjdk\/openjdk11:jdk-11.0.2.9-slim@sha256:f08341ea88e6dfae4a8ded768941574ead9b6794730f55afb8f54fe4bf7c1 31.9s =&gt; =&gt; resolve docker.io\/adoptopenjdk\/openjdk11:jdk-11.0.2.9-slim@sha256:f08341ea88e6dfae4a8ded768941574ead9b6794730f55afb8f54fe4bf7c1366 0.0s =&gt; =&gt; sha256:678b0ab60501b302a29b8aa6422edd85cefb694319e91cdbf61c06bf301135f2 119.85MB \/ 119.85MB 27.5s =&gt; =&gt; sha256:27672abf9edd1c23435c5bb863d55987a882c8491a7578c835346bede19488e2 8.65MB \/ 8.65MB 2.6s =&gt; =&gt; sha256:4d100ec154332f0aa9763dcb5e81a03b45789e7cb556d1c17d6f019ffed0ed29 4.73kB \/ 4.73kB 0.7s =&gt; =&gt; sha256:fc001299f62009a0d8ce4d3efaeaddbb8278bcb7de2fd80ab535fae4f507398f 163B \/ 163B 0.3s =&gt; =&gt; sha256:7e9f0564ef6f85c4690ca0b4ba7acd052790741b6e093c7376b23897e091c8d9 500B \/ 500B 0.4s =&gt; =&gt; sha256:9ef5b901d87c92303900ea484d10726d49c67c4e9fca99625086524c27c93025 29.11MB \/ 29.11MB 10.3s =&gt; =&gt; sha256:3daad4f910663d8404cbac98eed8f6332e7c5c4f9bd509f604f5b32f032d8f9a 849B \/ 849B 0.7s =&gt; =&gt; extracting sha256:9ef5b901d87c92303900ea484d10726d49c67c4e9fca99625086524c27c93025 3.2s =&gt; =&gt; extracting sha256:3daad4f910663d8404cbac98eed8f6332e7c5c4f9bd509f604f5b32f032d8f9a 0.0s =&gt; =&gt; extracting sha256:7e9f0564ef6f85c4690ca0b4ba7acd052790741b6e093c7376b23897e091c8d9 0.0s =&gt; =&gt; extracting sha256:fc001299f62009a0d8ce4d3efaeaddbb8278bcb7de2fd80ab535fae4f507398f 0.0s =&gt; =&gt; extracting sha256:27672abf9edd1c23435c5bb863d55987a882c8491a7578c835346bede19488e2 1.2s =&gt; =&gt; extracting sha256:4d100ec154332f0aa9763dcb5e81a03b45789e7cb556d1c17d6f019ffed0ed29 0.0s =&gt; =&gt; extracting sha256:678b0ab60501b302a29b8aa6422edd85cefb694319e91cdbf61c06bf301135f2 4.0s =&gt; [linux\/amd64 1\/3] FROM docker.io\/adoptopenjdk\/openjdk11:jdk-11.0.2.9-slim@sha256:f08341ea88e6dfae4a8ded768941574ead9b6794730f55afb8f54fe4bf7c1 33.9s =&gt; =&gt; resolve docker.io\/adoptopenjdk\/openjdk11:jdk-11.0.2.9-slim@sha256:f08341ea88e6dfae4a8ded768941574ead9b6794730f55afb8f54fe4bf7c1366 0.0s =&gt; =&gt; sha256:ae546bb81870d0906e710d6ffd7179f802580de1c654dca3e8cb0ef4db998253 121.40MB \/ 121.40MB 27.6s =&gt; =&gt; sha256:08a0d02a4ea8b9d7d36cdcb90325c5b3b8ebe76fe091c71d9786474ba544646e 4.74kB \/ 4.74kB 0.2s =&gt; =&gt; sha256:8fb802d85d6035613dd0a630fbdb918b3eaf76c9dc920c2aa77ccca537b0121d 8.81MB \/ 8.81MB 3.8s =&gt; =&gt; sha256:6e1bee0f8701f0ae53a5129dc82115967ae36faa30d7701b195dfc6ec317a51d 162B \/ 162B 0.1s =&gt; =&gt; sha256:041d4cd74a929bc4b66ee955ab5b229de098fa389d1a1fb9565e536d8878e15f 545B \/ 545B 0.1s =&gt; =&gt; sha256:898c46f3b1a1f39827ed135f020c32e2038c87ae0690a8fe73d94e5df9e6a2d6 32.47MB \/ 32.47MB 11.7s =&gt; =&gt; sha256:63366dfa0a5076458e37ebae948bc7823bab256ca27e09ab94d298e37df4c2a3 851B \/ 851B 0.2s =&gt; =&gt; extracting sha256:898c46f3b1a1f39827ed135f020c32e2038c87ae0690a8fe73d94e5df9e6a2d6 3.0s =&gt; =&gt; extracting sha256:63366dfa0a5076458e37ebae948bc7823bab256ca27e09ab94d298e37df4c2a3 0.0s =&gt; =&gt; extracting sha256:041d4cd74a929bc4b66ee955ab5b229de098fa389d1a1fb9565e536d8878e15f 0.0s =&gt; =&gt; extracting sha256:6e1bee0f8701f0ae53a5129dc82115967ae36faa30d7701b195dfc6ec317a51d 0.0s =&gt; =&gt; extracting sha256:8fb802d85d6035613dd0a630fbdb918b3eaf76c9dc920c2aa77ccca537b0121d 0.8s =&gt; =&gt; extracting sha256:08a0d02a4ea8b9d7d36cdcb90325c5b3b8ebe76fe091c71d9786474ba544646e 0.0s =&gt; =&gt; extracting sha256:ae546bb81870d0906e710d6ffd7179f802580de1c654dca3e8cb0ef4db998253 4.4s =&gt; [linux\/arm64 2\/3] COPY target\/*.jar \/opt\/app.jar 1.9s =&gt; [linux\/amd64 2\/3] COPY target\/*.jar \/opt\/app.jar 0.3s =&gt; [linux\/arm64 3\/3] WORKDIR \/opt 0.2s =&gt; [linux\/amd64 3\/3] WORKDIR \/opt 0.0s =&gt; exporting to image 77.3s =&gt; =&gt; exporting layers 1.5s =&gt; =&gt; exporting manifest sha256:7a1b33612ce01218d9ebaa9750981e9269ce756bcfdd1634d7e922f079c87433 0.0s =&gt; =&gt; exporting config sha256:a8149a14d4ca96271086f51bc99e173defac90881d2b50067d594c3d85c44411 0.0s =&gt; =&gt; exporting attestation manifest sha256:09f18e007c8276ff02e89bf17a1e154db8500616692597502028b5099d116b69 0.0s =&gt; =&gt; exporting manifest sha256:73f769810c6a9b75f3e038687753e8e6694c0ce170797c8f4e3b9ffe5eb826af 0.0s =&gt; =&gt; exporting config sha256:6a73ec697812d9248d2c9a330ab1107366d329fdff66b55c30fae452dcc3625c 0.0s =&gt; =&gt; exporting attestation manifest sha256:26ade3197d97c83b1240573656bd3fafe5a7d097ac6f33a8e4fbdbb934e83ab6 0.0s =&gt; =&gt; exporting manifest list sha256:b456d2006a26023d1a3698cce1a62eb5a403884dd145faba9c5351eea441cb1b 0.0s =&gt; =&gt; pushing layers 74.2s =&gt; =&gt; pushing manifest for docker.io\/donb4iu\/knote-java:1.0.1@sha256:b456d2006a26023d1a3698cce1a62eb5a403884dd145faba9c5351eea441cb1b 1.4s =&gt; [auth] donb4iu\/knote-java:pull,push token for registry-1.docker.io 0.0s Build multi-platform images faster with Docker Build Cloud: https:\/\/docs.docker.com\/go\/docker-build-cloud #MicroK8s Deployment Stateful - NFS ##( 05\/10\/24@ 8:57PM )( donbuddenbaum@donbs-imac ):~\/Documents\/Kalaxy2\/yaml\/knotes@main\u2717\u2717\u2717 kubectl apply -f ns.yaml namespace\/knote configured ##( 05\/10\/24@ 9:26PM )( donbuddenbaum@donbs-imac ):~\/Documents\/Kalaxy2\/yaml\/knotes@main\u2717\u2717\u2717 kubectl apply -f knote.yaml deployment.apps\/knote created service\/knote created ##( 05\/10\/24@ 9:32PM )( donbuddenbaum@donbs-imac ):~\/Documents\/Kalaxy2\/yaml\/knotes@main\u2717\u2717\u2717 kubectl apply -f mongo.yaml persistentvolumeclaim\/mongo-pvc created service\/mongo created deployment.apps\/mongo created #( 05\/10\/24@ 9:39PM )( donbuddenbaum@donbs-imac ):~\/Documents\/Kalaxy2\/yaml\/knotes@main\u2717\u2717\u2717 #Build &amp; Test Minio ##( 05\/10\/24@ 9:51PM )( donbuddenbaum@donbs-imac ):~\/Documents\/Kalaxy2\/yaml\/knotes\/nfs@main\u2717\u2717\u2717 docker run \u2013name=minio \u2013rm -p 9000:9000 -e MINIO_ACCESS_KEY=mykey -e MINIO_SECRET_KEY=mysecret minio\/minio server \/data Unable to find image 'minio\/minio:latest' locally latest: Pulling from minio\/minio ddf997398e20: Pull complete df4a579dec01: Pull complete 8192a80982f2: Pull complete 362c568d646c: Pull complete f1d1ac67109d: Pull complete 6722841456ff: Pull complete d5b199683645: Pull complete 4b0d9e6819e5: Pull complete Digest: sha256:420663b8685c5396f06405ad516d611db4465939a141cc7d40266342d0f2632d Status: Downloaded newer image for minio\/minio:latest WARNING: MINIO_ACCESS_KEY and MINIO_SECRET_KEY are deprecated. Please use MINIO_ROOT_USER and MINIO_ROOT_PASSWORD Formatting 1st pool, 1 set(s), 1 drives per set. WARNING: Host local has more than 0 drives of set. A host failure will result in data becoming unavailable. MinIO Object Storage Server Copyright: 2015-2024 MinIO, Inc. License: GNU AGPLv3 - https:\/\/www.gnu.org\/licenses\/agpl-3.0.html Version: RELEASE.2024-05-10T01-41-38Z (go1.22.3 linux\/amd64) API: http:\/\/172.17.0.2:9000 http:\/\/127.0.0.1:9000 WebUI: http:\/\/172.17.0.2:36159 http:\/\/127.0.0.1:36159 Docs: https:\/\/min.io\/docs\/minio\/linux\/index.html Status: 1 Online, 0 Offline. STARTUP WARNINGS: - The standard parity is set to 0. This can lead to data loss. ##( 05\/10\/24@10:22PM )( donbuddenbaum@donbs-imac ):~ docker run \u2013name=mongo \u2013rm -p 27017:27017 mongo {&quot;t&quot;:{&quot;$date&quot;:&quot;2024-05-11T02:22:21.907+00:00&quot;},&quot;s&quot;:&quot;I&quot;, &quot;c&quot;:&quot;CONTROL&quot;, &quot;id&quot;:23285, &quot;ctx&quot;:&quot;main&quot;,&quot;msg&quot;:&quot;Automatically disabling TLS 1.0, to force-enable TLS 1.0 specify --sslDisabledProtocols 'none'&quot;} {&quot;t&quot;:{&quot;$date&quot;:&quot;2024-05-11T02:22:21.908+00:00&quot;},&quot;s&quot;:&quot;I&quot;, &quot;c&quot;:&quot;NETWORK&quot;, &quot;id&quot;:4915701, &quot;ctx&quot;:&quot;main&quot;,&quot;msg&quot;:&quot;Initialized wire specification&quot;,&quot;attr&quot;:{&quot;spec&quot;:{&quot;incomingExternalClient&quot;:{&quot;minWireVersion&quot;:0,&quot;maxWireVersion&quot;:21},&quot;incomingInternalClient&quot;:{&quot;minWireVersion&quot;:0,&quot;maxWireVersion&quot;:21},&quot;outgoing&quot;:{&quot;minWireVersion&quot;:6,&quot;maxWireVersion&quot;:21},&quot;isInternalClient&quot;:true}}} {&quot;t&quot;:{&quot;$date&quot;:&quot;2024-05-11T02:22:21.908+00:00&quot;},&quot;s&quot;:&quot;I&quot;, &quot;c&quot;:&quot;NETWORK&quot;, &quot;id&quot;:4648601, &quot;ctx&quot;:&quot;main&quot;,&quot;msg&quot;:&quot;Implicit TCP FastOpen unavailable. If TCP FastOpen is required, set tcpFastOpenServer, tcpFastOpenClient, and tcpFastOpenQueueSize.&quot;} {&quot;t&quot;:{&quot;$date&quot;:&quot;2024-05-11T02:22:21.911+00:00&quot;},&quot;s&quot;:&quot;I&quot;, &quot;c&quot;:&quot;REPL&quot;, &quot;id&quot;:5123008, &quot;ctx&quot;:&quot;main&quot;,&quot;msg&quot;:&quot;Successfully registered PrimaryOnlyService&quot;,&quot;attr&quot;:{&quot;service&quot;:&quot;TenantMigrationDonorService&quot;,&quot;namespace&quot;:&quot;config.tenantMigrationDonors&quot;}} {&quot;t&quot;:{&quot;$date&quot;:&quot;2024-05-11T02:22:21.911+00:00&quot;},&quot;s&quot;:&quot;I&quot;, &quot;c&quot;:&quot;REPL&quot;, &quot;id&quot;:5123008, &quot;ctx&quot;:&quot;main&quot;,&quot;msg&quot;:&quot;Successfully registered PrimaryOnlyService&quot;,&quot;attr&quot;:{&quot;service&quot;:&quot;TenantMigrationRecipientService&quot;,&quot;namespace&quot;:&quot;config.tenantMigrationRecipients&quot;}} {&quot;t&quot;:{&quot;$date&quot;:&quot;2024-05-11T02:22:21.911+00:00&quot;},&quot;s&quot;:&quot;I&quot;, &quot;c&quot;:&quot;CONTROL&quot;, &quot;id&quot;:5945603, &quot;ctx&quot;:&quot;main&quot;,&quot;msg&quot;:&quot;Multi threading initialized&quot;} {&quot;t&quot;:{&quot;$date&quot;:&quot;2024-05-11T02:22:21.911+00:00&quot;},&quot;s&quot;:&quot;I&quot;, &quot;c&quot;:&quot;TENANT_M&quot;, &quot;id&quot;:7091600, &quot;ctx&quot;:&quot;main&quot;,&quot;msg&quot;:&quot;Starting TenantMigrationAccessBlockerRegistry&quot;} {&quot;t&quot;:{&quot;$date&quot;:&quot;2024-05-11T02:22:21.912+00:00&quot;},&quot;s&quot;:&quot;I&quot;, &quot;c&quot;:&quot;CONTROL&quot;, &quot;id&quot;:4615611, &quot;ctx&quot;:&quot;initandlisten&quot;,&quot;msg&quot;:&quot;MongoDB starting&quot;,&quot;attr&quot;:{&quot;pid&quot;:1,&quot;port&quot;:27017,&quot;dbPath&quot;:&quot;\/data\/db&quot;,&quot;architecture&quot;:&quot;64-bit&quot;,&quot;host&quot;:&quot;8a2d983b4624&quot;}} {&quot;t&quot;:{&quot;$date&quot;:&quot;2024-05-11T02:22:21.912+00:00&quot;},&quot;s&quot;:&quot;I&quot;, &quot;c&quot;:&quot;CONTROL&quot;, &quot;id&quot;:23403, &quot;ctx&quot;:&quot;initandlisten&quot;,&quot;msg&quot;:&quot;Build Info&quot;,&quot;attr&quot;:{&quot;buildInfo&quot;:{&quot;version&quot;:&quot;7.0.9&quot;,&quot;gitVersion&quot;:&quot;3ff3a3925c36ed277cf5eafca5495f2e3728dd67&quot;,&quot;openSSLVersion&quot;:&quot;OpenSSL 3.0.2 15 Mar 2022&quot;,&quot;modules&quot;:[],&quot;allocator&quot;:&quot;tcmalloc&quot;,&quot;environment&quot;:{&quot;distmod&quot;:&quot;ubuntu2204&quot;,&quot;distarch&quot;:&quot;x86_64&quot;,&quot;target_arch&quot;:&quot;x86_64&quot;}}}} {&quot;t&quot;:{&quot;$date&quot;:&quot;2024-05-11T02:22:21.912+00:00&quot;},&quot;s&quot;:&quot;I&quot;, &quot;c&quot;:&quot;CONTROL&quot;, &quot;id&quot;:51765, &quot;ctx&quot;:&quot;initandlisten&quot;,&quot;msg&quot;:&quot;Operating System&quot;,&quot;attr&quot;:{&quot;os&quot;:{&quot;name&quot;:&quot;Ubuntu&quot;,&quot;version&quot;:&quot;22.04&quot;}}} {&quot;t&quot;:{&quot;$date&quot;:&quot;2024-05-11T02:22:21.912+00:00&quot;},&quot;s&quot;:&quot;I&quot;, &quot;c&quot;:&quot;CONTROL&quot;, &quot;id&quot;:21951, &quot;ctx&quot;:&quot;initandlisten&quot;,&quot;msg&quot;:&quot;Options set by command line&quot;,&quot;attr&quot;:{&quot;options&quot;:{&quot;net&quot;:{&quot;bindIp&quot;:&quot;*&quot;}}}} {&quot;t&quot;:{&quot;$date&quot;:&quot;2024-05-11T02:22:21.914+00:00&quot;},&quot;s&quot;:&quot;I&quot;, &quot;c&quot;:&quot;STORAGE&quot;, &quot;id&quot;:22297, &quot;ctx&quot;:&quot;initandlisten&quot;,&quot;msg&quot;:&quot;Using the XFS filesystem is strongly recommended with the WiredTiger storage engine. See http:\/\/dochub.mongodb.org\/core\/prodnotes-filesystem&quot;,&quot;tags&quot;:[&quot;startupWarnings&quot;]} {&quot;t&quot;:{&quot;$date&quot;:&quot;2024-05-11T02:22:21.915+00:00&quot;},&quot;s&quot;:&quot;I&quot;, &quot;c&quot;:&quot;STORAGE&quot;, &quot;id&quot;:22315, &quot;ctx&quot;:&quot;initandlisten&quot;,&quot;msg&quot;:&quot;Opening WiredTiger&quot;,&quot;attr&quot;:{&quot;config&quot;:&quot;create,cache_size=3458M,session_max=33000,eviction=(threads_min=4,threads_max=4),config_base=false,statistics=(fast),log=(enabled=true,remove=true,path=journal,compressor=snappy),builtin_extension_config=(zstd=(compression_level=6)),file_manager=(close_idle_time=600,close_scan_interval=10,close_handle_minimum=2000),statistics_log=(wait=0),json_output=(error,message),verbose=[recovery_progress:1,checkpoint_progress:1,compact_progress:1,backup:0,checkpoint:0,compact:0,evict:0,history_store:0,recovery:0,rts:0,salvage:0,tiered:0,timestamp:0,transaction:0,verify:0,log:0],&quot;}} {&quot;t&quot;:{&quot;$date&quot;:&quot;2024-05-11T02:22:23.058+00:00&quot;},&quot;s&quot;:&quot;I&quot;, &quot;c&quot;:&quot;WTRECOV&quot;, &quot;id&quot;:22430, &quot;ctx&quot;:&quot;initandlisten&quot;,&quot;msg&quot;:&quot;WiredTiger message&quot;,&quot;attr&quot;:{&quot;message&quot;:{&quot;ts_sec&quot;:1715394143,&quot;ts_usec&quot;:58906,&quot;thread&quot;:&quot;1:0x7fdbdfe45c80&quot;,&quot;session_name&quot;:&quot;txn-recover&quot;,&quot;category&quot;:&quot;WT_VERB_RECOVERY_PROGRESS&quot;,&quot;category_id&quot;:30,&quot;verbose_level&quot;:&quot;DEBUG_1&quot;,&quot;verbose_level_id&quot;:1,&quot;msg&quot;:&quot;recovery log replay has successfully finished and ran for 0 milliseconds&quot;}}} {&quot;t&quot;:{&quot;$date&quot;:&quot;2024-05-11T02:22:23.059+00:00&quot;},&quot;s&quot;:&quot;I&quot;, &quot;c&quot;:&quot;WTRECOV&quot;, &quot;id&quot;:22430, &quot;ctx&quot;:&quot;initandlisten&quot;,&quot;msg&quot;:&quot;WiredTiger message&quot;,&quot;attr&quot;:{&quot;message&quot;:{&quot;ts_sec&quot;:1715394143,&quot;ts_usec&quot;:59041,&quot;thread&quot;:&quot;1:0x7fdbdfe45c80&quot;,&quot;session_name&quot;:&quot;txn-recover&quot;,&quot;category&quot;:&quot;WT_VERB_RECOVERY_PROGRESS&quot;,&quot;category_id&quot;:30,&quot;verbose_level&quot;:&quot;DEBUG_1&quot;,&quot;verbose_level_id&quot;:1,&quot;msg&quot;:&quot;Set global recovery timestamp: (0, 0)&quot;}}} {&quot;t&quot;:{&quot;$date&quot;:&quot;2024-05-11T02:22:23.059+00:00&quot;},&quot;s&quot;:&quot;I&quot;, &quot;c&quot;:&quot;WTRECOV&quot;, &quot;id&quot;:22430, &quot;ctx&quot;:&quot;initandlisten&quot;,&quot;msg&quot;:&quot;WiredTiger message&quot;,&quot;attr&quot;:{&quot;message&quot;:{&quot;ts_sec&quot;:1715394143,&quot;ts_usec&quot;:59078,&quot;thread&quot;:&quot;1:0x7fdbdfe45c80&quot;,&quot;session_name&quot;:&quot;txn-recover&quot;,&quot;category&quot;:&quot;WT_VERB_RECOVERY_PROGRESS&quot;,&quot;category_id&quot;:30,&quot;verbose_level&quot;:&quot;DEBUG_1&quot;,&quot;verbose_level_id&quot;:1,&quot;msg&quot;:&quot;Set global oldest timestamp: (0, 0)&quot;}}} {&quot;t&quot;:{&quot;$date&quot;:&quot;2024-05-11T02:22:23.059+00:00&quot;},&quot;s&quot;:&quot;I&quot;, &quot;c&quot;:&quot;WTRECOV&quot;, &quot;id&quot;:22430, &quot;ctx&quot;:&quot;initandlisten&quot;,&quot;msg&quot;:&quot;WiredTiger message&quot;,&quot;attr&quot;:{&quot;message&quot;:{&quot;ts_sec&quot;:1715394143,&quot;ts_usec&quot;:59125,&quot;thread&quot;:&quot;1:0x7fdbdfe45c80&quot;,&quot;session_name&quot;:&quot;txn-recover&quot;,&quot;category&quot;:&quot;WT_VERB_RECOVERY_PROGRESS&quot;,&quot;category_id&quot;:30,&quot;verbose_level&quot;:&quot;DEBUG_1&quot;,&quot;verbose_level_id&quot;:1,&quot;msg&quot;:&quot;recovery was completed successfully and took 0ms, including 0ms for the log replay, 0ms for the rollback to stable, and 0ms for the checkpoint.&quot;}}} {&quot;t&quot;:{&quot;$date&quot;:&quot;2024-05-11T02:22:23.077+00:00&quot;},&quot;s&quot;:&quot;I&quot;, &quot;c&quot;:&quot;STORAGE&quot;, &quot;id&quot;:4795906, &quot;ctx&quot;:&quot;initandlisten&quot;,&quot;msg&quot;:&quot;WiredTiger opened&quot;,&quot;attr&quot;:{&quot;durationMillis&quot;:1162}} {&quot;t&quot;:{&quot;$date&quot;:&quot;2024-05-11T02:22:23.077+00:00&quot;},&quot;s&quot;:&quot;I&quot;, &quot;c&quot;:&quot;RECOVERY&quot;, &quot;id&quot;:23987, &quot;ctx&quot;:&quot;initandlisten&quot;,&quot;msg&quot;:&quot;WiredTiger recoveryTimestamp&quot;,&quot;attr&quot;:{&quot;recoveryTimestamp&quot;:{&quot;$timestamp&quot;:{&quot;t&quot;:0,&quot;i&quot;:0}}}} {&quot;t&quot;:{&quot;$date&quot;:&quot;2024-05-11T02:22:23.108+00:00&quot;},&quot;s&quot;:&quot;W&quot;, &quot;c&quot;:&quot;CONTROL&quot;, &quot;id&quot;:22120, &quot;ctx&quot;:&quot;initandlisten&quot;,&quot;msg&quot;:&quot;Access control is not enabled for the database. Read and write access to data and configuration is unrestricted&quot;,&quot;tags&quot;:[&quot;startupWarnings&quot;]} {&quot;t&quot;:{&quot;$date&quot;:&quot;2024-05-11T02:22:23.109+00:00&quot;},&quot;s&quot;:&quot;W&quot;, &quot;c&quot;:&quot;CONTROL&quot;, &quot;id&quot;:22178, &quot;ctx&quot;:&quot;initandlisten&quot;,&quot;msg&quot;:&quot;\/sys\/kernel\/mm\/transparent_hugepage\/enabled is 'always'. We suggest setting it to 'never' in this binary version&quot;,&quot;tags&quot;:[&quot;startupWarnings&quot;]} {&quot;t&quot;:{&quot;$date&quot;:&quot;2024-05-11T02:22:23.110+00:00&quot;},&quot;s&quot;:&quot;W&quot;, &quot;c&quot;:&quot;CONTROL&quot;, &quot;id&quot;:5123300, &quot;ctx&quot;:&quot;initandlisten&quot;,&quot;msg&quot;:&quot;vm.max_map_count is too low&quot;,&quot;attr&quot;:{&quot;currentValue&quot;:262144,&quot;recommendedMinimum&quot;:1677720,&quot;maxConns&quot;:838860},&quot;tags&quot;:[&quot;startupWarnings&quot;]} {&quot;t&quot;:{&quot;$date&quot;:&quot;2024-05-11T02:22:23.110+00:00&quot;},&quot;s&quot;:&quot;I&quot;, &quot;c&quot;:&quot;STORAGE&quot;, &quot;id&quot;:20320, &quot;ctx&quot;:&quot;initandlisten&quot;,&quot;msg&quot;:&quot;createCollection&quot;,&quot;attr&quot;:{&quot;namespace&quot;:&quot;admin.system.version&quot;,&quot;uuidDisposition&quot;:&quot;provided&quot;,&quot;uuid&quot;:{&quot;uuid&quot;:{&quot;$uuid&quot;:&quot;8346e1e9-61a7-4c8c-abf7-e74a2bb727e0&quot;}},&quot;options&quot;:{&quot;uuid&quot;:{&quot;$uuid&quot;:&quot;8346e1e9-61a7-4c8c-abf7-e74a2bb727e0&quot;}}}} {&quot;t&quot;:{&quot;$date&quot;:&quot;2024-05-11T02:22:23.128+00:00&quot;},&quot;s&quot;:&quot;I&quot;, &quot;c&quot;:&quot;INDEX&quot;, &quot;id&quot;:20345, &quot;ctx&quot;:&quot;initandlisten&quot;,&quot;msg&quot;:&quot;Index build: done building&quot;,&quot;attr&quot;:{&quot;buildUUID&quot;:null,&quot;collectionUUID&quot;:{&quot;uuid&quot;:{&quot;$uuid&quot;:&quot;8346e1e9-61a7-4c8c-abf7-e74a2bb727e0&quot;}},&quot;namespace&quot;:&quot;admin.system.version&quot;,&quot;index&quot;:&quot;_id_&quot;,&quot;ident&quot;:&quot;index-1-2438475259501675333&quot;,&quot;collectionIdent&quot;:&quot;collection-0-2438475259501675333&quot;,&quot;commitTimestamp&quot;:null}} {&quot;t&quot;:{&quot;$date&quot;:&quot;2024-05-11T02:22:23.128+00:00&quot;},&quot;s&quot;:&quot;I&quot;, &quot;c&quot;:&quot;REPL&quot;, &quot;id&quot;:20459, &quot;ctx&quot;:&quot;initandlisten&quot;,&quot;msg&quot;:&quot;Setting featureCompatibilityVersion&quot;,&quot;attr&quot;:{&quot;newVersion&quot;:&quot;7.0&quot;}} {&quot;t&quot;:{&quot;$date&quot;:&quot;2024-05-11T02:22:23.128+00:00&quot;},&quot;s&quot;:&quot;I&quot;, &quot;c&quot;:&quot;REPL&quot;, &quot;id&quot;:5853300, &quot;ctx&quot;:&quot;initandlisten&quot;,&quot;msg&quot;:&quot;current featureCompatibilityVersion value&quot;,&quot;attr&quot;:{&quot;featureCompatibilityVersion&quot;:&quot;7.0&quot;,&quot;context&quot;:&quot;setFCV&quot;}} {&quot;t&quot;:{&quot;$date&quot;:&quot;2024-05-11T02:22:23.128+00:00&quot;},&quot;s&quot;:&quot;I&quot;, &quot;c&quot;:&quot;NETWORK&quot;, &quot;id&quot;:4915702, &quot;ctx&quot;:&quot;initandlisten&quot;,&quot;msg&quot;:&quot;Updated wire specification&quot;,&quot;attr&quot;:{&quot;oldSpec&quot;:{&quot;incomingExternalClient&quot;:{&quot;minWireVersion&quot;:0,&quot;maxWireVersion&quot;:21},&quot;incomingInternalClient&quot;:{&quot;minWireVersion&quot;:0,&quot;maxWireVersion&quot;:21},&quot;outgoing&quot;:{&quot;minWireVersion&quot;:6,&quot;maxWireVersion&quot;:21},&quot;isInternalClient&quot;:true},&quot;newSpec&quot;:{&quot;incomingExternalClient&quot;:{&quot;minWireVersion&quot;:0,&quot;maxWireVersion&quot;:21},&quot;incomingInternalClient&quot;:{&quot;minWireVersion&quot;:21,&quot;maxWireVersion&quot;:21},&quot;outgoing&quot;:{&quot;minWireVersion&quot;:21,&quot;maxWireVersion&quot;:21},&quot;isInternalClient&quot;:true}}} {&quot;t&quot;:{&quot;$date&quot;:&quot;2024-05-11T02:22:23.128+00:00&quot;},&quot;s&quot;:&quot;I&quot;, &quot;c&quot;:&quot;NETWORK&quot;, &quot;id&quot;:4915702, &quot;ctx&quot;:&quot;initandlisten&quot;,&quot;msg&quot;:&quot;Updated wire specification&quot;,&quot;attr&quot;:{&quot;oldSpec&quot;:{&quot;incomingExternalClient&quot;:{&quot;minWireVersion&quot;:0,&quot;maxWireVersion&quot;:21},&quot;incomingInternalClient&quot;:{&quot;minWireVersion&quot;:21,&quot;maxWireVersion&quot;:21},&quot;outgoing&quot;:{&quot;minWireVersion&quot;:21,&quot;maxWireVersion&quot;:21},&quot;isInternalClient&quot;:true},&quot;newSpec&quot;:{&quot;incomingExternalClient&quot;:{&quot;minWireVersion&quot;:0,&quot;maxWireVersion&quot;:21},&quot;incomingInternalClient&quot;:{&quot;minWireVersion&quot;:21,&quot;maxWireVersion&quot;:21},&quot;outgoing&quot;:{&quot;minWireVersion&quot;:21,&quot;maxWireVersion&quot;:21},&quot;isInternalClient&quot;:true}}} {&quot;t&quot;:{&quot;$date&quot;:&quot;2024-05-11T02:22:23.128+00:00&quot;},&quot;s&quot;:&quot;I&quot;, &quot;c&quot;:&quot;REPL&quot;, &quot;id&quot;:5853300, &quot;ctx&quot;:&quot;initandlisten&quot;,&quot;msg&quot;:&quot;current featureCompatibilityVersion value&quot;,&quot;attr&quot;:{&quot;featureCompatibilityVersion&quot;:&quot;7.0&quot;,&quot;context&quot;:&quot;startup&quot;}} {&quot;t&quot;:{&quot;$date&quot;:&quot;2024-05-11T02:22:23.129+00:00&quot;},&quot;s&quot;:&quot;I&quot;, &quot;c&quot;:&quot;STORAGE&quot;, &quot;id&quot;:5071100, &quot;ctx&quot;:&quot;initandlisten&quot;,&quot;msg&quot;:&quot;Clearing temp directory&quot;} {&quot;t&quot;:{&quot;$date&quot;:&quot;2024-05-11T02:22:23.129+00:00&quot;},&quot;s&quot;:&quot;I&quot;, &quot;c&quot;:&quot;CONTROL&quot;, &quot;id&quot;:6608200, &quot;ctx&quot;:&quot;initandlisten&quot;,&quot;msg&quot;:&quot;Initializing cluster server parameters from disk&quot;} {&quot;t&quot;:{&quot;$date&quot;:&quot;2024-05-11T02:22:23.129+00:00&quot;},&quot;s&quot;:&quot;I&quot;, &quot;c&quot;:&quot;CONTROL&quot;, &quot;id&quot;:20536, &quot;ctx&quot;:&quot;initandlisten&quot;,&quot;msg&quot;:&quot;Flow Control is enabled on this deployment&quot;} {&quot;t&quot;:{&quot;$date&quot;:&quot;2024-05-11T02:22:23.131+00:00&quot;},&quot;s&quot;:&quot;I&quot;, &quot;c&quot;:&quot;FTDC&quot;, &quot;id&quot;:20625, &quot;ctx&quot;:&quot;initandlisten&quot;,&quot;msg&quot;:&quot;Initializing full-time diagnostic data capture&quot;,&quot;attr&quot;:{&quot;dataDirectory&quot;:&quot;\/data\/db\/diagnostic.data&quot;}} {&quot;t&quot;:{&quot;$date&quot;:&quot;2024-05-11T02:22:23.134+00:00&quot;},&quot;s&quot;:&quot;I&quot;, &quot;c&quot;:&quot;STORAGE&quot;, &quot;id&quot;:20320, &quot;ctx&quot;:&quot;initandlisten&quot;,&quot;msg&quot;:&quot;createCollection&quot;,&quot;attr&quot;:{&quot;namespace&quot;:&quot;local.startup_log&quot;,&quot;uuidDisposition&quot;:&quot;generated&quot;,&quot;uuid&quot;:{&quot;uuid&quot;:{&quot;$uuid&quot;:&quot;b43a7135-b37c-4d6a-80ce-1df21104c953&quot;}},&quot;options&quot;:{&quot;capped&quot;:true,&quot;size&quot;:10485760}}} {&quot;t&quot;:{&quot;$date&quot;:&quot;2024-05-11T02:22:23.154+00:00&quot;},&quot;s&quot;:&quot;I&quot;, &quot;c&quot;:&quot;INDEX&quot;, &quot;id&quot;:20345, &quot;ctx&quot;:&quot;initandlisten&quot;,&quot;msg&quot;:&quot;Index build: done building&quot;,&quot;attr&quot;:{&quot;buildUUID&quot;:null,&quot;collectionUUID&quot;:{&quot;uuid&quot;:{&quot;$uuid&quot;:&quot;b43a7135-b37c-4d6a-80ce-1df21104c953&quot;}},&quot;namespace&quot;:&quot;local.startup_log&quot;,&quot;index&quot;:&quot;_id_&quot;,&quot;ident&quot;:&quot;index-3-2438475259501675333&quot;,&quot;collectionIdent&quot;:&quot;collection-2-2438475259501675333&quot;,&quot;commitTimestamp&quot;:null}} {&quot;t&quot;:{&quot;$date&quot;:&quot;2024-05-11T02:22:23.155+00:00&quot;},&quot;s&quot;:&quot;I&quot;, &quot;c&quot;:&quot;REPL&quot;, &quot;id&quot;:6015317, &quot;ctx&quot;:&quot;initandlisten&quot;,&quot;msg&quot;:&quot;Setting new configuration state&quot;,&quot;attr&quot;:{&quot;newState&quot;:&quot;ConfigReplicationDisabled&quot;,&quot;oldState&quot;:&quot;ConfigPreStart&quot;}} {&quot;t&quot;:{&quot;$date&quot;:&quot;2024-05-11T02:22:23.155+00:00&quot;},&quot;s&quot;:&quot;I&quot;, &quot;c&quot;:&quot;STORAGE&quot;, &quot;id&quot;:22262, &quot;ctx&quot;:&quot;initandlisten&quot;,&quot;msg&quot;:&quot;Timestamp monitor starting&quot;} {&quot;t&quot;:{&quot;$date&quot;:&quot;2024-05-11T02:22:23.158+00:00&quot;},&quot;s&quot;:&quot;I&quot;, &quot;c&quot;:&quot;STORAGE&quot;, &quot;id&quot;:20320, &quot;ctx&quot;:&quot;LogicalSessionCacheRefresh&quot;,&quot;msg&quot;:&quot;createCollection&quot;,&quot;attr&quot;:{&quot;namespace&quot;:&quot;config.system.sessions&quot;,&quot;uuidDisposition&quot;:&quot;generated&quot;,&quot;uuid&quot;:{&quot;uuid&quot;:{&quot;$uuid&quot;:&quot;d524d7c4-5c73-4c70-a167-20cf99272076&quot;}},&quot;options&quot;:{}}} {&quot;t&quot;:{&quot;$date&quot;:&quot;2024-05-11T02:22:23.158+00:00&quot;},&quot;s&quot;:&quot;I&quot;, &quot;c&quot;:&quot;CONTROL&quot;, &quot;id&quot;:20712, &quot;ctx&quot;:&quot;LogicalSessionCacheReap&quot;,&quot;msg&quot;:&quot;Sessions collection is not set up; waiting until next sessions reap interval&quot;,&quot;attr&quot;:{&quot;error&quot;:&quot;NamespaceNotFound: config.system.sessions does not exist&quot;}} {&quot;t&quot;:{&quot;$date&quot;:&quot;2024-05-11T02:22:23.159+00:00&quot;},&quot;s&quot;:&quot;I&quot;, &quot;c&quot;:&quot;NETWORK&quot;, &quot;id&quot;:23015, &quot;ctx&quot;:&quot;listener&quot;,&quot;msg&quot;:&quot;Listening on&quot;,&quot;attr&quot;:{&quot;address&quot;:&quot;\/tmp\/mongodb-27017.sock&quot;}} {&quot;t&quot;:{&quot;$date&quot;:&quot;2024-05-11T02:22:23.159+00:00&quot;},&quot;s&quot;:&quot;I&quot;, &quot;c&quot;:&quot;NETWORK&quot;, &quot;id&quot;:23015, &quot;ctx&quot;:&quot;listener&quot;,&quot;msg&quot;:&quot;Listening on&quot;,&quot;attr&quot;:{&quot;address&quot;:&quot;0.0.0.0&quot;}} {&quot;t&quot;:{&quot;$date&quot;:&quot;2024-05-11T02:22:23.159+00:00&quot;},&quot;s&quot;:&quot;I&quot;, &quot;c&quot;:&quot;NETWORK&quot;, &quot;id&quot;:23016, &quot;ctx&quot;:&quot;listener&quot;,&quot;msg&quot;:&quot;Waiting for connections&quot;,&quot;attr&quot;:{&quot;port&quot;:27017,&quot;ssl&quot;:&quot;off&quot;}} {&quot;t&quot;:{&quot;$date&quot;:&quot;2024-05-11T02:22:23.159+00:00&quot;},&quot;s&quot;:&quot;I&quot;, &quot;c&quot;:&quot;CONTROL&quot;, &quot;id&quot;:8423403, &quot;ctx&quot;:&quot;initandlisten&quot;,&quot;msg&quot;:&quot;mongod startup complete&quot;,&quot;attr&quot;:{&quot;Summary of time elapsed&quot;:{&quot;Startup from clean shutdown?&quot;:true,&quot;Statistics&quot;:{&quot;Transport layer setup&quot;:&quot;0 ms&quot;,&quot;Run initial syncer crash recovery&quot;:&quot;0 ms&quot;,&quot;Create storage engine lock file in the data directory&quot;:&quot;0 ms&quot;,&quot;Get metadata describing storage engine&quot;:&quot;0 ms&quot;,&quot;Create storage engine&quot;:&quot;1187 ms&quot;,&quot;Write current PID to file&quot;:&quot;0 ms&quot;,&quot;Write a new metadata for storage engine&quot;:&quot;0 ms&quot;,&quot;Initialize FCV before rebuilding indexes&quot;:&quot;0 ms&quot;,&quot;Drop abandoned idents and get back indexes that need to be rebuilt or builds that need to be restarted&quot;:&quot;0 ms&quot;,&quot;Rebuild indexes for collections&quot;:&quot;0 ms&quot;,&quot;Load cluster parameters from disk for a standalone&quot;:&quot;0 ms&quot;,&quot;Build user and roles graph&quot;:&quot;0 ms&quot;,&quot;Set up the background thread pool responsible for waiting for opTimes to be majority committed&quot;:&quot;0 ms&quot;,&quot;Initialize information needed to make a mongod instance shard aware&quot;:&quot;0 ms&quot;,&quot;Start up the replication coordinator&quot;:&quot;1 ms&quot;,&quot;Start transport layer&quot;:&quot;0 ms&quot;,&quot;_initAndListen total elapsed time&quot;:&quot;1247 ms&quot;}}}} {&quot;t&quot;:{&quot;$date&quot;:&quot;2024-05-11T02:22:23.177+00:00&quot;},&quot;s&quot;:&quot;I&quot;, &quot;c&quot;:&quot;REPL&quot;, &quot;id&quot;:7360102, &quot;ctx&quot;:&quot;LogicalSessionCacheRefresh&quot;,&quot;msg&quot;:&quot;Added oplog entry for create to transaction&quot;,&quot;attr&quot;:{&quot;namespace&quot;:&quot;config.$cmd&quot;,&quot;uuid&quot;:{&quot;uuid&quot;:{&quot;$uuid&quot;:&quot;d524d7c4-5c73-4c70-a167-20cf99272076&quot;}},&quot;object&quot;:{&quot;create&quot;:&quot;system.sessions&quot;,&quot;idIndex&quot;:{&quot;v&quot;:2,&quot;key&quot;:{&quot;_id&quot;:1},&quot;name&quot;:&quot;_id_&quot;}}}} {&quot;t&quot;:{&quot;$date&quot;:&quot;2024-05-11T02:22:23.177+00:00&quot;},&quot;s&quot;:&quot;I&quot;, &quot;c&quot;:&quot;REPL&quot;, &quot;id&quot;:7360100, &quot;ctx&quot;:&quot;LogicalSessionCacheRefresh&quot;,&quot;msg&quot;:&quot;Added oplog entry for createIndexes to transaction&quot;,&quot;attr&quot;:{&quot;namespace&quot;:&quot;config.$cmd&quot;,&quot;uuid&quot;:{&quot;uuid&quot;:{&quot;$uuid&quot;:&quot;d524d7c4-5c73-4c70-a167-20cf99272076&quot;}},&quot;object&quot;:{&quot;createIndexes&quot;:&quot;system.sessions&quot;,&quot;v&quot;:2,&quot;key&quot;:{&quot;lastUse&quot;:1},&quot;name&quot;:&quot;lsidTTLIndex&quot;,&quot;expireAfterSeconds&quot;:1800}}} {&quot;t&quot;:{&quot;$date&quot;:&quot;2024-05-11T02:22:23.186+00:00&quot;},&quot;s&quot;:&quot;I&quot;, &quot;c&quot;:&quot;INDEX&quot;, &quot;id&quot;:20345, &quot;ctx&quot;:&quot;LogicalSessionCacheRefresh&quot;,&quot;msg&quot;:&quot;Index build: done building&quot;,&quot;attr&quot;:{&quot;buildUUID&quot;:null,&quot;collectionUUID&quot;:{&quot;uuid&quot;:{&quot;$uuid&quot;:&quot;d524d7c4-5c73-4c70-a167-20cf99272076&quot;}},&quot;namespace&quot;:&quot;config.system.sessions&quot;,&quot;index&quot;:&quot;_id_&quot;,&quot;ident&quot;:&quot;index-5-2438475259501675333&quot;,&quot;collectionIdent&quot;:&quot;collection-4-2438475259501675333&quot;,&quot;commitTimestamp&quot;:null}} {&quot;t&quot;:{&quot;$date&quot;:&quot;2024-05-11T02:22:23.186+00:00&quot;},&quot;s&quot;:&quot;I&quot;, &quot;c&quot;:&quot;INDEX&quot;, &quot;id&quot;:20345, &quot;ctx&quot;:&quot;LogicalSessionCacheRefresh&quot;,&quot;msg&quot;:&quot;Index build: done building&quot;,&quot;attr&quot;:{&quot;buildUUID&quot;:null,&quot;collectionUUID&quot;:{&quot;uuid&quot;:{&quot;$uuid&quot;:&quot;d524d7c4-5c73-4c70-a167-20cf99272076&quot;}},&quot;namespace&quot;:&quot;config.system.sessions&quot;,&quot;index&quot;:&quot;lsidTTLIndex&quot;,&quot;ident&quot;:&quot;index-6-2438475259501675333&quot;,&quot;collectionIdent&quot;:&quot;collection-4-2438475259501675333&quot;,&quot;commitTimestamp&quot;:null}} {&quot;t&quot;:{&quot;$date&quot;:&quot;2024-05-11T02:23:23.109+00:00&quot;},&quot;s&quot;:&quot;I&quot;, &quot;c&quot;:&quot;WTCHKPT&quot;, &quot;id&quot;:22430, &quot;ctx&quot;:&quot;Checkpointer&quot;,&quot;msg&quot;:&quot;WiredTiger message&quot;,&quot;attr&quot;:{&quot;message&quot;:{&quot;ts_sec&quot;:1715394203,&quot;ts_usec&quot;:109865,&quot;thread&quot;:&quot;1:0x7fdbd6e32640&quot;,&quot;session_name&quot;:&quot;WT_SESSION.checkpoint&quot;,&quot;category&quot;:&quot;WT_VERB_CHECKPOINT_PROGRESS&quot;,&quot;category_id&quot;:6,&quot;verbose_level&quot;:&quot;DEBUG_1&quot;,&quot;verbose_level_id&quot;:1,&quot;msg&quot;:&quot;saving checkpoint snapshot min: 34, snapshot max: 34 snapshot count: 0, oldest timestamp: (0, 0) , meta checkpoint timestamp: (0, 0) base write gen: 1&quot;}}} {&quot;t&quot;:{&quot;$date&quot;:&quot;2024-05-11T02:24:23.131+00:00&quot;},&quot;s&quot;:&quot;I&quot;, &quot;c&quot;:&quot;WTCHKPT&quot;, &quot;id&quot;:22430, &quot;ctx&quot;:&quot;Checkpointer&quot;,&quot;msg&quot;:&quot;WiredTiger message&quot;,&quot;attr&quot;:{&quot;message&quot;:{&quot;ts_sec&quot;:1715394263,&quot;ts_usec&quot;:131330,&quot;thread&quot;:&quot;1:0x7fdbd6e32640&quot;,&quot;session_name&quot;:&quot;WT_SESSION.checkpoint&quot;,&quot;category&quot;:&quot;WT_VERB_CHECKPOINT_PROGRESS&quot;,&quot;category_id&quot;:6,&quot;verbose_level&quot;:&quot;DEBUG_1&quot;,&quot;verbose_level_id&quot;:1,&quot;msg&quot;:&quot;saving checkpoint snapshot min: 35, snapshot max: 35 snapshot count: 0, oldest timestamp: (0, 0) , meta checkpoint timestamp: (0, 0) base write gen: 1&quot;}}} ##( 05\/10\/24@10:21PM )( donbuddenbaum@donbs-imac ):~\/Documents\/knote-java\/04-05@master\u2717\u2717\u2717 mvn -Dminio.access.key=mykey -Dminio.secret.key=mysecret spring-boot:run [INFO] Scanning for projects... [INFO] [INFO] -----------------------&lt; io.learnk8s:knote-java &gt;----------------------- [INFO] Building knote 1.0.0 [INFO] --------------------------------[ jar ]--------------------------------- [INFO] [INFO] &gt;&gt;&gt; spring-boot-maven-plugin:2.1.6.RELEASE:run (default-cli) &gt; test-compile @ knote-java &gt;&gt;&gt; Downloading from central: https:\/\/repo.maven.apache.org\/maven2\/io\/minio\/minio\/6.0.8\/minio-6.0.8.pom Downloaded from central: https:\/\/repo.maven.apache.org\/maven2\/io\/minio\/minio\/6.0.8\/minio-6.0.8.pom (3.4 kB at 5.6 kB\/s) Downloading from central: https:\/\/repo.maven.apache.org\/maven2\/com\/google\/http-client\/google-http-client-xml\/1.24.1\/google-http-client-xml-1.24.1.pom Downloaded from central: https:\/\/repo.maven.apache.org\/maven2\/com\/google\/http-client\/google-http-client-xml\/1.24.1\/google-http-client-xml-1.24.1.pom (2.5 kB at 27 kB\/s) Downloading from central: https:\/\/repo.maven.apache.org\/maven2\/com\/google\/http-client\/google-http-client-parent\/1.24.1\/google-http-client-parent-1.24.1.pom Downloaded from central: https:\/\/repo.maven.apache.org\/maven2\/com\/google\/http-client\/google-http-client-parent\/1.24.1\/google-http-client-parent-1.24.1.pom (22 kB at 248 kB\/s) Downloading from central: https:\/\/repo.maven.apache.org\/maven2\/com\/google\/http-client\/google-http-client\/1.24.1\/google-http-client-1.24.1.pom Downloaded from central: https:\/\/repo.maven.apache.org\/maven2\/com\/google\/http-client\/google-http-client\/1.24.1\/google-http-client-1.24.1.pom (6.1 kB at 84 kB\/s) Downloading from central: https:\/\/repo.maven.apache.org\/maven2\/com\/google\/code\/findbugs\/jsr305\/3.0.2\/jsr305-3.0.2.pom Downloaded from central: https:\/\/repo.maven.apache.org\/maven2\/com\/google\/code\/findbugs\/jsr305\/3.0.2\/jsr305-3.0.2.pom (4.3 kB at 66 kB\/s) Downloading from central: https:\/\/repo.maven.apache.org\/maven2\/org\/apache\/httpcomponents\/httpclient\/4.5.9\/httpclient-4.5.9.pom Downloaded from central: https:\/\/repo.maven.apache.org\/maven2\/org\/apache\/httpcomponents\/httpclient\/4.5.9\/httpclient-4.5.9.pom (6.6 kB at 96 kB\/s) Downloading from central: https:\/\/repo.maven.apache.org\/maven2\/org\/apache\/httpcomponents\/httpcomponents-client\/4.5.9\/httpcomponents-client-4.5.9.pom Downloaded from central: https:\/\/repo.maven.apache.org\/maven2\/org\/apache\/httpcomponents\/httpcomponents-client\/4.5.9\/httpcomponents-client-4.5.9.pom (16 kB at 248 kB\/s) Downloading from central: https:\/\/repo.maven.apache.org\/maven2\/org\/apache\/httpcomponents\/httpcomponents-parent\/11\/httpcomponents-parent-11.pom Downloaded from central: https:\/\/repo.maven.apache.org\/maven2\/org\/apache\/httpcomponents\/httpcomponents-parent\/11\/httpcomponents-parent-11.pom (35 kB at 369 kB\/s) Downloading from central: https:\/\/repo.maven.apache.org\/maven2\/org\/apache\/httpcomponents\/httpcore\/4.4.11\/httpcore-4.4.11.pom Downloaded from central: https:\/\/repo.maven.apache.org\/maven2\/org\/apache\/httpcomponents\/httpcore\/4.4.11\/httpcore-4.4.11.pom (5.2 kB at 76 kB\/s) Downloading from central: https:\/\/repo.maven.apache.org\/maven2\/org\/apache\/httpcomponents\/httpcomponents-core\/4.4.11\/httpcomponents-core-4.4.11.pom Downloaded from central: https:\/\/repo.maven.apache.org\/maven2\/org\/apache\/httpcomponents\/httpcomponents-core\/4.4.11\/httpcomponents-core-4.4.11.pom (13 kB at 173 kB\/s) Downloading from central: https:\/\/repo.maven.apache.org\/maven2\/xpp3\/xpp3\/1.1.4c\/xpp3-1.1.4c.pom Downloaded from central: https:\/\/repo.maven.apache.org\/maven2\/xpp3\/xpp3\/1.1.4c\/xpp3-1.1.4c.pom (2.1 kB at 31 kB\/s) Downloading from central: https:\/\/repo.maven.apache.org\/maven2\/com\/google\/guava\/guava\/25.1-jre\/guava-25.1-jre.pom Downloaded from central: https:\/\/repo.maven.apache.org\/maven2\/com\/google\/guava\/guava\/25.1-jre\/guava-25.1-jre.pom (7.8 kB at 114 kB\/s) Downloading from central: https:\/\/repo.maven.apache.org\/maven2\/com\/google\/guava\/guava-parent\/25.1-jre\/guava-parent-25.1-jre.pom Downloaded from central: https:\/\/repo.maven.apache.org\/maven2\/com\/google\/guava\/guava-parent\/25.1-jre\/guava-parent-25.1-jre.pom (10 kB at 153 kB\/s) Downloading from central: https:\/\/repo.maven.apache.org\/maven2\/org\/checkerframework\/checker-qual\/2.0.0\/checker-qual-2.0.0.pom Downloaded from central: https:\/\/repo.maven.apache.org\/maven2\/org\/checkerframework\/checker-qual\/2.0.0\/checker-qual-2.0.0.pom (4.2 kB at 50 kB\/s) Downloading from central: https:\/\/repo.maven.apache.org\/maven2\/com\/google\/errorprone\/error_prone_annotations\/2.1.3\/error_prone_annotations-2.1.3.pom Downloaded from central: https:\/\/repo.maven.apache.org\/maven2\/com\/google\/errorprone\/error_prone_annotations\/2.1.3\/error_prone_annotations-2.1.3.pom (1.8 kB at 25 kB\/s) Downloading from central: https:\/\/repo.maven.apache.org\/maven2\/com\/google\/errorprone\/error_prone_parent\/2.1.3\/error_prone_parent-2.1.3.pom Downloaded from central: https:\/\/repo.maven.apache.org\/maven2\/com\/google\/errorprone\/error_prone_parent\/2.1.3\/error_prone_parent-2.1.3.pom (5.1 kB at 67 kB\/s) Downloading from central: https:\/\/repo.maven.apache.org\/maven2\/com\/google\/j2objc\/j2objc-annotations\/1.1\/j2objc-annotations-1.1.pom Downloaded from central: https:\/\/repo.maven.apache.org\/maven2\/com\/google\/j2objc\/j2objc-annotations\/1.1\/j2objc-annotations-1.1.pom (2.8 kB at 35 kB\/s) Downloading from central: https:\/\/repo.maven.apache.org\/maven2\/org\/codehaus\/mojo\/animal-sniffer-annotations\/1.14\/animal-sniffer-annotations-1.14.pom Downloaded from central: https:\/\/repo.maven.apache.org\/maven2\/org\/codehaus\/mojo\/animal-sniffer-annotations\/1.14\/animal-sniffer-annotations-1.14.pom (2.5 kB at 38 kB\/s) Downloading from central: https:\/\/repo.maven.apache.org\/maven2\/org\/codehaus\/mojo\/animal-sniffer-parent\/1.14\/animal-sniffer-parent-1.14.pom Downloaded from central: https:\/\/repo.maven.apache.org\/maven2\/org\/codehaus\/mojo\/animal-sniffer-parent\/1.14\/animal-sniffer-parent-1.14.pom (4.4 kB at 51 kB\/s) Downloading from central: https:\/\/repo.maven.apache.org\/maven2\/org\/codehaus\/mojo\/mojo-parent\/34\/mojo-parent-34.pom Downloaded from central: https:\/\/repo.maven.apache.org\/maven2\/org\/codehaus\/mojo\/mojo-parent\/34\/mojo-parent-34.pom (24 kB at 333 kB\/s) Downloading from central: https:\/\/repo.maven.apache.org\/maven2\/org\/codehaus\/codehaus-parent\/4\/codehaus-parent-4.pom Downloaded from central: https:\/\/repo.maven.apache.org\/maven2\/org\/codehaus\/codehaus-parent\/4\/codehaus-parent-4.pom (4.8 kB at 69 kB\/s) Downloading from central: https:\/\/repo.maven.apache.org\/maven2\/com\/squareup\/okhttp3\/okhttp\/3.13.1\/okhttp-3.13.1.pom Downloaded from central: https:\/\/repo.maven.apache.org\/maven2\/com\/squareup\/okhttp3\/okhttp\/3.13.1\/okhttp-3.13.1.pom (2.5 kB at 30 kB\/s) Downloading from central: https:\/\/repo.maven.apache.org\/maven2\/com\/squareup\/okhttp3\/parent\/3.13.1\/parent-3.13.1.pom Downloaded from central: https:\/\/repo.maven.apache.org\/maven2\/com\/squareup\/okhttp3\/parent\/3.13.1\/parent-3.13.1.pom (20 kB at 228 kB\/s) Downloading from central: https:\/\/repo.maven.apache.org\/maven2\/com\/squareup\/okio\/okio\/1.17.2\/okio-1.17.2.pom Downloaded from central: https:\/\/repo.maven.apache.org\/maven2\/com\/squareup\/okio\/okio\/1.17.2\/okio-1.17.2.pom (2.0 kB at 29 kB\/s) Downloading from central: https:\/\/repo.maven.apache.org\/maven2\/com\/squareup\/okio\/okio-parent\/1.17.2\/okio-parent-1.17.2.pom Downloaded from central: https:\/\/repo.maven.apache.org\/maven2\/com\/squareup\/okio\/okio-parent\/1.17.2\/okio-parent-1.17.2.pom (4.9 kB at 72 kB\/s) Downloading from central: https:\/\/repo.maven.apache.org\/maven2\/joda-time\/joda-time\/2.10.2\/joda-time-2.10.2.pom Downloaded from central: https:\/\/repo.maven.apache.org\/maven2\/joda-time\/joda-time\/2.10.2\/joda-time-2.10.2.pom (37 kB at 577 kB\/s) Downloading from central: https:\/\/repo.maven.apache.org\/maven2\/com\/google\/code\/findbugs\/annotations\/3.0.1\/annotations-3.0.1.pom Downloaded from central: https:\/\/repo.maven.apache.org\/maven2\/com\/google\/code\/findbugs\/annotations\/3.0.1\/annotations-3.0.1.pom (7.8 kB at 98 kB\/s) Downloading from central: https:\/\/repo.maven.apache.org\/maven2\/net\/jcip\/jcip-annotations\/1.0\/jcip-annotations-1.0.pom Downloaded from central: https:\/\/repo.maven.apache.org\/maven2\/net\/jcip\/jcip-annotations\/1.0\/jcip-annotations-1.0.pom (491 B at 6.6 kB\/s) Downloading from central: https:\/\/repo.maven.apache.org\/maven2\/com\/google\/code\/findbugs\/jsr305\/3.0.1\/jsr305-3.0.1.pom Downloaded from central: https:\/\/repo.maven.apache.org\/maven2\/com\/google\/code\/findbugs\/jsr305\/3.0.1\/jsr305-3.0.1.pom (4.3 kB at 45 kB\/s) Downloading from central: https:\/\/repo.maven.apache.org\/maven2\/io\/minio\/minio\/6.0.8\/minio-6.0.8.jar Downloading from central: https:\/\/repo.maven.apache.org\/maven2\/com\/google\/http-client\/google-http-client-xml\/1.24.1\/google-http-client-xml-1.24.1.jar Downloading from central: https:\/\/repo.maven.apache.org\/maven2\/com\/google\/http-client\/google-http-client\/1.24.1\/google-http-client-1.24.1.jar Downloading from central: https:\/\/repo.maven.apache.org\/maven2\/org\/apache\/httpcomponents\/httpclient\/4.5.9\/httpclient-4.5.9.jar Downloading from central: https:\/\/repo.maven.apache.org\/maven2\/org\/apache\/httpcomponents\/httpcore\/4.4.11\/httpcore-4.4.11.jar Downloaded from central: https:\/\/repo.maven.apache.org\/maven2\/io\/minio\/minio\/6.0.8\/minio-6.0.8.jar (136 kB at 965 kB\/s) Downloading from central: https:\/\/repo.maven.apache.org\/maven2\/xpp3\/xpp3\/1.1.4c\/xpp3-1.1.4c.jar Downloaded from central: https:\/\/repo.maven.apache.org\/maven2\/com\/google\/http-client\/google-http-client-xml\/1.24.1\/google-http-client-xml-1.24.1.jar (28 kB at 171 kB\/s) Downloading from central: https:\/\/repo.maven.apache.org\/maven2\/com\/google\/guava\/guava\/25.1-jre\/guava-25.1-jre.jar Downloaded from central: https:\/\/repo.maven.apache.org\/maven2\/xpp3\/xpp3\/1.1.4c\/xpp3-1.1.4c.jar (120 kB at 492 kB\/s) Downloading from central: https:\/\/repo.maven.apache.org\/maven2\/org\/checkerframework\/checker-qual\/2.0.0\/checker-qual-2.0.0.jar Downloaded from central: https:\/\/repo.maven.apache.org\/maven2\/com\/google\/http-client\/google-http-client\/1.24.1\/google-http-client-1.24.1.jar (383 kB at 1.4 MB\/s) Downloading from central: https:\/\/repo.maven.apache.org\/maven2\/com\/google\/errorprone\/error_prone_annotations\/2.1.3\/error_prone_annotations-2.1.3.jar Downloaded from central: https:\/\/repo.maven.apache.org\/maven2\/org\/apache\/httpcomponents\/httpcore\/4.4.11\/httpcore-4.4.11.jar (327 kB at 1.1 MB\/s) Downloading from central: https:\/\/repo.maven.apache.org\/maven2\/com\/google\/j2objc\/j2objc-annotations\/1.1\/j2objc-annotations-1.1.jar Downloaded from central: https:\/\/repo.maven.apache.org\/maven2\/org\/apache\/httpcomponents\/httpclient\/4.5.9\/httpclient-4.5.9.jar (774 kB at 2.2 MB\/s) Downloading from central: https:\/\/repo.maven.apache.org\/maven2\/org\/codehaus\/mojo\/animal-sniffer-annotations\/1.14\/animal-sniffer-annotations-1.14.jar Downloaded from central: https:\/\/repo.maven.apache.org\/maven2\/org\/checkerframework\/checker-qual\/2.0.0\/checker-qual-2.0.0.jar (343 kB at 880 kB\/s) Downloading from central: https:\/\/repo.maven.apache.org\/maven2\/com\/squareup\/okhttp3\/okhttp\/3.13.1\/okhttp-3.13.1.jar Downloaded from central: https:\/\/repo.maven.apache.org\/maven2\/com\/google\/errorprone\/error_prone_annotations\/2.1.3\/error_prone_annotations-2.1.3.jar (14 kB at 35 kB\/s) Downloading from central: https:\/\/repo.maven.apache.org\/maven2\/com\/squareup\/okio\/okio\/1.17.2\/okio-1.17.2.jar Downloaded from central: https:\/\/repo.maven.apache.org\/maven2\/com\/google\/j2objc\/j2objc-annotations\/1.1\/j2objc-annotations-1.1.jar (8.8 kB at 22 kB\/s) Downloading from central: https:\/\/repo.maven.apache.org\/maven2\/joda-time\/joda-time\/2.10.2\/joda-time-2.10.2.jar Downloaded from central: https:\/\/repo.maven.apache.org\/maven2\/org\/codehaus\/mojo\/animal-sniffer-annotations\/1.14\/animal-sniffer-annotations-1.14.jar (3.5 kB at 6.4 kB\/s) Downloading from central: https:\/\/repo.maven.apache.org\/maven2\/com\/google\/code\/findbugs\/annotations\/3.0.1\/annotations-3.0.1.jar Downloaded from central: https:\/\/repo.maven.apache.org\/maven2\/com\/google\/guava\/guava\/25.1-jre\/guava-25.1-jre.jar (2.7 MB at 4.5 MB\/s) Downloading from central: https:\/\/repo.maven.apache.org\/maven2\/net\/jcip\/jcip-annotations\/1.0\/jcip-annotations-1.0.jar Downloaded from central: https:\/\/repo.maven.apache.org\/maven2\/com\/squareup\/okio\/okio\/1.17.2\/okio-1.17.2.jar (92 kB at 150 kB\/s) Downloading from central: https:\/\/repo.maven.apache.org\/maven2\/com\/google\/code\/findbugs\/jsr305\/3.0.2\/jsr305-3.0.2.jar Downloaded from central: https:\/\/repo.maven.apache.org\/maven2\/com\/google\/code\/findbugs\/annotations\/3.0.1\/annotations-3.0.1.jar (39 kB at 60 kB\/s) Downloading from central: https:\/\/repo.maven.apache.org\/maven2\/commons-io\/commons-io\/2.6\/commons-io-2.6.jar Downloaded from central: https:\/\/repo.maven.apache.org\/maven2\/com\/squareup\/okhttp3\/okhttp\/3.13.1\/okhttp-3.13.1.jar (418 kB at 646 kB\/s) Downloaded from central: https:\/\/repo.maven.apache.org\/maven2\/joda-time\/joda-time\/2.10.2\/joda-time-2.10.2.jar (643 kB at 941 kB\/s) Downloaded from central: https:\/\/repo.maven.apache.org\/maven2\/com\/google\/code\/findbugs\/jsr305\/3.0.2\/jsr305-3.0.2.jar (20 kB at 28 kB\/s) Downloaded from central: https:\/\/repo.maven.apache.org\/maven2\/net\/jcip\/jcip-annotations\/1.0\/jcip-annotations-1.0.jar (2.3 kB at 3.2 kB\/s) Downloaded from central: https:\/\/repo.maven.apache.org\/maven2\/commons-io\/commons-io\/2.6\/commons-io-2.6.jar (215 kB at 290 kB\/s) [INFO] [INFO] --- maven-resources-plugin:3.1.0:resources (default-resources) @ knote-java --- [INFO] Using 'UTF-8' encoding to copy filtered resources. [INFO] Copying 1 resource [INFO] Copying 2 resources [INFO] [INFO] --- maven-compiler-plugin:3.8.1:compile (default-compile) @ knote-java --- [INFO] Changes detected - recompiling the module! [INFO] Compiling 1 source file to \/Users\/donbuddenbaum\/Documents\/knote-java\/04-05\/target\/classes [INFO] [INFO] --- maven-resources-plugin:3.1.0:testResources (default-testResources) @ knote-java --- [INFO] Using 'UTF-8' encoding to copy filtered resources. [INFO] skip non existing resourceDirectory \/Users\/donbuddenbaum\/Documents\/knote-java\/04-05\/src\/test\/resources [INFO] [INFO] --- maven-compiler-plugin:3.8.1:testCompile (default-testCompile) @ knote-java --- [INFO] Changes detected - recompiling the module! [INFO] Compiling 1 source file to \/Users\/donbuddenbaum\/Documents\/knote-java\/04-05\/target\/test-classes [INFO] [INFO] &lt;&lt;&lt; spring-boot-maven-plugin:2.1.6.RELEASE:run (default-cli) &lt; test-compile @ knote-java &lt;&lt;&lt; [INFO] [INFO] [INFO] --- spring-boot-maven-plugin:2.1.6.RELEASE:run (default-cli) @ knote-java --- . ____ _ __ _ _ \/\\\\ \/ ___'_ __ _ _(_)_ __ __ _ \\ \\ \\ \\ ( ( )\\___ | '_ | '_| | '_ \\\/ _` | \\ \\ \\ \\ \\\\\/ ___)| |_)| | | | | || (_| | ) ) ) ) ' |____| .__|_| |_|_| |_\\__, | \/ \/ \/ \/ =========|_|==============|___\/=\/_\/_\/_\/ :: Spring Boot :: (v2.1.6.RELEASE) 2024-05-10 22:30:09.601 INFO 18410 --- [ main] io.learnk8s.knote.KnoteJavaApplication : Starting KnoteJavaApplication on donbs-imac.local with PID 18410 (\/Users\/donbuddenbaum\/Documents\/knote-java\/04-05\/target\/classes started by donbuddenbaum in \/Users\/donbuddenbaum\/Documents\/knote-java\/04-05) 2024-05-10 22:30:09.605 INFO 18410 --- [ main] io.learnk8s.knote.KnoteJavaApplication : No active profile set, falling back to default profiles: default 2024-05-10 22:30:10.595 INFO 18410 --- [ main] .s.d.r.c.RepositoryConfigurationDelegate : Bootstrapping Spring Data repositories in DEFAULT mode. 2024-05-10 22:30:10.671 INFO 18410 --- [ main] .s.d.r.c.RepositoryConfigurationDelegate : Finished Spring Data repository scanning in 67ms. Found 1 repository interfaces. 2024-05-10 22:30:11.453 INFO 18410 --- [ main] o.s.b.w.embedded.tomcat.TomcatWebServer : Tomcat initialized with port(s): 8080 (http) 2024-05-10 22:30:11.518 INFO 18410 --- [ main] o.apache.catalina.core.StandardService : Starting service [Tomcat] 2024-05-10 22:30:11.518 INFO 18410 --- [ main] org.apache.catalina.core.StandardEngine : Starting Servlet engine: [Apache Tomcat\/9.0.21] 2024-05-10 22:30:11.694 INFO 18410 --- [ main] o.a.c.c.C.[Tomcat].[localhost].[\/] : Initializing Spring embedded WebApplicationContext 2024-05-10 22:30:11.695 INFO 18410 --- [ main] o.s.web.context.ContextLoader : Root WebApplicationContext: initialization completed in 2024 ms 2024-05-10 22:30:12.476 INFO 18410 --- [ main] org.mongodb.driver.cluster : Cluster created with settings {hosts=[localhost:27017], mode=SINGLE, requiredClusterType=UNKNOWN, serverSelectionTimeout='30000 ms', maxWaitQueueSize=500} 2024-05-10 22:30:12.599 INFO 18410 --- [localhost:27017] org.mongodb.driver.connection : Opened connection [connectionId{localValue:1}] to localhost:27017 2024-05-10 22:30:12.606 INFO 18410 --- [localhost:27017] org.mongodb.driver.cluster : Monitor thread successfully connected to server with description ServerDescription{address=localhost:27017, type=STANDALONE, state=CONNECTED, ok=true, version=ServerVersion{versionList=[7, 0, 8]}, minWireVersion=0, maxWireVersion=21, maxDocumentSize=16777216, logicalSessionTimeoutMinutes=30, roundTripTimeNanos=4057940} &gt; Minio initialized! ##( 05\/10\/24@10:48PM )( donbuddenbaum@donbs-imac ):~\/Documents\/knote-java\/04-05@master\u2717\u2717\u2717 docker stop mongo minio docker rm mongo minio mongo minio Error response from daemon: No such container: mongo Error response from daemon: No such container: minio #Build mArch Containers ##( 05\/10\/24@10:59PM )( donbuddenbaum@donbs-imac ):~\/Documents\/knote-java\/04-05@master\u2714 mvn -Dminio.access.key=mykey -Dminio.secret.key=mysecret clean install [INFO] Scanning for projects... [INFO] [INFO] -----------------------&lt; io.learnk8s:knote-java &gt;----------------------- [INFO] Building knote 1.0.0 [INFO] --------------------------------[ jar ]--------------------------------- [INFO] [INFO] --- maven-clean-plugin:3.1.0:clean (default-clean) @ knote-java --- [INFO] Deleting \/Users\/donbuddenbaum\/Documents\/knote-java\/04-05\/target [INFO] [INFO] --- maven-resources-plugin:3.1.0:resources (default-resources) @ knote-java --- [INFO] Using 'UTF-8' encoding to copy filtered resources. [INFO] Copying 1 resource [INFO] Copying 2 resources [INFO] [INFO] --- maven-compiler-plugin:3.8.1:compile (default-compile) @ knote-java --- [INFO] Changes detected - recompiling the module! [INFO] Compiling 1 source file to \/Users\/donbuddenbaum\/Documents\/knote-java\/04-05\/target\/classes [INFO] [INFO] --- maven-resources-plugin:3.1.0:testResources (default-testResources) @ knote-java --- [INFO] Using 'UTF-8' encoding to copy filtered resources. [INFO] skip non existing resourceDirectory \/Users\/donbuddenbaum\/Documents\/knote-java\/04-05\/src\/test\/resources [INFO] [INFO] --- maven-compiler-plugin:3.8.1:testCompile (default-testCompile) @ knote-java --- [INFO] Changes detected - recompiling the module! [INFO] Compiling 1 source file to \/Users\/donbuddenbaum\/Documents\/knote-java\/04-05\/target\/test-classes [INFO] [INFO] --- maven-surefire-plugin:2.22.2:test (default-test) @ knote-java --- [INFO] [INFO] ------------------------------------------------------- [INFO] T E S T S [INFO] ------------------------------------------------------- [INFO] Running io.learnk8s.knote.KnoteJavaApplicationTests 23:02:54.563 [main] DEBUG org.springframework.test.context.junit4.SpringJUnit4ClassRunner - SpringJUnit4ClassRunner constructor called with [class io.learnk8s.knote.KnoteJavaApplicationTests] 23:02:54.572 [main] DEBUG org.springframework.test.context.BootstrapUtils - Instantiating CacheAwareContextLoaderDelegate from class [org.springframework.test.context.cache.DefaultCacheAwareContextLoaderDelegate] 23:02:54.588 [main] DEBUG org.springframework.test.context.BootstrapUtils - Instantiating BootstrapContext using constructor [public org.springframework.test.context.support.DefaultBootstrapContext(java.lang.Class,org.springframework.test.context.CacheAwareContextLoaderDelegate)] 23:02:54.621 [main] DEBUG org.springframework.test.context.BootstrapUtils - Instantiating TestContextBootstrapper for test class [io.learnk8s.knote.KnoteJavaApplicationTests] from class [org.springframework.boot.test.context.SpringBootTestContextBootstrapper] 23:02:54.641 [main] INFO org.springframework.boot.test.context.SpringBootTestContextBootstrapper - Neither @ContextConfiguration nor @ContextHierarchy found for test class [io.learnk8s.knote.KnoteJavaApplicationTests], using SpringBootContextLoader 23:02:54.646 [main] DEBUG org.springframework.test.context.support.AbstractContextLoader - Did not detect default resource location for test class [io.learnk8s.knote.KnoteJavaApplicationTests]: class path resource [io\/learnk8s\/knote\/KnoteJavaApplicationTests-context.xml] does not exist 23:02:54.647 [main] DEBUG org.springframework.test.context.support.AbstractContextLoader - Did not detect default resource location for test class [io.learnk8s.knote.KnoteJavaApplicationTests]: class path resource [io\/learnk8s\/knote\/KnoteJavaApplicationTestsContext.groovy] does not exist 23:02:54.647 [main] INFO org.springframework.test.context.support.AbstractContextLoader - Could not detect default resource locations for test class [io.learnk8s.knote.KnoteJavaApplicationTests]: no resource found for suffixes {-context.xml, Context.groovy}. 23:02:54.648 [main] INFO org.springframework.test.context.support.AnnotationConfigContextLoaderUtils - Could not detect default configuration classes for test class [io.learnk8s.knote.KnoteJavaApplicationTests]: KnoteJavaApplicationTests does not declare any static, non-private, non-final, nested classes annotated with @Configuration. 23:02:54.712 [main] DEBUG org.springframework.test.context.support.ActiveProfilesUtils - Could not find an 'annotation declaring class' for annotation type [org.springframework.test.context.ActiveProfiles] and class [io.learnk8s.knote.KnoteJavaApplicationTests] 23:02:54.813 [main] DEBUG org.springframework.context.annotation.ClassPathScanningCandidateComponentProvider - Identified candidate component class: file [\/Users\/donbuddenbaum\/Documents\/knote-java\/04-05\/target\/classes\/io\/learnk8s\/knote\/KnoteJavaApplication.class] 23:02:54.819 [main] INFO org.springframework.boot.test.context.SpringBootTestContextBootstrapper - Found @SpringBootConfiguration io.learnk8s.knote.KnoteJavaApplication for test class io.learnk8s.knote.KnoteJavaApplicationTests 23:02:54.955 [main] DEBUG org.springframework.boot.test.context.SpringBootTestContextBootstrapper - @TestExecutionListeners is not present for class [io.learnk8s.knote.KnoteJavaApplicationTests]: using defaults. 23:02:54.956 [main] INFO org.springframework.boot.test.context.SpringBootTestContextBootstrapper - Loaded default TestExecutionListener class names from location [META-INF\/spring.factories]: [org.springframework.boot.test.mock.mockito.MockitoTestExecutionListener, org.springframework.boot.test.mock.mockito.ResetMocksTestExecutionListener, org.springframework.boot.test.autoconfigure.restdocs.RestDocsTestExecutionListener, org.springframework.boot.test.autoconfigure.web.client.MockRestServiceServerResetTestExecutionListener, org.springframework.boot.test.autoconfigure.web.servlet.MockMvcPrintOnlyOnFailureTestExecutionListener, org.springframework.boot.test.autoconfigure.web.servlet.WebDriverTestExecutionListener, org.springframework.test.context.web.ServletTestExecutionListener, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener, org.springframework.test.context.support.DependencyInjectionTestExecutionListener, org.springframework.test.context.support.DirtiesContextTestExecutionListener, org.springframework.test.context.transaction.TransactionalTestExecutionListener, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener] 23:02:54.978 [main] INFO org.springframework.boot.test.context.SpringBootTestContextBootstrapper - Using TestExecutionListeners: [org.springframework.test.context.web.ServletTestExecutionListener@63611043, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener@20ca951f, org.springframework.boot.test.mock.mockito.MockitoTestExecutionListener@2d778add, org.springframework.boot.test.autoconfigure.SpringBootDependencyInjectionTestExecutionListener@73302995, org.springframework.test.context.support.DirtiesContextTestExecutionListener@1838ccb8, org.springframework.test.context.transaction.TransactionalTestExecutionListener@6c2ed0cd, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener@7d9e8ef7, org.springframework.boot.test.mock.mockito.ResetMocksTestExecutionListener@f107c50, org.springframework.boot.test.autoconfigure.restdocs.RestDocsTestExecutionListener@51133c06, org.springframework.boot.test.autoconfigure.web.client.MockRestServiceServerResetTestExecutionListener@4b213651, org.springframework.boot.test.autoconfigure.web.servlet.MockMvcPrintOnlyOnFailureTestExecutionListener@4241e0f4, org.springframework.boot.test.autoconfigure.web.servlet.WebDriverTestExecutionListener@4ebff610] 23:02:54.980 [main] DEBUG org.springframework.test.annotation.ProfileValueUtils - Retrieved @ProfileValueSourceConfiguration [null] for test class [io.learnk8s.knote.KnoteJavaApplicationTests] 23:02:54.980 [main] DEBUG org.springframework.test.annotation.ProfileValueUtils - Retrieved ProfileValueSource type [class org.springframework.test.annotation.SystemProfileValueSource] for class [io.learnk8s.knote.KnoteJavaApplicationTests] 23:02:54.982 [main] DEBUG org.springframework.test.annotation.ProfileValueUtils - Retrieved @ProfileValueSourceConfiguration [null] for test class [io.learnk8s.knote.KnoteJavaApplicationTests] 23:02:54.982 [main] DEBUG org.springframework.test.annotation.ProfileValueUtils - Retrieved ProfileValueSource type [class org.springframework.test.annotation.SystemProfileValueSource] for class [io.learnk8s.knote.KnoteJavaApplicationTests] 23:02:54.983 [main] DEBUG org.springframework.test.annotation.ProfileValueUtils - Retrieved @ProfileValueSourceConfiguration [null] for test class [io.learnk8s.knote.KnoteJavaApplicationTests] 23:02:54.983 [main] DEBUG org.springframework.test.annotation.ProfileValueUtils - Retrieved ProfileValueSource type [class org.springframework.test.annotation.SystemProfileValueSource] for class [io.learnk8s.knote.KnoteJavaApplicationTests] 23:02:54.987 [main] DEBUG org.springframework.test.context.support.AbstractDirtiesContextTestExecutionListener - Before test class: context [DefaultTestContext@1b75c2e3 testClass = KnoteJavaApplicationTests, testInstance = [null], testMethod = [null], testException = [null], mergedContextConfiguration = [WebMergedContextConfiguration@1984b1f testClass = KnoteJavaApplicationTests, locations = '{}', classes = '{class io.learnk8s.knote.KnoteJavaApplication}', contextInitializerClasses = '[]', activeProfiles = '{}', propertySourceLocations = '{}', propertySourceProperties = '{minio.reconnect.enabled=false, org.springframework.boot.test.context.SpringBootTestContextBootstrapper=true}', contextCustomizers = set[org.springframework.boot.test.context.filter.ExcludeFilterContextCustomizer@60015ef5, org.springframework.boot.test.json.DuplicateJsonObjectContextCustomizerFactory$DuplicateJsonObjectContextCustomizer@65b3f4a4, org.springframework.boot.test.mock.mockito.MockitoContextCustomizer@0, org.springframework.boot.test.web.client.TestRestTemplateContextCustomizer@609db43b, org.springframework.boot.test.autoconfigure.properties.PropertyMappingContextCustomizer@0, org.springframework.boot.test.autoconfigure.web.servlet.WebDriverContextCustomizerFactory$Customizer@52102734], resourceBasePath = 'src\/main\/webapp', contextLoader = 'org.springframework.boot.test.context.SpringBootContextLoader', parent = [null]], attributes = map['org.springframework.test.context.web.ServletTestExecutionListener.activateListener' -&gt; true]], class annotated with @DirtiesContext [false] with mode [null]. 23:02:54.988 [main] DEBUG org.springframework.test.annotation.ProfileValueUtils - Retrieved @ProfileValueSourceConfiguration [null] for test class [io.learnk8s.knote.KnoteJavaApplicationTests] 23:02:54.988 [main] DEBUG org.springframework.test.annotation.ProfileValueUtils - Retrieved ProfileValueSource type [class org.springframework.test.annotation.SystemProfileValueSource] for class [io.learnk8s.knote.KnoteJavaApplicationTests] 23:02:55.015 [main] DEBUG org.springframework.test.context.support.TestPropertySourceUtils - Adding inlined properties to environment: {spring.jmx.enabled=false, minio.reconnect.enabled=false, org.springframework.boot.test.context.SpringBootTestContextBootstrapper=true, server.port=-1} . ____ _ __ _ _ \/\\\\ \/ ___'_ __ _ _(_)_ __ __ _ \\ \\ \\ \\ ( ( )\\___ | '_ | '_| | '_ \\\/ _` | \\ \\ \\ \\ \\\\\/ ___)| |_)| | | | | || (_| | ) ) ) ) ' |____| .__|_| |_|_| |_\\__, | \/ \/ \/ \/ =========|_|==============|___\/=\/_\/_\/_\/ :: Spring Boot :: (v2.1.6.RELEASE) 2024-05-10 23:02:55.411 INFO 29325 --- [ main] i.l.knote.KnoteJavaApplicationTests : Starting KnoteJavaApplicationTests on donbs-imac.local with PID 29325 (started by donbuddenbaum in \/Users\/donbuddenbaum\/Documents\/knote-java\/04-05) 2024-05-10 23:02:55.413 INFO 29325 --- [ main] i.l.knote.KnoteJavaApplicationTests : No active profile set, falling back to default profiles: default 2024-05-10 23:02:56.468 INFO 29325 --- [ main] .s.d.r.c.RepositoryConfigurationDelegate : Bootstrapping Spring Data repositories in DEFAULT mode. 2024-05-10 23:02:56.543 INFO 29325 --- [ main] .s.d.r.c.RepositoryConfigurationDelegate : Finished Spring Data repository scanning in 67ms. Found 1 repository interfaces. 2024-05-10 23:02:57.495 INFO 29325 --- [ main] org.mongodb.driver.cluster : Cluster created with settings {hosts=[localhost:27017], mode=SINGLE, requiredClusterType=UNKNOWN, serverSelectionTimeout='30000 ms', maxWaitQueueSize=500} 2024-05-10 23:02:57.600 INFO 29325 --- [localhost:27017] org.mongodb.driver.connection : Opened connection [connectionId{localValue:1}] to localhost:27017 2024-05-10 23:02:57.607 INFO 29325 --- [localhost:27017] org.mongodb.driver.cluster : Monitor thread successfully connected to server with description ServerDescription{address=localhost:27017, type=STANDALONE, state=CONNECTED, ok=true, version=ServerVersion{versionList=[7, 0, 8]}, minWireVersion=0, maxWireVersion=21, maxDocumentSize=16777216, logicalSessionTimeoutMinutes=30, roundTripTimeNanos=4290869} java.net.ConnectException: Failed to connect to localhost\/0:0:0:0:0:0:0:1:9000 at okhttp3.internal.connection.RealConnection.connectSocket(RealConnection.java:249) at okhttp3.internal.connection.RealConnection.connect(RealConnection.java:167) at okhttp3.internal.connection.StreamAllocation.findConnection(StreamAllocation.java:257) at okhttp3.internal.connection.StreamAllocation.findHealthyConnection(StreamAllocation.java:135) at okhttp3.internal.connection.StreamAllocation.newStream(StreamAllocation.java:114) at okhttp3.internal.connection.ConnectInterceptor.intercept(ConnectInterceptor.java:42) at okhttp3.internal.http.RealInterceptorChain.proceed(RealInterceptorChain.java:147) at okhttp3.internal.http.RealInterceptorChain.proceed(RealInterceptorChain.java:121) at okhttp3.internal.cache.CacheInterceptor.intercept(CacheInterceptor.java:94) at okhttp3.internal.http.RealInterceptorChain.proceed(RealInterceptorChain.java:147) at okhttp3.internal.http.RealInterceptorChain.proceed(RealInterceptorChain.java:121) at okhttp3.internal.http.BridgeInterceptor.intercept(BridgeInterceptor.java:93) at okhttp3.internal.http.RealInterceptorChain.proceed(RealInterceptorChain.java:147) at okhttp3.internal.http.RetryAndFollowUpInterceptor.intercept(RetryAndFollowUpInterceptor.java:125) at okhttp3.internal.http.RealInterceptorChain.proceed(RealInterceptorChain.java:147) at okhttp3.internal.http.RealInterceptorChain.proceed(RealInterceptorChain.java:121) at okhttp3.RealCall.getResponseWithInterceptorChain(RealCall.java:264) at okhttp3.RealCall.execute(RealCall.java:93) at io.minio.MinioClient.executeReq(MinioClient.java:1111) at io.minio.MinioClient.execute(MinioClient.java:1070) at io.minio.MinioClient.updateRegionCache(MinioClient.java:1219) at io.minio.MinioClient.getRegion(MinioClient.java:1264) at io.minio.MinioClient.executeHead(MinioClient.java:1312) at io.minio.MinioClient.bucketExists(MinioClient.java:3286) at io.learnk8s.knote.KNoteController.initMinio(KnoteJavaApplication.java:202) at io.learnk8s.knote.KNoteController.init(KnoteJavaApplication.java:130) at java.base\/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at java.base\/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) at java.base\/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.base\/java.lang.reflect.Method.invoke(Method.java:566) at org.springframework.beans.factory.annotation.InitDestroyAnnotationBeanPostProcessor$LifecycleElement.invoke(InitDestroyAnnotationBeanPostProcessor.java:363) at org.springframework.beans.factory.annotation.InitDestroyAnnotationBeanPostProcessor$LifecycleMetadata.invokeInitMethods(InitDestroyAnnotationBeanPostProcessor.java:307) at org.springframework.beans.factory.annotation.InitDestroyAnnotationBeanPostProcessor.postProcessBeforeInitialization(InitDestroyAnnotationBeanPostProcessor.java:136) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.applyBeanPostProcessorsBeforeInitialization(AbstractAutowireCapableBeanFactory.java:414) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.initializeBean(AbstractAutowireCapableBeanFactory.java:1770) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:593) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:515) at org.springframework.beans.factory.support.AbstractBeanFactory.lambda$doGetBean$0(AbstractBeanFactory.java:320) at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:222) at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:318) at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:199) at org.springframework.beans.factory.support.DefaultListableBeanFactory.preInstantiateSingletons(DefaultListableBeanFactory.java:845) at org.springframework.context.support.AbstractApplicationContext.finishBeanFactoryInitialization(AbstractApplicationContext.java:877) at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:549) at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:742) at org.springframework.boot.SpringApplication.refreshContext(SpringApplication.java:389) at org.springframework.boot.SpringApplication.run(SpringApplication.java:311) at org.springframework.boot.test.context.SpringBootContextLoader.loadContext(SpringBootContextLoader.java:119) at org.springframework.test.context.cache.DefaultCacheAwareContextLoaderDelegate.loadContextInternal(DefaultCacheAwareContextLoaderDelegate.java:99) at org.springframework.test.context.cache.DefaultCacheAwareContextLoaderDelegate.loadContext(DefaultCacheAwareContextLoaderDelegate.java:117) at org.springframework.test.context.support.DefaultTestContext.getApplicationContext(DefaultTestContext.java:108) at org.springframework.test.context.web.ServletTestExecutionListener.setUpRequestContextIfNecessary(ServletTestExecutionListener.java:190) at org.springframework.test.context.web.ServletTestExecutionListener.prepareTestInstance(ServletTestExecutionListener.java:132) at org.springframework.test.context.TestContextManager.prepareTestInstance(TestContextManager.java:246) at org.springframework.test.context.junit4.SpringJUnit4ClassRunner.createTest(SpringJUnit4ClassRunner.java:227) at org.springframework.test.context.junit4.SpringJUnit4ClassRunner$1.runReflectiveCall(SpringJUnit4ClassRunner.java:289) at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12) at org.springframework.test.context.junit4.SpringJUnit4ClassRunner.methodBlock(SpringJUnit4ClassRunner.java:291) at org.springframework.test.context.junit4.SpringJUnit4ClassRunner.runChild(SpringJUnit4ClassRunner.java:246) at org.springframework.test.context.junit4.SpringJUnit4ClassRunner.runChild(SpringJUnit4ClassRunner.java:97) at org.junit.runners.ParentRunner$3.run(ParentRunner.java:290) at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71) at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288) at org.junit.runners.ParentRunner.access$000(ParentRunner.java:58) at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268) at org.springframework.test.context.junit4.statements.RunBeforeTestClassCallbacks.evaluate(RunBeforeTestClassCallbacks.java:61) at org.springframework.test.context.junit4.statements.RunAfterTestClassCallbacks.evaluate(RunAfterTestClassCallbacks.java:70) at org.junit.runners.ParentRunner.run(ParentRunner.java:363) at org.springframework.test.context.junit4.SpringJUnit4ClassRunner.run(SpringJUnit4ClassRunner.java:190) at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:365) at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:273) at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238) at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:159) at org.apache.maven.surefire.booter.ForkedBooter.invokeProviderInSameClassLoader(ForkedBooter.java:384) at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:345) at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:126) at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:418) Caused by: java.net.ConnectException: Connection refused (Connection refused) at java.base\/java.net.PlainSocketImpl.socketConnect(Native Method) at java.base\/java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:412) at java.base\/java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:255) at java.base\/java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:237) at java.base\/java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392) at java.base\/java.net.Socket.connect(Socket.java:608) at okhttp3.internal.platform.Platform.connectSocket(Platform.java:130) at okhttp3.internal.connection.RealConnection.connectSocket(RealConnection.java:247) ... 76 more &gt; Minio Reconnect: false &gt; Minio initialized! 2024-05-10 23:02:59.082 INFO 29325 --- [ main] o.s.s.concurrent.ThreadPoolTaskExecutor : Initializing ExecutorService 'applicationTaskExecutor' 2024-05-10 23:02:59.334 INFO 29325 --- [ main] o.s.b.a.w.s.WelcomePageHandlerMapping : Adding welcome page template: index 2024-05-10 23:03:00.096 INFO 29325 --- [ main] o.s.b.a.e.web.EndpointLinksResolver : Exposing 2 endpoint(s) beneath base path '\/actuator' 2024-05-10 23:03:00.187 INFO 29325 --- [ main] i.l.knote.KnoteJavaApplicationTests : Started KnoteJavaApplicationTests in 5.159 seconds (JVM running for 6.445) [INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 6.438 s - in io.learnk8s.knote.KnoteJavaApplicationTests 2024-05-10 23:03:00.690 INFO 29325 --- [ Thread-1] o.s.s.concurrent.ThreadPoolTaskExecutor : Shutting down ExecutorService 'applicationTaskExecutor' [INFO] [INFO] Results: [INFO] [INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0 [INFO] [INFO] [INFO] --- maven-jar-plugin:3.1.2:jar (default-jar) @ knote-java --- [INFO] Building jar: \/Users\/donbuddenbaum\/Documents\/knote-java\/04-05\/target\/knote-java-1.0.0.jar [INFO] [INFO] --- spring-boot-maven-plugin:2.1.6.RELEASE:repackage (repackage) @ knote-java --- [INFO] Replacing main artifact with repackaged archive [INFO] [INFO] --- maven-install-plugin:2.5.2:install (default-install) @ knote-java --- [INFO] Installing \/Users\/donbuddenbaum\/Documents\/knote-java\/04-05\/target\/knote-java-1.0.0.jar to \/Users\/donbuddenbaum\/.m2\/repository\/io\/learnk8s\/knote-java\/1.0.0\/knote-java-1.0.0.jar [INFO] Installing \/Users\/donbuddenbaum\/Documents\/knote-java\/04-05\/pom.xml to \/Users\/donbuddenbaum\/.m2\/repository\/io\/learnk8s\/knote-java\/1.0.0\/knote-java-1.0.0.pom [INFO] ------------------------------------------------------------------------ [INFO] BUILD SUCCESS [INFO] ------------------------------------------------------------------------ [INFO] Total time: 15.505 s [INFO] Finished at: 2024-05-10T23:03:03-04:00 [INFO] ------------------------------------------------------------------------ ##( 05\/10\/24@10:48PM )( donbuddenbaum@donbs-imac ):~\/Documents\/knote-java\/04-05@master\u2717\u2717\u2717 docker buildx create \u2013use blissful_heisenberg ##( 05\/10\/24@11:03PM )( donbuddenbaum@donbs-imac ):~\/Documents\/knote-java\/04-05@master\u2717\u2717\u2717 docker buildx build \u2013platform linux\/amd64,linux\/arm64 -t donb4iu\/knote-java:2.0.0 \u2013push . [+] Building 21.5s (14\/14) FINISHED docker-container:blissful_heisenberg =&gt; [internal] load build definition from Dockerfile 0.0s =&gt; =&gt; transferring dockerfile: 188B 0.0s =&gt; [linux\/amd64 internal] load metadata for docker.io\/adoptopenjdk\/openjdk11:jdk-11.0.2.9-slim 0.9s =&gt; [linux\/arm64 internal] load metadata for docker.io\/adoptopenjdk\/openjdk11:jdk-11.0.2.9-slim 0.9s =&gt; [auth] adoptopenjdk\/openjdk11:pull token for registry-1.docker.io 0.0s =&gt; [internal] load .dockerignore 0.0s =&gt; =&gt; transferring context: 2B 0.0s =&gt; [internal] load build context 1.1s =&gt; =&gt; transferring context: 33.57MB 1.1s =&gt; CACHED [linux\/arm64 1\/3] FROM docker.io\/adoptopenjdk\/openjdk11:jdk-11.0.2.9-slim@sha256:f08341ea88e6dfae4a8ded768941574ead9b6794730f55afb8f54fe4bf7c1366 0.0s =&gt; =&gt; resolve docker.io\/adoptopenjdk\/openjdk11:jdk-11.0.2.9-slim@sha256:f08341ea88e6dfae4a8ded768941574ead9b6794730f55afb8f54fe4bf7c1366 0.0s =&gt; CACHED [linux\/amd64 1\/3] FROM docker.io\/adoptopenjdk\/openjdk11:jdk-11.0.2.9-slim@sha256:f08341ea88e6dfae4a8ded768941574ead9b6794730f55afb8f54fe4bf7c1366 0.0s =&gt; =&gt; resolve docker.io\/adoptopenjdk\/openjdk11:jdk-11.0.2.9-slim@sha256:f08341ea88e6dfae4a8ded768941574ead9b6794730f55afb8f54fe4bf7c1366 0.0s =&gt; [linux\/amd64 2\/3] COPY target\/*.jar \/opt\/app.jar 0.4s =&gt; [linux\/arm64 2\/3] COPY target\/*.jar \/opt\/app.jar 0.4s =&gt; [linux\/arm64 3\/3] WORKDIR \/opt 0.1s =&gt; [linux\/amd64 3\/3] WORKDIR \/opt 0.1s =&gt; exporting to image 18.8s =&gt; =&gt; exporting layers 1.9s =&gt; =&gt; exporting manifest sha256:464cdfed847001cee40bce41aebff78845aed5f5f79c7b2700044fe597e8539c 0.0s =&gt; =&gt; exporting config sha256:f39b96fb875d525ba3c0d98c91d6a391907b4e344a64fe60fb440e429399db59 0.0s =&gt; =&gt; exporting attestation manifest sha256:a2c2adf40ec7cc45d5c0578ce2a4abcf3d1c7521a8dc95e8b0f21682d0cb1562 0.0s =&gt; =&gt; exporting manifest sha256:7950d9291ad59642096c38e005d74e4306d7feda83aab20af2254fde1602e281 0.0s =&gt; =&gt; exporting config sha256:fddb98ea66dcfc12711eec7feb0c64a87986ce5faadc55e593aab930880ddca0 0.0s =&gt; =&gt; exporting attestation manifest sha256:6d0fc3be8e21b114312c1a86d5a9eee32ba08c1a760089675f4b115a0da5f080 0.0s =&gt; =&gt; exporting manifest list sha256:3b8cbe7f1c74738c85ba277235006606ff2daa8aaaaeae69c36bc1e565d130be 0.0s =&gt; =&gt; pushing layers 15.4s =&gt; =&gt; pushing manifest for docker.io\/donb4iu\/knote-java:2.0.0@sha256:3b8cbe7f1c74738c85ba277235006606ff2daa8aaaaeae69c36bc1e565d130be 1.4s =&gt; [auth] donb4iu\/knote-java:pull,push token for registry-1.docker.io 0.0s Build multi-platform images faster with Docker Build Cloud: https:\/\/docs.docker.com\/go\/docker-build-cloud #Build &amp; Test Minio with mArch image ##( 05\/10\/24@11:09PM )( donbuddenbaum@donbs-imac ):~\/Documents\/Kalaxy2\/yaml\/knotes\/nfs@main\u2717\u2717\u2717 docker run \u2013name=mongo \u2013rm \u2013network=knote mongo {&quot;t&quot;:{&quot;$date&quot;:&quot;2024-05-11T03:10:24.142+00:00&quot;},&quot;s&quot;:&quot;I&quot;, &quot;c&quot;:&quot;NETWORK&quot;, &quot;id&quot;:4915701, &quot;ctx&quot;:&quot;main&quot;,&quot;msg&quot;:&quot;Initialized wire specification&quot;,&quot;attr&quot;:{&quot;spec&quot;:{&quot;incomingExternalClient&quot;:{&quot;minWireVersion&quot;:0,&quot;maxWireVersion&quot;:21},&quot;incomingInternalClient&quot;:{&quot;minWireVersion&quot;:0,&quot;maxWireVersion&quot;:21},&quot;outgoing&quot;:{&quot;minWireVersion&quot;:6,&quot;maxWireVersion&quot;:21},&quot;isInternalClient&quot;:true}}} {&quot;t&quot;:{&quot;$date&quot;:&quot;2024-05-11T03:10:24.143+00:00&quot;},&quot;s&quot;:&quot;I&quot;, &quot;c&quot;:&quot;CONTROL&quot;, &quot;id&quot;:23285, &quot;ctx&quot;:&quot;main&quot;,&quot;msg&quot;:&quot;Automatically disabling TLS 1.0, to force-enable TLS 1.0 specify --sslDisabledProtocols 'none'&quot;} {&quot;t&quot;:{&quot;$date&quot;:&quot;2024-05-11T03:10:24.146+00:00&quot;},&quot;s&quot;:&quot;I&quot;, &quot;c&quot;:&quot;NETWORK&quot;, &quot;id&quot;:4648601, &quot;ctx&quot;:&quot;main&quot;,&quot;msg&quot;:&quot;Implicit TCP FastOpen unavailable. If TCP FastOpen is required, set tcpFastOpenServer, tcpFastOpenClient, and tcpFastOpenQueueSize.&quot;} {&quot;t&quot;:{&quot;$date&quot;:&quot;2024-05-11T03:10:24.149+00:00&quot;},&quot;s&quot;:&quot;I&quot;, &quot;c&quot;:&quot;REPL&quot;, &quot;id&quot;:5123008, &quot;ctx&quot;:&quot;main&quot;,&quot;msg&quot;:&quot;Successfully registered PrimaryOnlyService&quot;,&quot;attr&quot;:{&quot;service&quot;:&quot;TenantMigrationDonorService&quot;,&quot;namespace&quot;:&quot;config.tenantMigrationDonors&quot;}} {&quot;t&quot;:{&quot;$date&quot;:&quot;2024-05-11T03:10:24.149+00:00&quot;},&quot;s&quot;:&quot;I&quot;, &quot;c&quot;:&quot;REPL&quot;, &quot;id&quot;:5123008, &quot;ctx&quot;:&quot;main&quot;,&quot;msg&quot;:&quot;Successfully registered PrimaryOnlyService&quot;,&quot;attr&quot;:{&quot;service&quot;:&quot;TenantMigrationRecipientService&quot;,&quot;namespace&quot;:&quot;config.tenantMigrationRecipients&quot;}} {&quot;t&quot;:{&quot;$date&quot;:&quot;2024-05-11T03:10:24.149+00:00&quot;},&quot;s&quot;:&quot;I&quot;, &quot;c&quot;:&quot;CONTROL&quot;, &quot;id&quot;:5945603, &quot;ctx&quot;:&quot;main&quot;,&quot;msg&quot;:&quot;Multi threading initialized&quot;} {&quot;t&quot;:{&quot;$date&quot;:&quot;2024-05-11T03:10:24.149+00:00&quot;},&quot;s&quot;:&quot;I&quot;, &quot;c&quot;:&quot;TENANT_M&quot;, &quot;id&quot;:7091600, &quot;ctx&quot;:&quot;main&quot;,&quot;msg&quot;:&quot;Starting TenantMigrationAccessBlockerRegistry&quot;} {&quot;t&quot;:{&quot;$date&quot;:&quot;2024-05-11T03:10:24.150+00:00&quot;},&quot;s&quot;:&quot;I&quot;, &quot;c&quot;:&quot;CONTROL&quot;, &quot;id&quot;:4615611, &quot;ctx&quot;:&quot;initandlisten&quot;,&quot;msg&quot;:&quot;MongoDB starting&quot;,&quot;attr&quot;:{&quot;pid&quot;:1,&quot;port&quot;:27017,&quot;dbPath&quot;:&quot;\/data\/db&quot;,&quot;architecture&quot;:&quot;64-bit&quot;,&quot;host&quot;:&quot;126cb11ee1dc&quot;}} {&quot;t&quot;:{&quot;$date&quot;:&quot;2024-05-11T03:10:24.150+00:00&quot;},&quot;s&quot;:&quot;I&quot;, &quot;c&quot;:&quot;CONTROL&quot;, &quot;id&quot;:23403, &quot;ctx&quot;:&quot;initandlisten&quot;,&quot;msg&quot;:&quot;Build Info&quot;,&quot;attr&quot;:{&quot;buildInfo&quot;:{&quot;version&quot;:&quot;7.0.9&quot;,&quot;gitVersion&quot;:&quot;3ff3a3925c36ed277cf5eafca5495f2e3728dd67&quot;,&quot;openSSLVersion&quot;:&quot;OpenSSL 3.0.2 15 Mar 2022&quot;,&quot;modules&quot;:[],&quot;allocator&quot;:&quot;tcmalloc&quot;,&quot;environment&quot;:{&quot;distmod&quot;:&quot;ubuntu2204&quot;,&quot;distarch&quot;:&quot;x86_64&quot;,&quot;target_arch&quot;:&quot;x86_64&quot;}}}} {&quot;t&quot;:{&quot;$date&quot;:&quot;2024-05-11T03:10:24.150+00:00&quot;},&quot;s&quot;:&quot;I&quot;, &quot;c&quot;:&quot;CONTROL&quot;, &quot;id&quot;:51765, &quot;ctx&quot;:&quot;initandlisten&quot;,&quot;msg&quot;:&quot;Operating System&quot;,&quot;attr&quot;:{&quot;os&quot;:{&quot;name&quot;:&quot;Ubuntu&quot;,&quot;version&quot;:&quot;22.04&quot;}}} {&quot;t&quot;:{&quot;$date&quot;:&quot;2024-05-11T03:10:24.150+00:00&quot;},&quot;s&quot;:&quot;I&quot;, &quot;c&quot;:&quot;CONTROL&quot;, &quot;id&quot;:21951, &quot;ctx&quot;:&quot;initandlisten&quot;,&quot;msg&quot;:&quot;Options set by command line&quot;,&quot;attr&quot;:{&quot;options&quot;:{&quot;net&quot;:{&quot;bindIp&quot;:&quot;*&quot;}}}} {&quot;t&quot;:{&quot;$date&quot;:&quot;2024-05-11T03:10:24.152+00:00&quot;},&quot;s&quot;:&quot;I&quot;, &quot;c&quot;:&quot;STORAGE&quot;, &quot;id&quot;:22297, &quot;ctx&quot;:&quot;initandlisten&quot;,&quot;msg&quot;:&quot;Using the XFS filesystem is strongly recommended with the WiredTiger storage engine. See http:\/\/dochub.mongodb.org\/core\/prodnotes-filesystem&quot;,&quot;tags&quot;:[&quot;startupWarnings&quot;]} {&quot;t&quot;:{&quot;$date&quot;:&quot;2024-05-11T03:10:24.153+00:00&quot;},&quot;s&quot;:&quot;I&quot;, &quot;c&quot;:&quot;STORAGE&quot;, &quot;id&quot;:22315, &quot;ctx&quot;:&quot;initandlisten&quot;,&quot;msg&quot;:&quot;Opening WiredTiger&quot;,&quot;attr&quot;:{&quot;config&quot;:&quot;create,cache_size=3458M,session_max=33000,eviction=(threads_min=4,threads_max=4),config_base=false,statistics=(fast),log=(enabled=true,remove=true,path=journal,compressor=snappy),builtin_extension_config=(zstd=(compression_level=6)),file_manager=(close_idle_time=600,close_scan_interval=10,close_handle_minimum=2000),statistics_log=(wait=0),json_output=(error,message),verbose=[recovery_progress:1,checkpoint_progress:1,compact_progress:1,backup:0,checkpoint:0,compact:0,evict:0,history_store:0,recovery:0,rts:0,salvage:0,tiered:0,timestamp:0,transaction:0,verify:0,log:0],&quot;}} {&quot;t&quot;:{&quot;$date&quot;:&quot;2024-05-11T03:10:25.141+00:00&quot;},&quot;s&quot;:&quot;I&quot;, &quot;c&quot;:&quot;WTRECOV&quot;, &quot;id&quot;:22430, &quot;ctx&quot;:&quot;initandlisten&quot;,&quot;msg&quot;:&quot;WiredTiger message&quot;,&quot;attr&quot;:{&quot;message&quot;:{&quot;ts_sec&quot;:1715397025,&quot;ts_usec&quot;:141511,&quot;thread&quot;:&quot;1:0x7f9d962efc80&quot;,&quot;session_name&quot;:&quot;txn-recover&quot;,&quot;category&quot;:&quot;WT_VERB_RECOVERY_PROGRESS&quot;,&quot;category_id&quot;:30,&quot;verbose_level&quot;:&quot;DEBUG_1&quot;,&quot;verbose_level_id&quot;:1,&quot;msg&quot;:&quot;recovery log replay has successfully finished and ran for 0 milliseconds&quot;}}} {&quot;t&quot;:{&quot;$date&quot;:&quot;2024-05-11T03:10:25.141+00:00&quot;},&quot;s&quot;:&quot;I&quot;, &quot;c&quot;:&quot;WTRECOV&quot;, &quot;id&quot;:22430, &quot;ctx&quot;:&quot;initandlisten&quot;,&quot;msg&quot;:&quot;WiredTiger message&quot;,&quot;attr&quot;:{&quot;message&quot;:{&quot;ts_sec&quot;:1715397025,&quot;ts_usec&quot;:141680,&quot;thread&quot;:&quot;1:0x7f9d962efc80&quot;,&quot;session_name&quot;:&quot;txn-recover&quot;,&quot;category&quot;:&quot;WT_VERB_RECOVERY_PROGRESS&quot;,&quot;category_id&quot;:30,&quot;verbose_level&quot;:&quot;DEBUG_1&quot;,&quot;verbose_level_id&quot;:1,&quot;msg&quot;:&quot;Set global recovery timestamp: (0, 0)&quot;}}} {&quot;t&quot;:{&quot;$date&quot;:&quot;2024-05-11T03:10:25.141+00:00&quot;},&quot;s&quot;:&quot;I&quot;, &quot;c&quot;:&quot;WTRECOV&quot;, &quot;id&quot;:22430, &quot;ctx&quot;:&quot;initandlisten&quot;,&quot;msg&quot;:&quot;WiredTiger message&quot;,&quot;attr&quot;:{&quot;message&quot;:{&quot;ts_sec&quot;:1715397025,&quot;ts_usec&quot;:141726,&quot;thread&quot;:&quot;1:0x7f9d962efc80&quot;,&quot;session_name&quot;:&quot;txn-recover&quot;,&quot;category&quot;:&quot;WT_VERB_RECOVERY_PROGRESS&quot;,&quot;category_id&quot;:30,&quot;verbose_level&quot;:&quot;DEBUG_1&quot;,&quot;verbose_level_id&quot;:1,&quot;msg&quot;:&quot;Set global oldest timestamp: (0, 0)&quot;}}} {&quot;t&quot;:{&quot;$date&quot;:&quot;2024-05-11T03:10:25.141+00:00&quot;},&quot;s&quot;:&quot;I&quot;, &quot;c&quot;:&quot;WTRECOV&quot;, &quot;id&quot;:22430, &quot;ctx&quot;:&quot;initandlisten&quot;,&quot;msg&quot;:&quot;WiredTiger message&quot;,&quot;attr&quot;:{&quot;message&quot;:{&quot;ts_sec&quot;:1715397025,&quot;ts_usec&quot;:141796,&quot;thread&quot;:&quot;1:0x7f9d962efc80&quot;,&quot;session_name&quot;:&quot;txn-recover&quot;,&quot;category&quot;:&quot;WT_VERB_RECOVERY_PROGRESS&quot;,&quot;category_id&quot;:30,&quot;verbose_level&quot;:&quot;DEBUG_1&quot;,&quot;verbose_level_id&quot;:1,&quot;msg&quot;:&quot;recovery was completed successfully and took 0ms, including 0ms for the log replay, 0ms for the rollback to stable, and 0ms for the checkpoint.&quot;}}} {&quot;t&quot;:{&quot;$date&quot;:&quot;2024-05-11T03:10:25.155+00:00&quot;},&quot;s&quot;:&quot;I&quot;, &quot;c&quot;:&quot;STORAGE&quot;, &quot;id&quot;:4795906, &quot;ctx&quot;:&quot;initandlisten&quot;,&quot;msg&quot;:&quot;WiredTiger opened&quot;,&quot;attr&quot;:{&quot;durationMillis&quot;:1002}} {&quot;t&quot;:{&quot;$date&quot;:&quot;2024-05-11T03:10:25.155+00:00&quot;},&quot;s&quot;:&quot;I&quot;, &quot;c&quot;:&quot;RECOVERY&quot;, &quot;id&quot;:23987, &quot;ctx&quot;:&quot;initandlisten&quot;,&quot;msg&quot;:&quot;WiredTiger recoveryTimestamp&quot;,&quot;attr&quot;:{&quot;recoveryTimestamp&quot;:{&quot;$timestamp&quot;:{&quot;t&quot;:0,&quot;i&quot;:0}}}} {&quot;t&quot;:{&quot;$date&quot;:&quot;2024-05-11T03:10:25.183+00:00&quot;},&quot;s&quot;:&quot;W&quot;, &quot;c&quot;:&quot;CONTROL&quot;, &quot;id&quot;:22120, &quot;ctx&quot;:&quot;initandlisten&quot;,&quot;msg&quot;:&quot;Access control is not enabled for the database. Read and write access to data and configuration is unrestricted&quot;,&quot;tags&quot;:[&quot;startupWarnings&quot;]} {&quot;t&quot;:{&quot;$date&quot;:&quot;2024-05-11T03:10:25.183+00:00&quot;},&quot;s&quot;:&quot;W&quot;, &quot;c&quot;:&quot;CONTROL&quot;, &quot;id&quot;:22178, &quot;ctx&quot;:&quot;initandlisten&quot;,&quot;msg&quot;:&quot;\/sys\/kernel\/mm\/transparent_hugepage\/enabled is 'always'. We suggest setting it to 'never' in this binary version&quot;,&quot;tags&quot;:[&quot;startupWarnings&quot;]} {&quot;t&quot;:{&quot;$date&quot;:&quot;2024-05-11T03:10:25.183+00:00&quot;},&quot;s&quot;:&quot;W&quot;, &quot;c&quot;:&quot;CONTROL&quot;, &quot;id&quot;:5123300, &quot;ctx&quot;:&quot;initandlisten&quot;,&quot;msg&quot;:&quot;vm.max_map_count is too low&quot;,&quot;attr&quot;:{&quot;currentValue&quot;:262144,&quot;recommendedMinimum&quot;:1677720,&quot;maxConns&quot;:838860},&quot;tags&quot;:[&quot;startupWarnings&quot;]} {&quot;t&quot;:{&quot;$date&quot;:&quot;2024-05-11T03:10:25.184+00:00&quot;},&quot;s&quot;:&quot;I&quot;, &quot;c&quot;:&quot;STORAGE&quot;, &quot;id&quot;:20320, &quot;ctx&quot;:&quot;initandlisten&quot;,&quot;msg&quot;:&quot;createCollection&quot;,&quot;attr&quot;:{&quot;namespace&quot;:&quot;admin.system.version&quot;,&quot;uuidDisposition&quot;:&quot;provided&quot;,&quot;uuid&quot;:{&quot;uuid&quot;:{&quot;$uuid&quot;:&quot;1526df3f-333a-4db1-a2ee-298688b10402&quot;}},&quot;options&quot;:{&quot;uuid&quot;:{&quot;$uuid&quot;:&quot;1526df3f-333a-4db1-a2ee-298688b10402&quot;}}}} {&quot;t&quot;:{&quot;$date&quot;:&quot;2024-05-11T03:10:25.202+00:00&quot;},&quot;s&quot;:&quot;I&quot;, &quot;c&quot;:&quot;INDEX&quot;, &quot;id&quot;:20345, &quot;ctx&quot;:&quot;initandlisten&quot;,&quot;msg&quot;:&quot;Index build: done building&quot;,&quot;attr&quot;:{&quot;buildUUID&quot;:null,&quot;collectionUUID&quot;:{&quot;uuid&quot;:{&quot;$uuid&quot;:&quot;1526df3f-333a-4db1-a2ee-298688b10402&quot;}},&quot;namespace&quot;:&quot;admin.system.version&quot;,&quot;index&quot;:&quot;_id_&quot;,&quot;ident&quot;:&quot;index-1-8856531098339113795&quot;,&quot;collectionIdent&quot;:&quot;collection-0-8856531098339113795&quot;,&quot;commitTimestamp&quot;:null}} {&quot;t&quot;:{&quot;$date&quot;:&quot;2024-05-11T03:10:25.202+00:00&quot;},&quot;s&quot;:&quot;I&quot;, &quot;c&quot;:&quot;REPL&quot;, &quot;id&quot;:20459, &quot;ctx&quot;:&quot;initandlisten&quot;,&quot;msg&quot;:&quot;Setting featureCompatibilityVersion&quot;,&quot;attr&quot;:{&quot;newVersion&quot;:&quot;7.0&quot;}} {&quot;t&quot;:{&quot;$date&quot;:&quot;2024-05-11T03:10:25.202+00:00&quot;},&quot;s&quot;:&quot;I&quot;, &quot;c&quot;:&quot;REPL&quot;, &quot;id&quot;:5853300, &quot;ctx&quot;:&quot;initandlisten&quot;,&quot;msg&quot;:&quot;current featureCompatibilityVersion value&quot;,&quot;attr&quot;:{&quot;featureCompatibilityVersion&quot;:&quot;7.0&quot;,&quot;context&quot;:&quot;setFCV&quot;}} {&quot;t&quot;:{&quot;$date&quot;:&quot;2024-05-11T03:10:25.202+00:00&quot;},&quot;s&quot;:&quot;I&quot;, &quot;c&quot;:&quot;NETWORK&quot;, &quot;id&quot;:4915702, &quot;ctx&quot;:&quot;initandlisten&quot;,&quot;msg&quot;:&quot;Updated wire specification&quot;,&quot;attr&quot;:{&quot;oldSpec&quot;:{&quot;incomingExternalClient&quot;:{&quot;minWireVersion&quot;:0,&quot;maxWireVersion&quot;:21},&quot;incomingInternalClient&quot;:{&quot;minWireVersion&quot;:0,&quot;maxWireVersion&quot;:21},&quot;outgoing&quot;:{&quot;minWireVersion&quot;:6,&quot;maxWireVersion&quot;:21},&quot;isInternalClient&quot;:true},&quot;newSpec&quot;:{&quot;incomingExternalClient&quot;:{&quot;minWireVersion&quot;:0,&quot;maxWireVersion&quot;:21},&quot;incomingInternalClient&quot;:{&quot;minWireVersion&quot;:21,&quot;maxWireVersion&quot;:21},&quot;outgoing&quot;:{&quot;minWireVersion&quot;:21,&quot;maxWireVersion&quot;:21},&quot;isInternalClient&quot;:true}}} {&quot;t&quot;:{&quot;$date&quot;:&quot;2024-05-11T03:10:25.203+00:00&quot;},&quot;s&quot;:&quot;I&quot;, &quot;c&quot;:&quot;NETWORK&quot;, &quot;id&quot;:4915702, &quot;ctx&quot;:&quot;initandlisten&quot;,&quot;msg&quot;:&quot;Updated wire specification&quot;,&quot;attr&quot;:{&quot;oldSpec&quot;:{&quot;incomingExternalClient&quot;:{&quot;minWireVersion&quot;:0,&quot;maxWireVersion&quot;:21},&quot;incomingInternalClient&quot;:{&quot;minWireVersion&quot;:21,&quot;maxWireVersion&quot;:21},&quot;outgoing&quot;:{&quot;minWireVersion&quot;:21,&quot;maxWireVersion&quot;:21},&quot;isInternalClient&quot;:true},&quot;newSpec&quot;:{&quot;incomingExternalClient&quot;:{&quot;minWireVersion&quot;:0,&quot;maxWireVersion&quot;:21},&quot;incomingInternalClient&quot;:{&quot;minWireVersion&quot;:21,&quot;maxWireVersion&quot;:21},&quot;outgoing&quot;:{&quot;minWireVersion&quot;:21,&quot;maxWireVersion&quot;:21},&quot;isInternalClient&quot;:true}}} {&quot;t&quot;:{&quot;$date&quot;:&quot;2024-05-11T03:10:25.203+00:00&quot;},&quot;s&quot;:&quot;I&quot;, &quot;c&quot;:&quot;REPL&quot;, &quot;id&quot;:5853300, &quot;ctx&quot;:&quot;initandlisten&quot;,&quot;msg&quot;:&quot;current featureCompatibilityVersion value&quot;,&quot;attr&quot;:{&quot;featureCompatibilityVersion&quot;:&quot;7.0&quot;,&quot;context&quot;:&quot;startup&quot;}} {&quot;t&quot;:{&quot;$date&quot;:&quot;2024-05-11T03:10:25.205+00:00&quot;},&quot;s&quot;:&quot;I&quot;, &quot;c&quot;:&quot;STORAGE&quot;, &quot;id&quot;:5071100, &quot;ctx&quot;:&quot;initandlisten&quot;,&quot;msg&quot;:&quot;Clearing temp directory&quot;} {&quot;t&quot;:{&quot;$date&quot;:&quot;2024-05-11T03:10:25.205+00:00&quot;},&quot;s&quot;:&quot;I&quot;, &quot;c&quot;:&quot;CONTROL&quot;, &quot;id&quot;:6608200, &quot;ctx&quot;:&quot;initandlisten&quot;,&quot;msg&quot;:&quot;Initializing cluster server parameters from disk&quot;} {&quot;t&quot;:{&quot;$date&quot;:&quot;2024-05-11T03:10:25.205+00:00&quot;},&quot;s&quot;:&quot;I&quot;, &quot;c&quot;:&quot;CONTROL&quot;, &quot;id&quot;:20536, &quot;ctx&quot;:&quot;initandlisten&quot;,&quot;msg&quot;:&quot;Flow Control is enabled on this deployment&quot;} {&quot;t&quot;:{&quot;$date&quot;:&quot;2024-05-11T03:10:25.207+00:00&quot;},&quot;s&quot;:&quot;I&quot;, &quot;c&quot;:&quot;FTDC&quot;, &quot;id&quot;:20625, &quot;ctx&quot;:&quot;initandlisten&quot;,&quot;msg&quot;:&quot;Initializing full-time diagnostic data capture&quot;,&quot;attr&quot;:{&quot;dataDirectory&quot;:&quot;\/data\/db\/diagnostic.data&quot;}} {&quot;t&quot;:{&quot;$date&quot;:&quot;2024-05-11T03:10:25.209+00:00&quot;},&quot;s&quot;:&quot;I&quot;, &quot;c&quot;:&quot;STORAGE&quot;, &quot;id&quot;:20320, &quot;ctx&quot;:&quot;initandlisten&quot;,&quot;msg&quot;:&quot;createCollection&quot;,&quot;attr&quot;:{&quot;namespace&quot;:&quot;local.startup_log&quot;,&quot;uuidDisposition&quot;:&quot;generated&quot;,&quot;uuid&quot;:{&quot;uuid&quot;:{&quot;$uuid&quot;:&quot;48960fb4-2f88-4d83-8b7e-697ab298f1f7&quot;}},&quot;options&quot;:{&quot;capped&quot;:true,&quot;size&quot;:10485760}}} {&quot;t&quot;:{&quot;$date&quot;:&quot;2024-05-11T03:10:25.231+00:00&quot;},&quot;s&quot;:&quot;I&quot;, &quot;c&quot;:&quot;INDEX&quot;, &quot;id&quot;:20345, &quot;ctx&quot;:&quot;initandlisten&quot;,&quot;msg&quot;:&quot;Index build: done building&quot;,&quot;attr&quot;:{&quot;buildUUID&quot;:null,&quot;collectionUUID&quot;:{&quot;uuid&quot;:{&quot;$uuid&quot;:&quot;48960fb4-2f88-4d83-8b7e-697ab298f1f7&quot;}},&quot;namespace&quot;:&quot;local.startup_log&quot;,&quot;index&quot;:&quot;_id_&quot;,&quot;ident&quot;:&quot;index-3-8856531098339113795&quot;,&quot;collectionIdent&quot;:&quot;collection-2-8856531098339113795&quot;,&quot;commitTimestamp&quot;:null}} {&quot;t&quot;:{&quot;$date&quot;:&quot;2024-05-11T03:10:25.231+00:00&quot;},&quot;s&quot;:&quot;I&quot;, &quot;c&quot;:&quot;REPL&quot;, &quot;id&quot;:6015317, &quot;ctx&quot;:&quot;initandlisten&quot;,&quot;msg&quot;:&quot;Setting new configuration state&quot;,&quot;attr&quot;:{&quot;newState&quot;:&quot;ConfigReplicationDisabled&quot;,&quot;oldState&quot;:&quot;ConfigPreStart&quot;}} {&quot;t&quot;:{&quot;$date&quot;:&quot;2024-05-11T03:10:25.231+00:00&quot;},&quot;s&quot;:&quot;I&quot;, &quot;c&quot;:&quot;STORAGE&quot;, &quot;id&quot;:22262, &quot;ctx&quot;:&quot;initandlisten&quot;,&quot;msg&quot;:&quot;Timestamp monitor starting&quot;} {&quot;t&quot;:{&quot;$date&quot;:&quot;2024-05-11T03:10:25.234+00:00&quot;},&quot;s&quot;:&quot;I&quot;, &quot;c&quot;:&quot;CONTROL&quot;, &quot;id&quot;:20712, &quot;ctx&quot;:&quot;LogicalSessionCacheReap&quot;,&quot;msg&quot;:&quot;Sessions collection is not set up; waiting until next sessions reap interval&quot;,&quot;attr&quot;:{&quot;error&quot;:&quot;NamespaceNotFound: config.system.sessions does not exist&quot;}} {&quot;t&quot;:{&quot;$date&quot;:&quot;2024-05-11T03:10:25.234+00:00&quot;},&quot;s&quot;:&quot;I&quot;, &quot;c&quot;:&quot;STORAGE&quot;, &quot;id&quot;:20320, &quot;ctx&quot;:&quot;LogicalSessionCacheRefresh&quot;,&quot;msg&quot;:&quot;createCollection&quot;,&quot;attr&quot;:{&quot;namespace&quot;:&quot;config.system.sessions&quot;,&quot;uuidDisposition&quot;:&quot;generated&quot;,&quot;uuid&quot;:{&quot;uuid&quot;:{&quot;$uuid&quot;:&quot;e7845007-46de-4e79-bfae-5f3f2c0f7219&quot;}},&quot;options&quot;:{}}} {&quot;t&quot;:{&quot;$date&quot;:&quot;2024-05-11T03:10:25.235+00:00&quot;},&quot;s&quot;:&quot;I&quot;, &quot;c&quot;:&quot;NETWORK&quot;, &quot;id&quot;:23015, &quot;ctx&quot;:&quot;listener&quot;,&quot;msg&quot;:&quot;Listening on&quot;,&quot;attr&quot;:{&quot;address&quot;:&quot;\/tmp\/mongodb-27017.sock&quot;}} {&quot;t&quot;:{&quot;$date&quot;:&quot;2024-05-11T03:10:25.235+00:00&quot;},&quot;s&quot;:&quot;I&quot;, &quot;c&quot;:&quot;NETWORK&quot;, &quot;id&quot;:23015, &quot;ctx&quot;:&quot;listener&quot;,&quot;msg&quot;:&quot;Listening on&quot;,&quot;attr&quot;:{&quot;address&quot;:&quot;0.0.0.0&quot;}} {&quot;t&quot;:{&quot;$date&quot;:&quot;2024-05-11T03:10:25.235+00:00&quot;},&quot;s&quot;:&quot;I&quot;, &quot;c&quot;:&quot;NETWORK&quot;, &quot;id&quot;:23016, &quot;ctx&quot;:&quot;listener&quot;,&quot;msg&quot;:&quot;Waiting for connections&quot;,&quot;attr&quot;:{&quot;port&quot;:27017,&quot;ssl&quot;:&quot;off&quot;}} {&quot;t&quot;:{&quot;$date&quot;:&quot;2024-05-11T03:10:25.235+00:00&quot;},&quot;s&quot;:&quot;I&quot;, &quot;c&quot;:&quot;CONTROL&quot;, &quot;id&quot;:8423403, &quot;ctx&quot;:&quot;initandlisten&quot;,&quot;msg&quot;:&quot;mongod startup complete&quot;,&quot;attr&quot;:{&quot;Summary of time elapsed&quot;:{&quot;Startup from clean shutdown?&quot;:true,&quot;Statistics&quot;:{&quot;Transport layer setup&quot;:&quot;0 ms&quot;,&quot;Run initial syncer crash recovery&quot;:&quot;0 ms&quot;,&quot;Create storage engine lock file in the data directory&quot;:&quot;0 ms&quot;,&quot;Get metadata describing storage engine&quot;:&quot;0 ms&quot;,&quot;Create storage engine&quot;:&quot;1024 ms&quot;,&quot;Write current PID to file&quot;:&quot;0 ms&quot;,&quot;Write a new metadata for storage engine&quot;:&quot;3 ms&quot;,&quot;Initialize FCV before rebuilding indexes&quot;:&quot;1 ms&quot;,&quot;Drop abandoned idents and get back indexes that need to be rebuilt or builds that need to be restarted&quot;:&quot;0 ms&quot;,&quot;Rebuild indexes for collections&quot;:&quot;0 ms&quot;,&quot;Load cluster parameters from disk for a standalone&quot;:&quot;0 ms&quot;,&quot;Build user and roles graph&quot;:&quot;0 ms&quot;,&quot;Set up the background thread pool responsible for waiting for opTimes to be majority committed&quot;:&quot;0 ms&quot;,&quot;Initialize information needed to make a mongod instance shard aware&quot;:&quot;0 ms&quot;,&quot;Start up the replication coordinator&quot;:&quot;0 ms&quot;,&quot;Start transport layer&quot;:&quot;1 ms&quot;,&quot;_initAndListen total elapsed time&quot;:&quot;1085 ms&quot;}}}} {&quot;t&quot;:{&quot;$date&quot;:&quot;2024-05-11T03:10:25.254+00:00&quot;},&quot;s&quot;:&quot;I&quot;, &quot;c&quot;:&quot;REPL&quot;, &quot;id&quot;:7360102, &quot;ctx&quot;:&quot;LogicalSessionCacheRefresh&quot;,&quot;msg&quot;:&quot;Added oplog entry for create to transaction&quot;,&quot;attr&quot;:{&quot;namespace&quot;:&quot;config.$cmd&quot;,&quot;uuid&quot;:{&quot;uuid&quot;:{&quot;$uuid&quot;:&quot;e7845007-46de-4e79-bfae-5f3f2c0f7219&quot;}},&quot;object&quot;:{&quot;create&quot;:&quot;system.sessions&quot;,&quot;idIndex&quot;:{&quot;v&quot;:2,&quot;key&quot;:{&quot;_id&quot;:1},&quot;name&quot;:&quot;_id_&quot;}}}} {&quot;t&quot;:{&quot;$date&quot;:&quot;2024-05-11T03:10:25.255+00:00&quot;},&quot;s&quot;:&quot;I&quot;, &quot;c&quot;:&quot;REPL&quot;, &quot;id&quot;:7360100, &quot;ctx&quot;:&quot;LogicalSessionCacheRefresh&quot;,&quot;msg&quot;:&quot;Added oplog entry for createIndexes to transaction&quot;,&quot;attr&quot;:{&quot;namespace&quot;:&quot;config.$cmd&quot;,&quot;uuid&quot;:{&quot;uuid&quot;:{&quot;$uuid&quot;:&quot;e7845007-46de-4e79-bfae-5f3f2c0f7219&quot;}},&quot;object&quot;:{&quot;createIndexes&quot;:&quot;system.sessions&quot;,&quot;v&quot;:2,&quot;key&quot;:{&quot;lastUse&quot;:1},&quot;name&quot;:&quot;lsidTTLIndex&quot;,&quot;expireAfterSeconds&quot;:1800}}} {&quot;t&quot;:{&quot;$date&quot;:&quot;2024-05-11T03:10:25.265+00:00&quot;},&quot;s&quot;:&quot;I&quot;, &quot;c&quot;:&quot;INDEX&quot;, &quot;id&quot;:20345, &quot;ctx&quot;:&quot;LogicalSessionCacheRefresh&quot;,&quot;msg&quot;:&quot;Index build: done building&quot;,&quot;attr&quot;:{&quot;buildUUID&quot;:null,&quot;collectionUUID&quot;:{&quot;uuid&quot;:{&quot;$uuid&quot;:&quot;e7845007-46de-4e79-bfae-5f3f2c0f7219&quot;}},&quot;namespace&quot;:&quot;config.system.sessions&quot;,&quot;index&quot;:&quot;_id_&quot;,&quot;ident&quot;:&quot;index-5-8856531098339113795&quot;,&quot;collectionIdent&quot;:&quot;collection-4-8856531098339113795&quot;,&quot;commitTimestamp&quot;:null}} {&quot;t&quot;:{&quot;$date&quot;:&quot;2024-05-11T03:10:25.265+00:00&quot;},&quot;s&quot;:&quot;I&quot;, &quot;c&quot;:&quot;INDEX&quot;, &quot;id&quot;:20345, &quot;ctx&quot;:&quot;LogicalSessionCacheRefresh&quot;,&quot;msg&quot;:&quot;Index build: done building&quot;,&quot;attr&quot;:{&quot;buildUUID&quot;:null,&quot;collectionUUID&quot;:{&quot;uuid&quot;:{&quot;$uuid&quot;:&quot;e7845007-46de-4e79-bfae-5f3f2c0f7219&quot;}},&quot;namespace&quot;:&quot;config.system.sessions&quot;,&quot;index&quot;:&quot;lsidTTLIndex&quot;,&quot;ident&quot;:&quot;index-6-8856531098339113795&quot;,&quot;collectionIdent&quot;:&quot;collection-4-8856531098339113795&quot;,&quot;commitTimestamp&quot;:null}} {&quot;t&quot;:{&quot;$date&quot;:&quot;2024-05-11T03:11:25.183+00:00&quot;},&quot;s&quot;:&quot;I&quot;, &quot;c&quot;:&quot;WTCHKPT&quot;, &quot;id&quot;:22430, &quot;ctx&quot;:&quot;Checkpointer&quot;,&quot;msg&quot;:&quot;WiredTiger message&quot;,&quot;attr&quot;:{&quot;message&quot;:{&quot;ts_sec&quot;:1715397085,&quot;ts_usec&quot;:183310,&quot;thread&quot;:&quot;1:0x7f9d8d2dc640&quot;,&quot;session_name&quot;:&quot;WT_SESSION.checkpoint&quot;,&quot;category&quot;:&quot;WT_VERB_CHECKPOINT_PROGRESS&quot;,&quot;category_id&quot;:6,&quot;verbose_level&quot;:&quot;DEBUG_1&quot;,&quot;verbose_level_id&quot;:1,&quot;msg&quot;:&quot;saving checkpoint snapshot min: 34, snapshot max: 34 snapshot count: 0, oldest timestamp: (0, 0) , meta checkpoint timestamp: (0, 0) base write gen: 1&quot;}}} {&quot;t&quot;:{&quot;$date&quot;:&quot;2024-05-11T03:11:52.775+00:00&quot;},&quot;s&quot;:&quot;I&quot;, &quot;c&quot;:&quot;NETWORK&quot;, &quot;id&quot;:22943, &quot;ctx&quot;:&quot;listener&quot;,&quot;msg&quot;:&quot;Connection accepted&quot;,&quot;attr&quot;:{&quot;remote&quot;:&quot;172.21.0.4:49540&quot;,&quot;uuid&quot;:{&quot;uuid&quot;:{&quot;$uuid&quot;:&quot;10e5dbd0-59ef-456c-9c44-582a0edd2b0b&quot;}},&quot;connectionId&quot;:1,&quot;connectionCount&quot;:1}} {&quot;t&quot;:{&quot;$date&quot;:&quot;2024-05-11T03:11:52.803+00:00&quot;},&quot;s&quot;:&quot;I&quot;, &quot;c&quot;:&quot;NETWORK&quot;, &quot;id&quot;:51800, &quot;ctx&quot;:&quot;conn1&quot;,&quot;msg&quot;:&quot;client metadata&quot;,&quot;attr&quot;:{&quot;remote&quot;:&quot;172.21.0.4:49540&quot;,&quot;client&quot;:&quot;conn1&quot;,&quot;negotiatedCompressors&quot;:[],&quot;doc&quot;:{&quot;driver&quot;:{&quot;name&quot;:&quot;mongo-java-driver&quot;,&quot;version&quot;:&quot;3.8.2&quot;},&quot;os&quot;:{&quot;type&quot;:&quot;Linux&quot;,&quot;name&quot;:&quot;Linux&quot;,&quot;architecture&quot;:&quot;amd64&quot;,&quot;version&quot;:&quot;6.6.22-linuxkit&quot;},&quot;platform&quot;:&quot;Java\/AdoptOpenJDK\/11.0.2+9&quot;}}} {&quot;t&quot;:{&quot;$date&quot;:&quot;2024-05-11T03:11:52.840+00:00&quot;},&quot;s&quot;:&quot;I&quot;, &quot;c&quot;:&quot;NETWORK&quot;, &quot;id&quot;:6788700, &quot;ctx&quot;:&quot;conn1&quot;,&quot;msg&quot;:&quot;Received first command on ingress connection since session start or auth handshake&quot;,&quot;attr&quot;:{&quot;elapsedMillis&quot;:36}} ##( 05\/10\/24@11:27PM )( donbuddenbaum@donbs-imac ):~\/Documents\/knote-java@master\u2717\u2717\u2717 docker run \u2013name=minio \u2013rm \u2013network=knote -e MINIO_ACCESS_KEY=mykey -e MINIO_SECRET_KEY=mysecret minio\/minio server \/data WARNING: MINIO_ACCESS_KEY and MINIO_SECRET_KEY are deprecated. Please use MINIO_ROOT_USER and MINIO_ROOT_PASSWORD Formatting 1st pool, 1 set(s), 1 drives per set. WARNING: Host local has more than 0 drives of set. A host failure will result in data becoming unavailable. MinIO Object Storage Server Copyright: 2015-2024 MinIO, Inc. License: GNU AGPLv3 - https:\/\/www.gnu.org\/licenses\/agpl-3.0.html Version: RELEASE.2024-05-10T01-41-38Z (go1.22.3 linux\/amd64) API: http:\/\/172.21.0.3:9000 http:\/\/127.0.0.1:9000 WebUI: http:\/\/172.21.0.3:36049 http:\/\/127.0.0.1:36049 Docs: https:\/\/min.io\/docs\/minio\/linux\/index.html Status: 1 Online, 0 Offline. STARTUP WARNINGS: - The standard parity is set to 0. This can lead to data loss. ##( 05\/10\/24@11:27PM )( donbuddenbaum@donbs-imac ):~\/Documents\/knote-java\/04-05@master\u2717\u2717\u2717 docker run \u2013name=knote-java \u2013rm \u2013network=knote -p 8080:8080 -e MONGO_URL=mongodb:\/\/mongo:27017\/dev -e MINIO_ACCESS_KEY=mykey -e MINIO_SECRET_KEY=mysecret -e MINIO_HOST=minio donb4iu\/knote-java:2.0.0 Picked up JAVA_TOOL_OPTIONS: . ____ _ __ _ _ \/\\\\ \/ ___'_ __ _ _(_)_ __ __ _ \\ \\ \\ \\ ( ( )\\___ | '_ | '_| | '_ \\\/ _` | \\ \\ \\ \\ \\\\\/ ___)| |_)| | | | | || (_| | ) ) ) ) ' |____| .__|_| |_|_| |_\\__, | \/ \/ \/ \/ =========|_|==============|___\/=\/_\/_\/_\/ :: Spring Boot :: (v2.1.6.RELEASE) 2024-05-11 03:29:14.585 INFO 1 --- [ main] io.learnk8s.knote.KnoteJavaApplication : Starting KnoteJavaApplication v1.0.0 on 732b0d8774f2 with PID 1 (\/opt\/app.jar started by root in \/opt) 2024-05-11 03:29:14.605 INFO 1 --- [ main] io.learnk8s.knote.KnoteJavaApplication : No active profile set, falling back to default profiles: default 2024-05-11 03:29:16.400 INFO 1 --- [ main] .s.d.r.c.RepositoryConfigurationDelegate : Bootstrapping Spring Data repositories in DEFAULT mode. 2024-05-11 03:29:16.497 INFO 1 --- [ main] .s.d.r.c.RepositoryConfigurationDelegate : Finished Spring Data repository scanning in 88ms. Found 1 repository interfaces. 2024-05-11 03:29:17.652 INFO 1 --- [ main] o.s.b.w.embedded.tomcat.TomcatWebServer : Tomcat initialized with port(s): 8080 (http) 2024-05-11 03:29:17.727 INFO 1 --- [ main] o.apache.catalina.core.StandardService : Starting service [Tomcat] 2024-05-11 03:29:17.728 INFO 1 --- [ main] org.apache.catalina.core.StandardEngine : Starting Servlet engine: [Apache Tomcat\/9.0.21] 2024-05-11 03:29:17.895 INFO 1 --- [ main] o.a.c.c.C.[Tomcat].[localhost].[\/] : Initializing Spring embedded WebApplicationContext 2024-05-11 03:29:17.896 INFO 1 --- [ main] o.s.web.context.ContextLoader : Root WebApplicationContext: initialization completed in 3192 ms 2024-05-11 03:29:18.565 INFO 1 --- [ main] org.mongodb.driver.cluster : Cluster created with settings {hosts=[mongo:27017], mode=SINGLE, requiredClusterType=UNKNOWN, serverSelectionTimeout='30000 ms', maxWaitQueueSize=500} 2024-05-11 03:29:18.727 INFO 1 --- [l'}-mongo:27017] org.mongodb.driver.connection : Opened connection [connectionId{localValue:1}] to mongo:27017 2024-05-11 03:29:18.735 INFO 1 --- [l'}-mongo:27017] org.mongodb.driver.cluster : Monitor thread successfully connected to server with description ServerDescription{address=mongo:27017, type=STANDALONE, state=CONNECTED, ok=true, version=ServerVersion{versionList=[7, 0, 9]}, minWireVersion=0, maxWireVersion=21, maxDocumentSize=16777216, logicalSessionTimeoutMinutes=30, roundTripTimeNanos=4861925} &gt; Minio initialized! 2024-05-11 03:29:20.207 INFO 1 --- [ main] o.s.s.concurrent.ThreadPoolTaskExecutor : Initializing ExecutorService 'applicationTaskExecutor' 2024-05-11 03:29:20.421 INFO 1 --- [ main] o.s.b.a.w.s.WelcomePageHandlerMapping : Adding welcome page template: index 2024-05-11 03:29:20.805 INFO 1 --- [ main] o.s.b.a.e.web.EndpointLinksResolver : Exposing 2 endpoint(s) beneath base path '\/actuator' 2024-05-11 03:29:20.926 INFO 1 --- [ main] o.s.b.w.embedded.tomcat.TomcatWebServer : Tomcat started on port(s): 8080 (http) with context path '' 2024-05-11 03:29:20.933 INFO 1 --- [ main] io.learnk8s.knote.KnoteJavaApplication : Started KnoteJavaApplication in 7.411 seconds (JVM running for 8.585) 2024-05-11 03:30:05.190 INFO 1 --- [nio-8080-exec-1] o.a.c.c.C.[Tomcat].[localhost].[\/] : Initializing Spring DispatcherServlet 'dispatcherServlet' 2024-05-11 03:30:05.191 INFO 1 --- [nio-8080-exec-1] o.s.web.servlet.DispatcherServlet : Initializing Servlet 'dispatcherServlet' 2024-05-11 03:30:05.214 INFO 1 --- [nio-8080-exec-1] o.s.web.servlet.DispatcherServlet : Completed initialization in 23 ms 2024-05-11 03:30:05.342 INFO 1 --- [nio-8080-exec-1] org.mongodb.driver.connection : Opened connection [connectionId{localValue:2}] to mongo:27017","tags":"","url":"java\/knotes.html"},{"title":"jupyter tensorflow","text":"Table of Contents Jupyter and Tensorflow References #Jupyter and Tensorflow #References Jupyter Notebook + TensorFlow on a Raspberry Pi\u2019s Kubernetes Cluster GitHub","tags":"","url":"jupyter_tensorflow\/jupyter_tensorflow.html"},{"title":"microk8s add ons","text":"Table of Contents MicroK8s Addons References #MicroK8s Addons #References The MicroK8s addons framework is now open to everyone","tags":"","url":"microk8s_add_ons.html"},{"title":"nfs-csi","text":"Table of Contents MicroK8s NFS CSI Reference Setup MicroK8s dbuddenbaum@arm64-01:~$ microk8s enable helm3 dbuddenbaum@arm64-01:~$ microk8s helm3 repo add csi-driver-nfs https:\/\/raw.githubusercontent.com\/kubernetes-csi\/csi-driver-nfs\/master\/charts dbuddenbaum@arm64-01:~$ microk8s helm3 repo update dbuddenbaum@arm64-01:~$ microk8s helm3 install csi-driver-nfs csi-driver-nfs\/csi-driver-nfs \u2013namespace kube-system \u2013set kubeletDir=\/var\/snap\/microk8s\/common\/var\/lib\/kubelet dbuddenbaum@arm64-01:~$ microk8s kubectl get csidrivers Storage Class and PV #( 02\/18\/24@ 5:15PM )( donbuddenbaum@donbs-imac ):~\/Documents\/Kalaxy2\/yaml\/microk8s\/nfs@main\u2717\u2717\u2717 #( 02\/18\/24@ 5:28PM )( donbuddenbaum@donbs-imac ):~\/Documents\/Kalaxy2\/yaml\/microk8s\/k8s-dashboard@main\u2717\u2717\u2717 dbuddenbaum@arm64-01:~$ microk8s kubectl describe pvc my-pvc #MicroK8s NFS CSI #Reference #Setup #MicroK8s #dbuddenbaum@arm64-01:~$ microk8s enable helm3 Infer repository core for addon helm3 Addon core\/helm3 is already enabled #dbuddenbaum@arm64-01:~$ microk8s helm3 repo add csi-driver-nfs https:\/\/raw.githubusercontent.com\/kubernetes-csi\/csi-driver-nfs\/master\/charts &quot;csi-driver-nfs&quot; has been added to your repositories #dbuddenbaum@arm64-01:~$ microk8s helm3 repo update Hang tight while we grab the latest from your chart repositories... ...Successfully got an update from the &quot;csi-driver-nfs&quot; chart repository Update Complete. \u2388Happy Helming!\u2388 #dbuddenbaum@arm64-01:~$ microk8s helm3 install csi-driver-nfs csi-driver-nfs\/csi-driver-nfs \u2013namespace kube-system \u2013set kubeletDir=\/var\/snap\/microk8s\/common\/var\/lib\/kubelet NAME: csi-driver-nfs LAST DEPLOYED: Sun Feb 18 17:42:07 2024 NAMESPACE: kube-system STATUS: deployed REVISION: 1 TEST SUITE: None NOTES: The CSI NFS Driver is getting deployed to your cluster. To check CSI NFS Driver pods status, please run: kubectl --namespace=kube-system get pods --selector=&quot;app.kubernetes.io\/instance=csi-driver-nfs&quot; --watch #dbuddenbaum@arm64-01:~$ microk8s kubectl get csidrivers NAME ATTACHREQUIRED PODINFOONMOUNT STORAGECAPACITY TOKENREQUESTS REQUIRESREPUBLISH MODES AGE nfs.csi.k8s.io false false false &lt;unset&gt; false Persistent 9m29s #Storage Class and PV ##( 02\/18\/24@ 5:15PM )( donbuddenbaum@donbs-imac ):~\/Documents\/Kalaxy2\/yaml\/microk8s\/nfs@main\u2717\u2717\u2717 kubectl apply -f sc-nfs.yaml storageclass.storage.k8s.io\/nfs-csi created #####( 02\/18\/24@ 5:19PM )( donbuddenbaum@donbs-imac ):~\/Documents\/Kalaxy2\/yaml\/microk8s\/nfs@main\u2717\u2717\u2717 kubectl apply -f pvc-nfs.yaml persistentvolumeclaim\/my-pvc created ##( 02\/18\/24@ 5:28PM )( donbuddenbaum@donbs-imac ):~\/Documents\/Kalaxy2\/yaml\/microk8s\/k8s-dashboard@main\u2717\u2717\u2717 kubectl get sc NAME PROVISIONER RECLAIMPOLICY VOLUMEBINDINGMODE ALLOWVOLUMEEXPANSION AGE nfs-csi nfs.csi.k8s.io Delete Immediate false 9m7s #dbuddenbaum@arm64-01:~$ microk8s kubectl describe pvc my-pvc Name: my-pvc Namespace: default StorageClass: nfs-csi Status: Bound Volume: pvc-84f2de83-f0cc-48f7-865d-e9ab6b77a9f0 Labels: &lt;none&gt; Annotations: pv.kubernetes.io\/bind-completed: yes pv.kubernetes.io\/bound-by-controller: yes volume.beta.kubernetes.io\/storage-provisioner: nfs.csi.k8s.io volume.kubernetes.io\/storage-provisioner: nfs.csi.k8s.io Finalizers: [kubernetes.io\/pvc-protection] Capacity: 5Gi Access Modes: RWO VolumeMode: Filesystem Used By: &lt;none&gt; Events: &lt;none&gt;","tags":"","url":"nfs\/nfs_csi.html"},{"title":"face recognition","text":"Table of Contents Face Recognition References Architecture Tech Stack System Design Overview Basic Requirements System Architecture Database Design Setup Dockerfile #( 06\/13\/24@ 3:54PM )( donbuddenbaum@donbs-imac ):~\/Documents\/rPi4\/Attendlytical\/client@main\u2717\u2717\u2717 #( 06\/13\/24@ 3:55PM )( donbuddenbaum@donbs-imac ):~\/Documents\/rPi4\/Attendlytical\/client@main\u2717\u2717\u2717 Client Deployment #( 06\/13\/24@ 4:32PM )( donbuddenbaum@donbs-imac ):~\/Documents\/Kalaxy2\/yaml\/face_recognition\/client@main\u2717\u2717\u2717 #( 06\/13\/24@ 4:33PM )( donbuddenbaum@donbs-imac ):~\/Documents\/Kalaxy2\/yaml\/face_recognition\/client@main\u2717\u2717\u2717 #( 06\/13\/24@ 4:33PM )( donbuddenbaum@donbs-imac ):~\/Documents\/Kalaxy2\/yaml\/face_recognition\/client@main\u2717\u2717\u2717 Server Deployment #( 06\/14\/24@11:15PM )( donbuddenbaum@donbs-imac ):~\/Documents\/Kalaxy2\/yaml\/face_recognition\/server@main\u2717\u2717\u2717 #Face Recognition #References DeepFace: A Library for Face Recognition and Facial Analysis Part I: Implement a Face Recognition Attendance System with face-api.js Part II: Implement a Face Recognition Attendance System with face-api.js Part III: Implement a Face Recognition Attendance System with face-api.js Part IV: Serverless Deployment with Netlify Lambda (ReactJS FE + GraphQL BE) Part V: Kubernetes Deployment with Minikube For A Full Stack Application (React + NodeJS + GraphQL) #Architecture #Tech Stack The overview architecture is the client-server and linked to the MongoDB. The client side will carry out all the procedure of face recognition such as face detection, facial landmark detection, feature extraction and feature matching. The extracted feature is sent over to the server and stored into the database. During the matching process, all the feature vectors are fetched accordingly to match with the detected feature vectors. #System Design Overview Design for the education institution\/college\/university. In the attendance system, there are 2 user roles which are lecturer and student. The lecturer can: add course, view course info, create the attendance, change the attendance system, join the attendance room (Face Matching occurs) and view attendance report. The student can: enrol course, view course info, upload face image (Face Registration occurs) , join attendance room and view attendance report. #Basic Requirements Attendance Form Attendance Transaction with Timestamp Display (Record earliest timestamp) Activate\/Deactivation of Attendance Transaction Attendance Report #System Architecture The system is a client-server architecture which contains several modules such as face registration module, face matching module, user module, attendance module and course module. Each module is backed by the resolver in the server to handle the respective GraphQL request query. #Database Design There is a total of 5 collections, namely \u201cPeople\u201d, \u201cFace Photo\u201d, \u201cCourse\u201d, \u201cAttendance\u201d and \u201cTrx\u201d. #Setup #Dockerfile docker buildx create --use docker buildx build --platform linux\/amd64,linux\/arm64 -f Dockerfile -t donb4iu\/attendlytical-client --push . run in attendlytical repo @ \/Users\/donbuddenbaum\/Documents\/rPi4\/Attendlytical\/client ##( 06\/13\/24@ 3:54PM )( donbuddenbaum@donbs-imac ):~\/Documents\/rPi4\/Attendlytical\/client@main\u2717\u2717\u2717 docker buildx create \u2013use gifted_burnell ##( 06\/13\/24@ 3:55PM )( donbuddenbaum@donbs-imac ):~\/Documents\/rPi4\/Attendlytical\/client@main\u2717\u2717\u2717 docker buildx build \u2013platform linux\/amd64,linux\/arm64 -f Dockerfile -t donb4iu\/attendlytical-client \u2013push . [+] Building 1017.6s (21\/21) FINISHED docker-container:gifted_burnell =&gt; [internal] booting buildkit 4.1s =&gt; =&gt; pulling image moby\/buildkit:buildx-stable-1 1.6s =&gt; =&gt; creating container buildx_buildkit_gifted_burnell0 2.5s =&gt; [internal] load build definition from Dockerfile 0.1s =&gt; =&gt; transferring dockerfile: 334B 0.0s =&gt; [linux\/arm64 internal] load metadata for docker.io\/library\/node:16-alpine 2.3s =&gt; [linux\/amd64 internal] load metadata for docker.io\/library\/node:16-alpine 2.2s =&gt; [auth] library\/node:pull token for registry-1.docker.io 0.0s =&gt; [internal] load .dockerignore 0.1s =&gt; =&gt; transferring context: 96B 0.0s =&gt; [linux\/amd64 1\/6] FROM docker.io\/library\/node:16-alpine@sha256:a1f9d027912b58a7c75be7716c97cfbc6d3099f3a97ed84aa490be9dee20e787 7.9s =&gt; =&gt; resolve docker.io\/library\/node:16-alpine@sha256:a1f9d027912b58a7c75be7716c97cfbc6d3099f3a97ed84aa490be9dee20e787 0.0s =&gt; =&gt; sha256:d9059661ce70092af66d2773666584fc8addcb78a2be63f720022f4875577ea9 452B \/ 452B 0.3s =&gt; =&gt; sha256:eee371b9ce3ffdbb8aa703b9a14d318801ddc3468f096bb6cfeabbeb715147f9 36.63MB \/ 36.63MB 4.1s =&gt; =&gt; sha256:7264a8db6415046d36d16ba98b79778e18accee6ffa71850405994cffa9be7de 3.40MB \/ 3.40MB 1.7s =&gt; =&gt; sha256:93b3025fe10392717d06ec0d012a9ffa2039d766a322aac899c6831dd93382c2 2.34MB \/ 2.34MB 0.7s =&gt; =&gt; extracting sha256:7264a8db6415046d36d16ba98b79778e18accee6ffa71850405994cffa9be7de 0.5s =&gt; =&gt; extracting sha256:eee371b9ce3ffdbb8aa703b9a14d318801ddc3468f096bb6cfeabbeb715147f9 2.8s =&gt; =&gt; extracting sha256:93b3025fe10392717d06ec0d012a9ffa2039d766a322aac899c6831dd93382c2 0.1s =&gt; =&gt; extracting sha256:d9059661ce70092af66d2773666584fc8addcb78a2be63f720022f4875577ea9 0.0s =&gt; [linux\/arm64 1\/6] FROM docker.io\/library\/node:16-alpine@sha256:a1f9d027912b58a7c75be7716c97cfbc6d3099f3a97ed84aa490be9dee20e787 27.0s =&gt; =&gt; resolve docker.io\/library\/node:16-alpine@sha256:a1f9d027912b58a7c75be7716c97cfbc6d3099f3a97ed84aa490be9dee20e787 0.0s =&gt; =&gt; sha256:6574fa54520867ff3b1634aa74c4749441c37892c2ee032cf292b798e4ee6770 448B \/ 448B 0.2s =&gt; =&gt; sha256:9d78f986cf6a87dbf98f64d646b5cfe3df77e1ce63b3097dd49a2ce2ac83d092 2.34MB \/ 2.34MB 0.4s =&gt; =&gt; sha256:ec2c8699950ec39d29e23b3e0880c1ceb06f9f62a698385f880207e6f600df29 36.45MB \/ 36.45MB 22.6s =&gt; =&gt; sha256:9fda8d8052c61740409c4bea888859c141fd8cc3f58ac61943144ff6d1681b2d 3.33MB \/ 3.33MB 0.9s =&gt; =&gt; extracting sha256:9fda8d8052c61740409c4bea888859c141fd8cc3f58ac61943144ff6d1681b2d 0.4s =&gt; =&gt; extracting sha256:ec2c8699950ec39d29e23b3e0880c1ceb06f9f62a698385f880207e6f600df29 3.5s =&gt; =&gt; extracting sha256:9d78f986cf6a87dbf98f64d646b5cfe3df77e1ce63b3097dd49a2ce2ac83d092 0.3s =&gt; =&gt; extracting sha256:6574fa54520867ff3b1634aa74c4749441c37892c2ee032cf292b798e4ee6770 0.0s =&gt; [internal] load build context 1.0s =&gt; =&gt; transferring context: 15.16MB 0.9s =&gt; [linux\/amd64 2\/6] RUN mkdir -p \/home\/node\/app\/node_modules &amp;&amp; chown -R node:node \/home\/node\/app 0.7s =&gt; [linux\/amd64 3\/6] WORKDIR \/home\/node\/app 0.0s =&gt; [linux\/amd64 4\/6] COPY --chown=node:node package*.json .\/ 0.1s =&gt; [linux\/amd64 5\/6] RUN npm install --legacy-peer-deps 127.8s =&gt; [linux\/arm64 2\/6] RUN mkdir -p \/home\/node\/app\/node_modules &amp;&amp; chown -R node:node \/home\/node\/app 0.8s =&gt; [linux\/arm64 3\/6] WORKDIR \/home\/node\/app 0.1s =&gt; [linux\/arm64 4\/6] COPY --chown=node:node package*.json .\/ 0.1s =&gt; [linux\/arm64 5\/6] RUN npm install --legacy-peer-deps 798.2s =&gt; [linux\/amd64 6\/6] COPY --chown=node:node . . 1.7s =&gt; [linux\/arm64 6\/6] COPY --chown=node:node . . 1.4s =&gt; exporting to image 182.3s =&gt; =&gt; exporting layers 34.2s =&gt; =&gt; exporting manifest sha256:324880f43e043e01c26d00d158da59a9c08cf16a7531668f183dee7a85e25b53 0.0s =&gt; =&gt; exporting config sha256:602412009279d60a71b681564de96024d6d11d28e9989678957f9e1a9557f9ef 0.0s =&gt; =&gt; exporting attestation manifest sha256:5bad34d7fb101e2c4eb0966a67d4c07f9a51b480327230284cf22774ffc3ad7c 0.0s =&gt; =&gt; exporting manifest sha256:6496728cec4c0d2ee0d322395c47087ed74af2b84aec379d7518283d72f358b9 0.0s =&gt; =&gt; exporting config sha256:351e41c848794aa33d17b3554b14deed6fe6547a5e5880f38cb0fb7ad9f92656 0.0s =&gt; =&gt; exporting attestation manifest sha256:a475ced0e9e35d0914d6b799a7b2d90aa58b5ab197be24abc20b8c9bd1842a97 0.0s =&gt; =&gt; exporting manifest list sha256:24a427f16e9c1cdfee89f19da16125fbbe057dc42e50b6006928cef02d23fb9d 0.0s =&gt; =&gt; pushing layers 146.6s =&gt; =&gt; pushing manifest for docker.io\/donb4iu\/attendlytical-client:latest@sha256:24a427f16e9c1cdfee89f19da16125fbbe057dc42e50b6006928cef02d23fb9d 1.3s =&gt; [auth] donb4iu\/attendlytical-client:pull,push token for registry-1.docker.io 0.0s Build multi-platform images faster with Docker Build Cloud: https:\/\/docs.docker.com\/go\/docker-build-cloud #Client Deployment ##( 06\/13\/24@ 4:32PM )( donbuddenbaum@donbs-imac ):~\/Documents\/Kalaxy2\/yaml\/face_recognition\/client@main\u2717\u2717\u2717 kubectl apply -f ns.yaml namespace\/attendlytical created ##( 06\/13\/24@ 4:33PM )( donbuddenbaum@donbs-imac ):~\/Documents\/Kalaxy2\/yaml\/face_recognition\/client@main\u2717\u2717\u2717 kubectl apply -f configmap.yaml configmap\/client-config created ##( 06\/13\/24@ 4:33PM )( donbuddenbaum@donbs-imac ):~\/Documents\/Kalaxy2\/yaml\/face_recognition\/client@main\u2717\u2717\u2717 kubectl apply -f deployment.yaml #Server Deployment ##( 06\/14\/24@11:15PM )( donbuddenbaum@donbs-imac ):~\/Documents\/Kalaxy2\/yaml\/face_recognition\/server@main\u2717\u2717\u2717 kubectl apply -f mongo-config.yml kubectl apply -f mongo-secret.yml kubectl apply -f mongo-pvc.yml kubectl apply -f mongo.yml kubectl apply -f mongo-express.yml kubectl apply -f cloudinary-secret.yml kubectl apply -f attendlytical-server.yml configmap\/mongo-config created secret\/mongo-secret created persistentvolumeclaim\/mongo-data-pvc created deployment.apps\/mongo-deployment created service\/mongo-service created deployment.apps\/mongo-express-deployment created service\/mongo-express-service created secret\/cloudinary-secret created deployment.apps\/server-deployment created service\/server-service created","tags":"","url":"nodejs\/face_recognition.html"},{"title":"minio","text":"Table of Contents Object Storage with MiniO Reference Setup #Object Storage with MiniO #Reference Create Your Local Object Storage with MiniO, PySpark, and Delta Lake medium-materials #Setup","tags":"","url":"object_storage\/minio.html"},{"title":"open project","text":"Table of Contents Open Project References #Open Project #References","tags":"","url":"project_management\/open_project.html"},{"title":"django cicd ecom k8s","text":"Table of Contents Django CICD eCommerce Kubernetes References App Setup (3.12.0-venv) #( 05\/28\/24@ 3:59PM )( donbuddenbaum@donbs-imac ):~\/Documents (3.12.0-venv) #( 05\/28\/24@ 4:10PM )( donbuddenbaum@donbs-imac ):~\/Documents\/django_multitenant_saas_ecommerce_kubernetes (3.12.0-venv) #( 05\/28\/24@ 4:17PM )( donbuddenbaum@donbs-imac ):~\/Documents\/django_multitenant_saas_ecommerce_kubernetes (3.12.0-venv) #( 05\/28\/24@ 4:59PM )( donbuddenbaum@donbs-imac ):~\/Documents\/django_multitenant_saas_ecommerce_kubernetes #Django CICD eCommerce Kubernetes #References Technical Guide: End-to-End CI\/CD DevOps with Jenkins, Terraform, Docker, Kubernetes, SonarQube, ArgoCD, AWS EC2, EKS, and GitHub Actions (Django Deployment) #App Setup #(3.12.0-venv) #( 05\/28\/24@ 3:59PM )( donbuddenbaum@donbs-imac ):~\/Documents django-admin startproject django_multitenant_saas_ecommerce_kubernetes #(3.12.0-venv) #( 05\/28\/24@ 4:10PM )( donbuddenbaum@donbs-imac ):~\/Documents\/django_multitenant_saas_ecommerce_kubernetes ls -la total 8 drwxr-xr-x 4 donbuddenbaum staff 128 May 28 16:06 . drwx------@ 99 donbuddenbaum staff 3168 May 28 16:06 .. drwxr-xr-x 7 donbuddenbaum staff 224 May 28 16:06 django_multitenant_saas_ecommerce_kubernetes -rwxr-xr-x 1 donbuddenbaum staff 700 May 28 16:06 manage.py #(3.12.0-venv) #( 05\/28\/24@ 4:17PM )( donbuddenbaum@donbs-imac ):~\/Documents\/django_multitenant_saas_ecommerce_kubernetes python manage.py runserver Watching for file changes with StatReloader Performing system checks... System check identified no issues (0 silenced). You have 18 unapplied migration(s). Your project may not work properly until you apply the migrations for app(s): admin, auth, contenttypes, sessions. Run 'python manage.py migrate' to apply them. May 28, 2024 - 20:30:19 Django version 5.0.6, using settings 'django_multitenant_saas_ecommerce_kubernetes.settings' Starting development server at http:\/\/127.0.0.1:8000\/ Quit the server with CONTROL-C. [28\/May\/2024 20:31:16] &quot;GET \/ HTTP\/1.1&quot; 200 10629 Not Found: \/favicon.ico [28\/May\/2024 20:31:17] &quot;GET \/favicon.ico HTTP\/1.1&quot; 404 2148 #(3.12.0-venv) #( 05\/28\/24@ 4:59PM )( donbuddenbaum@donbs-imac ):~\/Documents\/django_multitenant_saas_ecommerce_kubernetes mkdir apps\/app first python manage.py startapp app apps\/app python manage.py startapp home apps\/home","tags":"","url":"python\/django_cicd_ecom_k8s.html"},{"title":"environment","text":"Table of Contents Python Environment Reference Install (3.12.0-venv) #( 04\/23\/24@ 2:58PM )( donbuddenbaum@donbs-imac ):~\/Documents Setup #( 04\/22\/24@ 6:03PM )( donbuddenbaum@donbs-imac ):~ #( 04\/22\/24@ 6:03PM )( donbuddenbaum@donbs-imac ):~ #( 04\/22\/24@ 6:07PM )( donbuddenbaum@donbs-imac ):~ #( 04\/22\/24@ 6:15PM )( donbuddenbaum@donbs-imac ):~ Django #Python Environment #Reference The ultimate guide to managing Python virtual environments in MacOS zauberzeug \/ nicegui How to start a Python project with Django in 2020 The Ultimate Python Set Up: Pyenv + Poetry #Install #(3.12.0-venv) #( 04\/23\/24@ 2:58PM )( donbuddenbaum@donbs-imac ):~\/Documents pip install nicegui-highcharts #Setup ##( 04\/22\/24@ 6:03PM )( donbuddenbaum@donbs-imac ):~ pyenv \u2013help Usage: pyenv &lt;command&gt; [&lt;args&gt;] Some useful pyenv commands are: --version Display the version of pyenv activate Activate virtual environment commands List all available pyenv commands deactivate Deactivate virtual environment doctor Verify pyenv installation and development tools to build pythons. exec Run an executable with the selected Python version global Set or show the global Python version(s) help Display help for a command hooks List hook scripts for a given pyenv command init Configure the shell environment for pyenv install Install a Python version using python-build latest Print the latest installed or known version with the given prefix local Set or show the local application-specific Python version(s) prefix Display prefixes for Python versions rehash Rehash pyenv shims (run this after installing executables) root Display the root directory where versions and shims are kept shell Set or show the shell-specific Python version shims List existing pyenv shims uninstall Uninstall Python versions update Update pyenv, its plugins including the list of available versions version Show the current Python version(s) and its origin version-file Detect the file that sets the current pyenv version version-name Show the current Python version version-origin Explain how the current Python version is set versions List all Python versions available to pyenv virtualenv Create a Python virtualenv using the pyenv-virtualenv plugin virtualenv-delete Uninstall a specific Python virtualenv virtualenv-init Configure the shell environment for pyenv-virtualenv virtualenv-prefix Display real_prefix for a Python virtualenv version virtualenvs List all Python virtualenvs found in `$PYENV_ROOT\/versions\/*'. whence List all Python versions that contain the given executable which Display the full path to an executable See `pyenv help &lt;command&gt;' for information on a specific command. For full documentation, see: https:\/\/github.com\/pyenv\/pyenv#readme ##( 04\/22\/24@ 6:03PM )( donbuddenbaum@donbs-imac ):~ pyenv versions * system (set by \/Users\/donbuddenbaum\/.pyenv\/version) ##( 04\/22\/24@ 6:07PM )( donbuddenbaum@donbs-imac ):~ pyenv install 3.12.0 python-build: use openssl@3 from homebrew python-build: use readline from homebrew Downloading Python-3.12.0.tar.xz... -&gt; https:\/\/www.python.org\/ftp\/python\/3.12.0\/Python-3.12.0.tar.xz Installing Python-3.12.0... python-build: use tcl-tk from homebrew python-build: use readline from homebrew python-build: use ncurses from homebrew python-build: use zlib from xcode sdk Installed Python-3.12.0 to \/Users\/donbuddenbaum\/.pyenv\/versions\/3.12.0 ##( 04\/22\/24@ 6:15PM )( donbuddenbaum@donbs-imac ):~ pyenv versions * system (set by \/Users\/donbuddenbaum\/.pyenv\/version) 3.12.0 #Django","tags":"","url":"python\/environment.html"},{"title":"click","text":"Table of Contents Click Reference #Click #Reference click","tags":"","url":"python\/frameworks\/click.html"},{"title":"django","text":"Table of Contents Django References Django Commands Setup #( 05\/17\/24@10:18PM )( donbuddenbaum@donbs-imac ):~\/Documents\/pollapp\/mysite@main\u2717\u2717\u2717 #( 05\/17\/24@11:11PM )( donbuddenbaum@donbs-imac ):~\/Documents\/pollapp\/mysite@main\u2717\u2717\u2717 Super User (3.12.0-venv) #( 05\/18\/24@12:29AM )( donbuddenbaum@donbs-imac ):~\/Documents\/pollapp\/mysite@main\u2717\u2717\u2717 Database Testing (3.12.0-venv) #( 05\/18\/24@ 2:55AM )( donbuddenbaum@donbs-imac ):~\/Documents\/pollapp\/mysite@main\u2717\u2717\u2717 #Django #References How to install Django Writing your first Django app Introducing automated testing #Django Commands Command Cheatsheet Command Description . python -m venv (name_of_venv) Creates a virtual environment . source (venv)\/bin\/activate Activates a virtual environment . django-admin startproject (project_name) Starts a Django project , django-admin startproject (project_name) . Sets up a project in the same directory . python manage.py runserver Runs the Django server . python manage.py startapp (app_name) Creates a Django app #Setup check routes in urls.py ##( 05\/17\/24@10:18PM )( donbuddenbaum@donbs-imac ):~\/Documents\/pollapp\/mysite@main\u2717\u2717\u2717 python manage.py runserver Performing system checks... System check identified no issues (0 silenced). You have 18 unapplied migration(s). Your project may not work properly until you apply the migrations for app(s): admin, auth, contenttypes, sessions. Run 'python manage.py migrate' to apply them. May 18, 2024 - 02:18:44 Django version 5.0.4, using settings 'mysite.settings' Starting development server at http:\/\/127.0.0.1:8000\/ Quit the server with CONTROL-C. Not Found: \/ [18\/May\/2024 02:19:08] &quot;GET \/ HTTP\/1.1&quot; 404 2165 Not Found: \/po\/\/s [18\/May\/2024 02:19:57] &quot;GET \/po\/\/s HTTP\/1.1&quot; 404 2198 [18\/May\/2024 02:20:09] &quot;GET \/polls HTTP\/1.1&quot; 301 0 [18\/May\/2024 02:20:09] &quot;GET \/polls\/ HTTP\/1.1&quot; 200 40 Setup Database tables for installed apps ##( 05\/17\/24@11:11PM )( donbuddenbaum@donbs-imac ):~\/Documents\/pollapp\/mysite@main\u2717\u2717\u2717 python manage.py migrate Operations to perform: Apply all migrations: admin, auth, contenttypes, sessions Running migrations: Applying contenttypes.0001_initial... OK Applying auth.0001_initial... OK Applying admin.0001_initial... OK Applying admin.0002_logentry_remove_auto_add... OK Applying admin.0003_logentry_add_action_flag_choices... OK Applying contenttypes.0002_remove_content_type_name... OK Applying auth.0002_alter_permission_name_max_length... OK Applying auth.0003_alter_user_email_max_length... OK Applying auth.0004_alter_user_username_opts... OK Applying auth.0005_alter_user_last_login_null... OK Applying auth.0006_require_contenttypes_0002... OK Applying auth.0007_alter_validators_add_error_messages... OK Applying auth.0008_alter_user_username_max_length... OK Applying auth.0009_alter_user_last_name_max_length... OK Applying auth.0010_alter_group_name_max_length... OK Applying auth.0011_update_proxy_permissions... OK Applying auth.0012_alter_user_first_name_max_length... OK Applying sessions.0001_initial... OK #Super User #(3.12.0-venv) #( 05\/18\/24@12:29AM )( donbuddenbaum@donbs-imac ):~\/Documents\/pollapp\/mysite@main\u2717\u2717\u2717 python manage.py createsuperuser Username (leave blank to use 'donbuddenbaum'): admin Email address: dbuddenbaum@gmail.com Password: Password (again): Superuser created successfully. #Database database model and migration (pollapp) #Testing #(3.12.0-venv) #( 05\/18\/24@ 2:55AM )( donbuddenbaum@donbs-imac ):~\/Documents\/pollapp\/mysite@main\u2717\u2717\u2717 python manage.py test polls Found 1 test(s). Creating test database for alias 'default'... System check identified no issues (0 silenced). F ====================================================================== FAIL: test_was_published_recently_with_future_question (polls.tests.QuestionModelTests.test_was_published_recently_with_future_question) was_published_recently() returns False for questions whose pub_date ---------------------------------------------------------------------- Traceback (most recent call last): File &quot;\/Users\/donbuddenbaum\/Documents\/pollapp\/mysite\/polls\/tests.py&quot;, line 19, in test_was_published_recently_with_future_question self.assertIs(future_question.was_published_recently(), False) AssertionError: True is not False ---------------------------------------------------------------------- Ran 1 test in 0.002s FAILED (failures=1) Destroying test database for alias 'default'...","tags":"","url":"python\/frameworks\/django.html"},{"title":"nicegui","text":"Table of Contents NiceGUI Reference #NiceGUI #Reference Meet the NiceGUI: Your Soon-to-be Favorite Python UI Library NiceGUI Documentation","tags":"","url":"python\/nicegui.html"},{"title":"pollapp","text":"Table of Contents Python Polling App References Setup Project and pages Run project and pages #( 05\/17\/24@10:18PM )( donbuddenbaum@donbs-imac ):~\/Documents\/pollapp\/mysite@main\u2717\u2717\u2717 Setup database Edit the polls\/models.py file so it looks like this: Edit the mysite\/settings.py file include the polls app in database tables (3.12.0-venv) #( 05\/17\/24@11:49PM )( donbuddenbaum@donbs-imac ):~\/Documents\/pollapp\/mysite@main\u2717\u2717\u2717 run the migrations and manage database schema automatically (3.12.0-venv) #( 05\/17\/24@11:49PM )( donbuddenbaum@donbs-imac ):~\/Documents\/pollapp\/mysite@main\u2717\u2717\u2717 create those model tables in database: (3.12.0-venv) #( 05\/17\/24@11:51PM )( donbuddenbaum@donbs-imac ):~\/Documents\/pollapp\/mysite@main\u2717\u2717\u2717 query database with shell (3.12.0-venv) #( 05\/17\/24@11:57PM )( donbuddenbaum@donbs-imac ):~\/Documents\/pollapp\/mysite@main\u2717\u2717\u2717 #Python Polling App #References https:\/\/github.com\/donb4iu\/pollapp Writing your first Django app #Setup #Project and pages django-admin startproject mysite mysite\/ manage.py mysite\/ __init__.py settings.py urls.py asgi.py wsgi.py In the polls\/urls.py file include the following code: from django.urls import path from . import views urlpatterns = [ path(&quot;&quot;, views.index, name=&quot;index&quot;), ] In mysite\/urls.py from django.contrib import admin from django.urls import include, path urlpatterns = [ path(&quot;polls\/&quot;, include(&quot;polls.urls&quot;)), path(&quot;admin\/&quot;, admin.site.urls), ] #Run project and pages ##( 05\/17\/24@10:18PM )( donbuddenbaum@donbs-imac ):~\/Documents\/pollapp\/mysite@main\u2717\u2717\u2717 python manage.py runserver Watching for file changes with StatReloader Performing system checks... System check identified no issues (0 silenced). You have 18 unapplied migration(s). Your project may not work properly until you apply the migrations for app(s): admin, auth, contenttypes, sessions. Run 'python manage.py migrate' to apply them. May 18, 2024 - 02:18:44 Django version 5.0.4, using settings 'mysite.settings' Starting development server at http:\/\/127.0.0.1:8000\/ Quit the server with CONTROL-C. Not Found: \/ [18\/May\/2024 02:19:08] &quot;GET \/ HTTP\/1.1&quot; 404 2165 Not Found: \/po\/\/s [18\/May\/2024 02:19:57] &quot;GET \/po\/\/s HTTP\/1.1&quot; 404 2198 [18\/May\/2024 02:20:09] &quot;GET \/polls HTTP\/1.1&quot; 301 0 [18\/May\/2024 02:20:09] &quot;GET \/polls\/ HTTP\/1.1&quot; 200 40 #Setup database #Edit the polls\/models.py file so it looks like this: from django.db import models class Question(models.Model): question_text = models.CharField(max_length=200) pub_date = models.DateTimeField(&quot;date published&quot;) class Choice(models.Model): question = models.ForeignKey(Question, on_delete=models.CASCADE) choice_text = models.CharField(max_length=200) votes = models.IntegerField(default=0) #Edit the mysite\/settings.py file INSTALLED_APPS = [ &quot;polls.apps.PollsConfig&quot;, &quot;django.contrib.admin&quot;, &quot;django.contrib.auth&quot;, &quot;django.contrib.contenttypes&quot;, &quot;django.contrib.sessions&quot;, &quot;django.contrib.messages&quot;, &quot;django.contrib.staticfiles&quot;, ] #include the polls app in database tables #(3.12.0-venv) #( 05\/17\/24@11:49PM )( donbuddenbaum@donbs-imac ):~\/Documents\/pollapp\/mysite@main\u2717\u2717\u2717 python manage.py makemigrations polls Migrations for 'polls': polls\/migrations\/0001_initial.py - Create model Question - Create model Choice #run the migrations and manage database schema automatically #(3.12.0-venv) #( 05\/17\/24@11:49PM )( donbuddenbaum@donbs-imac ):~\/Documents\/pollapp\/mysite@main\u2717\u2717\u2717 python manage.py sqlmigrate polls 0001 BEGIN; -- -- Create model Question -- CREATE TABLE &quot;polls_question&quot; (&quot;id&quot; integer NOT NULL PRIMARY KEY AUTOINCREMENT, &quot;question_text&quot; varchar(200) NOT NULL, &quot;pub_date&quot; datetime NOT NULL); -- -- Create model Choice -- CREATE TABLE &quot;polls_choice&quot; (&quot;id&quot; integer NOT NULL PRIMARY KEY AUTOINCREMENT, &quot;choice_text&quot; varchar(200) NOT NULL, &quot;votes&quot; integer NOT NULL, &quot;question_id&quot; bigint NOT NULL REFERENCES &quot;polls_question&quot; (&quot;id&quot;) DEFERRABLE INITIALLY DEFERRED); CREATE INDEX &quot;polls_choice_question_id_c5b4b260&quot; ON &quot;polls_choice&quot; (&quot;question_id&quot;); COMMIT; #create those model tables in database: #(3.12.0-venv) #( 05\/17\/24@11:51PM )( donbuddenbaum@donbs-imac ):~\/Documents\/pollapp\/mysite@main\u2717\u2717\u2717 python manage.py migrate Operations to perform: Apply all migrations: admin, auth, contenttypes, polls, sessions Running migrations: Applying polls.0001_initial... OK #query database with shell &gt;&gt;&gt; from polls.models import Choice, Question # Import the model classes we just wrote. # No questions are in the system yet. &gt;&gt;&gt; Question.objects.all() &lt;QuerySet []&gt; # Create a new Question. # Support for time zones is enabled in the default settings file, so # Django expects a datetime with tzinfo for pub_date. Use timezone.now() # instead of datetime.datetime.now() and it will do the right thing. &gt;&gt;&gt; from django.utils import timezone &gt;&gt;&gt; q = Question(question_text=&quot;What's new?&quot;, pub_date=timezone.now()) # Save the object into the database. You have to call save() explicitly. &gt;&gt;&gt; q.save() # Now it has an ID. &gt;&gt;&gt; q.id 1 # Access model field values via Python attributes. &gt;&gt;&gt; q.question_text &quot;What's new?&quot; &gt;&gt;&gt; q.pub_date datetime.datetime(2012, 2, 26, 13, 0, 0, 775217, tzinfo=datetime.timezone.utc) # Change values by changing the attributes, then calling save(). &gt;&gt;&gt; q.question_text = &quot;What's up?&quot; &gt;&gt;&gt; q.save() # objects.all() displays all the questions in the database. &gt;&gt;&gt; Question.objects.all() &lt;QuerySet [&lt;Question: Question object (1)&gt;]&gt; #(3.12.0-venv) #( 05\/17\/24@11:57PM )( donbuddenbaum@donbs-imac ):~\/Documents\/pollapp\/mysite@main\u2717\u2717\u2717 python manage.py shell Python 3.12.0 (main, Apr 22 2024, 18:13:12) [Clang 15.0.0 (clang-1500.1.0.2.5)] on darwin Type &quot;help&quot;, &quot;copyright&quot;, &quot;credits&quot; or &quot;license&quot; for more information. (InteractiveConsole) from polls.models import Choice, Question Question.objects.all() &lt;QuerySet []&gt; from django.utils import timezone q = Question(question_text=\u201cWhat\u2019s new?\u201d, pub_date=timezone.now()) q.save() q.id 1 q.question_text \u201cWhat\u2019s new?\u201d q.pub_date datetime.datetime(2024, 5, 18, 4, 9, 55, 562224, tzinfo=datetime.timezone.utc) q.question_text = \u201cWhat\u2019s up?\u201d q.save() Question.objects.all() &lt;QuerySet [&lt;Question: Question object (1)&gt;]&gt;","tags":"","url":"python\/pollapp.html"},{"title":"references","text":"Table of Contents Index I N T #Index #I Nginx vs. Traefik: Which one you should choose? #N Nginx #T Traefik","tags":"","url":"references\/index.html"},{"title":"microk8s node","text":"Table of Contents Remove Microk8s node Reference Remove Microk8s dbuddenbaum@arm64-02:~$ microk8s leave dbuddenbaum@arm64-02:~$ sudo microk8s stop dbuddenbaum@arm64-01:~$ microk8s remove-node arm64-02 dbuddenbaum@arm64-02:~$ sudo microk8s disable dbuddenbaum@arm64-02:~$ sudo snap remove microk8s dbuddenbaum@arm64-02:~$ sudo rm -rf \/var\/snap\/microk8s\/ dbuddenbaum@arm64-02:~$ sudo rm -rf \/var\/snap\/microk8s-common\/ dbuddenbaum@arm64-02:~$ ps aux | grep microk8s dbuddenbaum@arm64-02:~$ sudo rm -rf \/etc\/kubernetes\/ #Remove Microk8s node #Reference How to Uninstall MicroK8s on Ubuntu 20.04 #Remove Microk8s #dbuddenbaum@arm64-02:~$ microk8s leave Configuring services. Generating new cluster certificates. Waiting for node to start. #dbuddenbaum@arm64-02:~$ sudo microk8s stop Stopped. #dbuddenbaum@arm64-01:~$ microk8s remove-node arm64-02 #dbuddenbaum@arm64-02:~$ sudo microk8s disable Usage: microk8s disable [OPTIONS] ADDONS... Try &quot;microk8s disable -h&quot; for help. Error: Missing argument &quot;ADDONS...&quot;. #dbuddenbaum@arm64-02:~$ sudo snap remove microk8s microk8s removed #dbuddenbaum@arm64-02:~$ sudo rm -rf \/var\/snap\/microk8s\/ #dbuddenbaum@arm64-02:~$ sudo rm -rf \/var\/snap\/microk8s-common\/ #dbuddenbaum@arm64-02:~$ ps aux | grep microk8s dbudden+ 33720 0.0 0.0 5968 664 pts\/0 S+ 15:43 0:00 grep --color=auto microk8s #dbuddenbaum@arm64-02:~$ sudo rm -rf \/etc\/kubernetes\/","tags":"","url":"remove\/microk8s\/microk8s_node.html"},{"title":"argocd","text":"Table of Contents Argo CD Reference Source dbuddenbaum@amd64-03:~$ microk8s enable community Setup #( 04\/09\/24@11:33PM )( donbuddenbaum@donbs-imac ):~\/Documents\/Kalaxy2\/yaml\/microk8s\/nfs@main\u2717\u2717\u2717 #( 04\/09\/24@11:33PM )( donbuddenbaum@donbs-imac ):~\/Documents\/Kalaxy2\/yaml\/microk8s\/nfs@main\u2717\u2717\u2717 #( 04\/09\/24@11:37PM )( donbuddenbaum@donbs-imac ):~\/Documents\/Kalaxy2\/yaml\/microk8s\/nfs@main\u2717\u2717\u2717 #( 04\/09\/24@11:38PM )( donbuddenbaum@donbs-imac ):~\/Documents\/Kalaxy2\/yaml\/microk8s\/nfs@main\u2717\u2717\u2717 Login #( 04\/09\/24@11:58PM )( donbuddenbaum@donbs-imac ):~ #( 04\/09\/24@11:59PM )( donbuddenbaum@donbs-imac ):~ Examples #Argo CD #Reference Addons in the Community Repository Argo CD - Declarative GitOps CD for Kubernetes ArgoCD Example Apps #Source #dbuddenbaum@amd64-03:~$ microk8s enable community Infer repository core for addon community Cloning into '\/var\/snap\/microk8s\/common\/addons\/community'... done. Community repository is now enabled #Setup ##( 04\/09\/24@11:33PM )( donbuddenbaum@donbs-imac ):~\/Documents\/Kalaxy2\/yaml\/microk8s\/nfs@main\u2717\u2717\u2717 kubectl create namespace argocd namespace\/argocd created ##( 04\/09\/24@11:33PM )( donbuddenbaum@donbs-imac ):~\/Documents\/Kalaxy2\/yaml\/microk8s\/nfs@main\u2717\u2717\u2717 kubectl apply -n argocd -f https:\/\/raw.githubusercontent.com\/argoproj\/argo-cd\/stable\/manifests\/install.yaml customresourcedefinition.apiextensions.k8s.io\/applications.argoproj.io created customresourcedefinition.apiextensions.k8s.io\/applicationsets.argoproj.io created customresourcedefinition.apiextensions.k8s.io\/appprojects.argoproj.io created serviceaccount\/argocd-application-controller created serviceaccount\/argocd-applicationset-controller created serviceaccount\/argocd-dex-server created serviceaccount\/argocd-notifications-controller created serviceaccount\/argocd-redis created serviceaccount\/argocd-repo-server created serviceaccount\/argocd-server created role.rbac.authorization.k8s.io\/argocd-application-controller created role.rbac.authorization.k8s.io\/argocd-applicationset-controller created role.rbac.authorization.k8s.io\/argocd-dex-server created role.rbac.authorization.k8s.io\/argocd-notifications-controller created role.rbac.authorization.k8s.io\/argocd-server created clusterrole.rbac.authorization.k8s.io\/argocd-application-controller created clusterrole.rbac.authorization.k8s.io\/argocd-applicationset-controller created clusterrole.rbac.authorization.k8s.io\/argocd-server created rolebinding.rbac.authorization.k8s.io\/argocd-application-controller created rolebinding.rbac.authorization.k8s.io\/argocd-applicationset-controller created rolebinding.rbac.authorization.k8s.io\/argocd-dex-server created rolebinding.rbac.authorization.k8s.io\/argocd-notifications-controller created rolebinding.rbac.authorization.k8s.io\/argocd-server created clusterrolebinding.rbac.authorization.k8s.io\/argocd-application-controller created clusterrolebinding.rbac.authorization.k8s.io\/argocd-applicationset-controller created clusterrolebinding.rbac.authorization.k8s.io\/argocd-server created configmap\/argocd-cm created configmap\/argocd-cmd-params-cm created configmap\/argocd-gpg-keys-cm created configmap\/argocd-notifications-cm created configmap\/argocd-rbac-cm created configmap\/argocd-ssh-known-hosts-cm created configmap\/argocd-tls-certs-cm created secret\/argocd-notifications-secret created secret\/argocd-secret created service\/argocd-applicationset-controller created service\/argocd-dex-server created service\/argocd-metrics created service\/argocd-notifications-controller-metrics created service\/argocd-redis created service\/argocd-repo-server created service\/argocd-server created service\/argocd-server-metrics created deployment.apps\/argocd-applicationset-controller created deployment.apps\/argocd-dex-server created deployment.apps\/argocd-notifications-controller created deployment.apps\/argocd-redis created deployment.apps\/argocd-repo-server created deployment.apps\/argocd-server created statefulset.apps\/argocd-application-controller created networkpolicy.networking.k8s.io\/argocd-application-controller-network-policy created networkpolicy.networking.k8s.io\/argocd-applicationset-controller-network-policy created networkpolicy.networking.k8s.io\/argocd-dex-server-network-policy created networkpolicy.networking.k8s.io\/argocd-notifications-controller-network-policy created networkpolicy.networking.k8s.io\/argocd-redis-network-policy created networkpolicy.networking.k8s.io\/argocd-repo-server-network-policy created ##( 04\/09\/24@11:37PM )( donbuddenbaum@donbs-imac ):~\/Documents\/Kalaxy2\/yaml\/microk8s\/nfs@main\u2717\u2717\u2717 kubectl patch svc argocd-server -n argocd -p \u2018{\u201cspec\u201d: {\u201ctype\u201d: \u201cLoadBalancer\u201d}}\u2019 service\/argocd-server patched ##( 04\/09\/24@11:38PM )( donbuddenbaum@donbs-imac ):~\/Documents\/Kalaxy2\/yaml\/microk8s\/nfs@main\u2717\u2717\u2717 kubectl get services \u2013all-namespaces NAMESPACE NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE argocd argocd-applicationset-controller ClusterIP 10.152.183.100 &lt;none&gt; 7000\/TCP,8080\/TCP 3m argocd argocd-dex-server ClusterIP 10.152.183.223 &lt;none&gt; 5556\/TCP,5557\/TCP,5558\/TCP 3m argocd argocd-metrics ClusterIP 10.152.183.60 &lt;none&gt; 8082\/TCP 3m argocd argocd-notifications-controller-metrics ClusterIP 10.152.183.185 &lt;none&gt; 9001\/TCP 3m argocd argocd-redis ClusterIP 10.152.183.241 &lt;none&gt; 6379\/TCP 3m argocd argocd-repo-server ClusterIP 10.152.183.134 &lt;none&gt; 8081\/TCP,8084\/TCP 3m argocd argocd-server LoadBalancer 10.152.183.253 192.168.2.24 80:31274\/TCP,443:32169\/TCP 3m argocd argocd-server-metrics ClusterIP 10.152.183.73 &lt;none&gt; 8083\/TCP 2m59s default kubernetes ClusterIP 10.152.183.1 &lt;none&gt; 443\/TCP 32d ingress ingress LoadBalancer 10.152.183.172 192.168.2.21 80:31990\/TCP,443:32252\/TCP 29d kube-system dashboard-metrics-scraper ClusterIP 10.152.183.110 &lt;none&gt; 8000\/TCP 29d kube-system k8s-dashboard LoadBalancer 10.152.183.107 192.168.2.20 443:31584\/TCP 32d kube-system kube-dns ClusterIP 10.152.183.10 &lt;none&gt; 53\/UDP,53\/TCP,9153\/TCP 32d kube-system kube-prom-stack-kube-prome-coredns ClusterIP None &lt;none&gt; 9153\/TCP 32d kube-system kube-prom-stack-kube-prome-kube-controller-manager ClusterIP None &lt;none&gt; 10257\/TCP 32d kube-system kube-prom-stack-kube-prome-kube-etcd ClusterIP None &lt;none&gt; 2381\/TCP 32d kube-system kube-prom-stack-kube-prome-kube-proxy ClusterIP None &lt;none&gt; 10249\/TCP 32d kube-system kube-prom-stack-kube-prome-kube-scheduler ClusterIP None &lt;none&gt; 10259\/TCP 32d kube-system kube-prom-stack-kube-prome-kubelet ClusterIP None &lt;none&gt; 10250\/TCP,10255\/TCP,4194\/TCP 32d kube-system kubernetes-dashboard ClusterIP 10.152.183.47 &lt;none&gt; 443\/TCP 29d kube-system metrics-server ClusterIP 10.152.183.244 &lt;none&gt; 443\/TCP 32d metallb-system webhook-service ClusterIP 10.152.183.40 &lt;none&gt; 443\/TCP 32d observability alertmanager-operated ClusterIP None &lt;none&gt; 9093\/TCP,9094\/TCP,9094\/UDP 32d observability grafana-dashboard LoadBalancer 10.152.183.114 192.168.2.22 80:31096\/TCP 29d observability kube-prom-stack-grafana ClusterIP 10.152.183.128 &lt;none&gt; 80\/TCP 32d observability kube-prom-stack-kube-prome-alertmanager ClusterIP 10.152.183.138 &lt;none&gt; 9093\/TCP 32d observability kube-prom-stack-kube-prome-operator ClusterIP 10.152.183.200 &lt;none&gt; 443\/TCP 32d observability kube-prom-stack-kube-prome-prometheus ClusterIP 10.152.183.69 &lt;none&gt; 9090\/TCP 32d observability kube-prom-stack-kube-state-metrics ClusterIP 10.152.183.167 &lt;none&gt; 8080\/TCP 32d observability kube-prom-stack-prometheus-node-exporter ClusterIP 10.152.183.159 &lt;none&gt; 9100\/TCP 32d observability loki ClusterIP 10.152.183.226 &lt;none&gt; 3100\/TCP 32d observability loki-headless ClusterIP None &lt;none&gt; 3100\/TCP 32d observability loki-memberlist ClusterIP None &lt;none&gt; 7946\/TCP 32d observability prometheus-dashboard LoadBalancer 10.152.183.196 192.168.2.23 80:32457\/TCP 29d observability prometheus-operated ClusterIP None &lt;none&gt; 9090\/TCP 32d observability tempo ClusterIP 10.152.183.59 &lt;none&gt; 3100\/TCP,16687\/TCP,16686\/TCP,6831\/UDP,6832\/UDP,14268\/TCP,14250\/TCP,9411\/TCP,55680\/TCP,55681\/TCP,4317\/TCP,4318\/TCP,55678\/TCP 32d #Login ##( 04\/09\/24@11:58PM )( donbuddenbaum@donbs-imac ):~ brew install argocd Running `brew update --auto-update`... . . . ==&gt; Downloading https:\/\/ghcr.io\/v2\/homebrew\/core\/argocd\/manifests\/2.10.6 ####################################################################################################################################################################################################################################################### 100.0% ==&gt; Fetching argocd ==&gt; Downloading https:\/\/ghcr.io\/v2\/homebrew\/core\/argocd\/blobs\/sha256:5992447e29db9177fdf758a81633ceb432e8e116ef76b63e9df09abaa7a15cce ####################################################################################################################################################################################################################################################### 100.0% ==&gt; Pouring argocd--2.10.6.ventura.bottle.tar.gz ==&gt; Caveats zsh completions have been installed to: \/usr\/local\/share\/zsh\/site-functions ==&gt; Summary \ud83c\udf7a \/usr\/local\/Cellar\/argocd\/2.10.6: 8 files, 159.3MB ==&gt; Running `brew cleanup argocd`... ##( 04\/09\/24@11:59PM )( donbuddenbaum@donbs-imac ):~ argocd admin initial-password -n argocd #Examples","tags":"","url":"setup\/argocd\/argocd.html"},{"title":"microk8s","text":"Table of Contents Setup MicroK8s Reference Setup ARM64 Init #( 02\/17\/24@10:43PM )( donbuddenbaum@donbs-imac ):~\/Documents\/Kalaxy2\/cloud-init-setup@main\u2714 Node pi@arm64-05:~$ sudo passwd dbuddenbaum #( 02\/18\/24@ 1:00AM )( donbuddenbaum@donbs-imac ):~\/Documents\/Kalaxy2\/cloud-init-setup@main\u2717\u2717\u2717 dbuddenbaum@donb-ms7821:~$ ssh-keygen -f \u201c\/home\/dbuddenbaum\/.ssh\/known_hosts\u201d -R \u201c192.168.2.51\u201d dbuddenbaum@arm64-05:~$ sudo snap install microk8s \u2013classic \u2013channel=1.29\/stable buddenbaum@arm64-01:~$ sudo microk8s add-node dbuddenbaum@arm64-05:~$ sudo usermod -a -G microk8s dbuddenbaum dbuddenbaum@arm64-05:~$ sudo chown -f -R dbuddenbaum ~\/.kubesudo chown -f -R dbuddenbaum ~\/.kube #### dbuddenbaum@arm64-05:~$ newgrp microk8s dbuddenbaum@arm64-05:~$ microk8s join 192.168.2.51:25000\/64fd2ec74c48cdd2d113805beead7a28\/307234781a84 \u2013worker dbuddenbaum@arm64-01:~$ microk8s config &gt; config Cluster dbuddenbaum@amd64-03:~$ microk8s enable dns dbuddenbaum@amd64-03:~$ microk8s enable dashboard #( 04\/09\/24@ 9:43PM )( donbuddenbaum@donbs-imac ):~ dbuddenbaum@amd64-03:~$ microk8s enable ingress dbuddenbaum@amd64-03:~$ microk8s enable metallb dbuddenbaum@amd64-03:~$ microk8s enable observability Dashboard #( 02\/18\/24@ 3:04PM )( donbuddenbaum@donbs-imac ):~\/Documents\/Kalaxy2\/yaml\/microk8s\/k8s-dashboard@main\u2717\u2717\u2717 #( 02\/18\/24@ 3:04PM )( donbuddenbaum@donbs-imac ):~\/Documents\/Kalaxy2\/yaml\/microk8s\/k8s-dashboard@main\u2717\u2717\u2717 Token with Duration #( 02\/18\/24@ 3:13PM )( donbuddenbaum@donbs-imac ):~\/Documents\/Kalaxy2\/yaml\/microk8s\/k8s-dashboard@main\u2717\u2717\u2717 #( 02\/18\/24@ 3:13PM )( donbuddenbaum@donbs-imac ):~\/Documents\/Kalaxy2\/yaml\/microk8s\/k8s-dashboard@main\u2717\u2717\u2717 Observability dbuddenbaum@arm64-01:~$ microk8s enable prometheus Grafana #( 02\/20\/24@ 6:54PM )( donbuddenbaum@donbs-imac ):~\/Documents\/Kalaxy2@main\u2717\u2717\u2717 #( 02\/20\/24@ 6:56PM )( donbuddenbaum@donbs-imac ):~\/Documents\/Kalaxy2@main\u2717\u2717\u2717 #( 02\/20\/24@ 7:47PM )( donbuddenbaum@donbs-imac ):~\/Documents\/Kalaxy2\/yaml\/microk8s\/prometheus@main\u2717\u2717\u2717 Config for Kubectl dbuddenbaum@arm64-01:~\/.kube$ #( 02\/29\/24@ 7:05PM )( donbuddenbaum@donbs-imac ):~\/.kube #( 02\/29\/24@ 7:05PM )( donbuddenbaum@donbs-imac ):~\/.kube #( 05\/07\/24@ 2:32PM )( donbuddenbaum@donbs-imac ):~ #Setup MicroK8s #Reference How to create a ServiceMonitor in Microk8s: Observability Tutorial #Setup #ARM64 Init ##( 02\/17\/24@10:43PM )( donbuddenbaum@donbs-imac ):~\/Documents\/Kalaxy2\/cloud-init-setup@main\u2714 flash \u2013userdata cloud-config-4.yml ~\/Downloads\/RPI-USB-BOOT.img Is \/dev\/disk2 correct? y Unmounting \/dev\/disk2 ... Unmount of all volumes on disk2 was successful Unmount of all volumes on disk2 was successful Flashing \/Users\/donbuddenbaum\/Downloads\/RPI-USB-BOOT.img to \/dev\/rdisk2 ... Password: 3.03GiB 0:01:30 [34.3MiB\/s] [=======================================================================================================================================================================================================================================================================================================================&gt;] 100% 0+49604 records in 3100+1 records out 3250806272 bytes transferred in 77.088032 secs (42170051 bytes\/sec) Mounting Disk Mounting \/dev\/disk2 to customize... Copying cloud-init cloud-config-4.yml to \/Volumes\/system-boot\/user-data ... Unmounting \/dev\/disk2 ... &quot;disk2&quot; ejected. Finished. #Node #pi@arm64-05:~$ sudo passwd dbuddenbaum New password: Retype new password: passwd: password updated successfully ##( 02\/18\/24@ 1:00AM )( donbuddenbaum@donbs-imac ):~\/Documents\/Kalaxy2\/cloud-init-setup@main\u2717\u2717\u2717 ssh-copy-id dbuddenbaum@192.168.2.54 \/usr\/bin\/ssh-copy-id: INFO: Source of key(s) to be installed: &quot;\/Users\/donbuddenbaum\/.ssh\/id_rsa.pub&quot; \/usr\/bin\/ssh-copy-id: INFO: attempting to log in with the new key(s), to filter out any that are already installed \/usr\/bin\/ssh-copy-id: INFO: 1 key(s) remain to be installed -- if you are prompted now it is to install the new keys dbuddenbaum@192.168.2.54's password: Number of key(s) added: 1 Now try logging into the machine, with: &quot;ssh 'dbuddenbaum@192.168.2.54'&quot; and check to make sure that only the key(s) you wanted were added.## #dbuddenbaum@donb-ms7821:~$ ssh-keygen -f \u201c\/home\/dbuddenbaum\/.ssh\/known_hosts\u201d -R \u201c192.168.2.51\u201d # Host 192.168.2.51 found: line 2 \/home\/dbuddenbaum\/.ssh\/known_hosts updated. Original contents retained as \/home\/dbuddenbaum\/.ssh\/known_hosts.old #dbuddenbaum@arm64-05:~$ sudo snap install microk8s \u2013classic \u2013channel=1.29\/stable microk8s (1.29\/stable) v1.29.0 from Canonical\u2713 installed #buddenbaum@arm64-01:~$ sudo microk8s add-node From the node you wish to join to this cluster, run the following: microk8s join 192.168.2.51:25000\/64fd2ec74c48cdd2d113805beead7a28\/307234781a84 Use the '--worker' flag to join a node as a worker not running the control plane, eg: microk8s join 192.168.2.51:25000\/64fd2ec74c48cdd2d113805beead7a28\/307234781a84 --worker If the node you are adding is not reachable through the default interface you can use one of the following: microk8s join 192.168.2.51:25000\/64fd2ec74c48cdd2d113805beead7a28\/307234781a84 microk8s join 2603:6081:1e00:1075:dea6:32ff:febb:c8bf:25000\/64fd2ec74c48cdd2d113805beead7a28\/307234781a84 #dbuddenbaum@arm64-05:~$ sudo usermod -a -G microk8s dbuddenbaum #dbuddenbaum@arm64-05:~$ sudo chown -f -R dbuddenbaum ~\/.kubesudo chown -f -R dbuddenbaum ~\/.kube ##### dbuddenbaum@arm64-05:~$ newgrp microk8s #dbuddenbaum@arm64-05:~$ microk8s join 192.168.2.51:25000\/64fd2ec74c48cdd2d113805beead7a28\/307234781a84 \u2013worker Contacting cluster at 192.168.2.51 The node has joined the cluster and will appear in the nodes list in a few seconds. This worker node gets automatically configured with the API server endpoints. If the API servers are behind a loadbalancer please set the '--refresh-interval' to '0s' in: \/var\/snap\/microk8s\/current\/args\/apiserver-proxy and replace the API server endpoints with the one provided by the loadbalancer in: \/var\/snap\/microk8s\/current\/args\/traefik\/provider.yaml Successfully joined the cluster. #dbuddenbaum@arm64-01:~$ microk8s config &gt; config cd .kube rsync dbuddenbaum@amd64-03:~\/.kube\/config config #Cluster #dbuddenbaum@amd64-03:~$ microk8s enable dns Infer repository core for addon dns Addon core\/dns is already enabled #dbuddenbaum@amd64-03:~$ microk8s enable dashboard Infer repository core for addon dashboard Enabling Kubernetes Dashboard Infer repository core for addon metrics-server Enabling Metrics-Server serviceaccount\/metrics-server created clusterrole.rbac.authorization.k8s.io\/system:aggregated-metrics-reader created clusterrole.rbac.authorization.k8s.io\/system:metrics-server created rolebinding.rbac.authorization.k8s.io\/metrics-server-auth-reader created clusterrolebinding.rbac.authorization.k8s.io\/metrics-server:system:auth-delegator created clusterrolebinding.rbac.authorization.k8s.io\/system:metrics-server created service\/metrics-server created deployment.apps\/metrics-server created apiservice.apiregistration.k8s.io\/v1beta1.metrics.k8s.io created clusterrolebinding.rbac.authorization.k8s.io\/microk8s-admin created Adding argument --authentication-token-webhook to nodes. Metrics-Server is enabled Applying manifest serviceaccount\/kubernetes-dashboard created service\/kubernetes-dashboard created secret\/kubernetes-dashboard-certs created secret\/kubernetes-dashboard-csrf created secret\/kubernetes-dashboard-key-holder created configmap\/kubernetes-dashboard-settings created role.rbac.authorization.k8s.io\/kubernetes-dashboard created clusterrole.rbac.authorization.k8s.io\/kubernetes-dashboard created rolebinding.rbac.authorization.k8s.io\/kubernetes-dashboard created clusterrolebinding.rbac.authorization.k8s.io\/kubernetes-dashboard created deployment.apps\/kubernetes-dashboard created service\/dashboard-metrics-scraper created deployment.apps\/dashboard-metrics-scraper created secret\/microk8s-dashboard-token created If RBAC is not enabled access the dashboard using the token retrieved with: microk8s kubectl describe secret -n kube-system microk8s-dashboard-token Use this token in the https login UI of the kubernetes-dashboard service. In an RBAC enabled setup (microk8s enable RBAC) you need to create a user with restricted permissions as shown in: https:\/\/github.com\/kubernetes\/dashboard\/blob\/master\/docs\/user\/access-control\/creating-sample-user.md ##( 04\/09\/24@ 9:43PM )( donbuddenbaum@donbs-imac ):~ kubectl patch \u2013namespace kube-system deployment kubernetes-dashboard \u2013type=\u2018json\u2019 \u2013patch \u2018[{\u201cop\u201d: \u201cadd\u201d, \u201cpath\u201d: \u201c\/spec\/template\/spec\/containers\/0\/args\/2\u201d, \u201cvalue\u201d: \u201c\u2013token-ttl=43200\u201d }]\u2019 deployment.apps\/kubernetes-dashboard patched #dbuddenbaum@amd64-03:~$ microk8s enable ingress Infer repository core for addon ingress Enabling Ingress ingressclass.networking.k8s.io\/public created ingressclass.networking.k8s.io\/nginx created namespace\/ingress created serviceaccount\/nginx-ingress-microk8s-serviceaccount created clusterrole.rbac.authorization.k8s.io\/nginx-ingress-microk8s-clusterrole created role.rbac.authorization.k8s.io\/nginx-ingress-microk8s-role created clusterrolebinding.rbac.authorization.k8s.io\/nginx-ingress-microk8s created rolebinding.rbac.authorization.k8s.io\/nginx-ingress-microk8s created configmap\/nginx-load-balancer-microk8s-conf created configmap\/nginx-ingress-tcp-microk8s-conf created configmap\/nginx-ingress-udp-microk8s-conf created daemonset.apps\/nginx-ingress-microk8s-controller created Ingress is enabled #dbuddenbaum@amd64-03:~$ microk8s enable metallb Enabling MetalLB Enter each IP address range delimited by comma (e.g. '10.64.140.43-10.64.140.49,192.168.0.105-192.168.0.111'): 192.168.2.20-192.168.2.49 Applying Metallb manifest customresourcedefinition.apiextensions.k8s.io\/addresspools.metallb.io created customresourcedefinition.apiextensions.k8s.io\/bfdprofiles.metallb.io created customresourcedefinition.apiextensions.k8s.io\/bgpadvertisements.metallb.io created customresourcedefinition.apiextensions.k8s.io\/bgppeers.metallb.io created customresourcedefinition.apiextensions.k8s.io\/communities.metallb.io created customresourcedefinition.apiextensions.k8s.io\/ipaddresspools.metallb.io created customresourcedefinition.apiextensions.k8s.io\/l2advertisements.metallb.io created namespace\/metallb-system created serviceaccount\/controller created serviceaccount\/speaker created clusterrole.rbac.authorization.k8s.io\/metallb-system:controller created clusterrole.rbac.authorization.k8s.io\/metallb-system:speaker created role.rbac.authorization.k8s.io\/controller created role.rbac.authorization.k8s.io\/pod-lister created clusterrolebinding.rbac.authorization.k8s.io\/metallb-system:controller created clusterrolebinding.rbac.authorization.k8s.io\/metallb-system:speaker created rolebinding.rbac.authorization.k8s.io\/controller created secret\/webhook-server-cert created service\/webhook-service created rolebinding.rbac.authorization.k8s.io\/pod-lister created daemonset.apps\/speaker created deployment.apps\/controller created validatingwebhookconfiguration.admissionregistration.k8s.io\/validating-webhook-configuration created Waiting for Metallb controller to be ready. error: timed out waiting for the condition on deployments\/controller MetalLB controller is still not ready deployment.apps\/controller condition met ipaddresspool.metallb.io\/default-addresspool created l2advertisement.metallb.io\/default-advertise-all-pools created MetalLB is enabled dbuddenbaum@amd64-03:~$ microk8s enable helm3 Infer repository core for addon helm3 Addon core\/helm3 is already enabled #dbuddenbaum@amd64-03:~$ microk8s enable observability Infer repository core for addon observability Addon core\/dns is already enabled Addon core\/helm3 is already enabled Enabling default storage class. WARNING: Hostpath storage is not suitable for production environments. A hostpath volume can grow beyond the size limit set in the volume claim manifest. deployment.apps\/hostpath-provisioner created storageclass.storage.k8s.io\/microk8s-hostpath created serviceaccount\/microk8s-hostpath created clusterrole.rbac.authorization.k8s.io\/microk8s-hostpath created clusterrolebinding.rbac.authorization.k8s.io\/microk8s-hostpath created Storage will be available soon. Enabling observability Release &quot;kube-prom-stack&quot; does not exist. Installing it now. NAME: kube-prom-stack LAST DEPLOYED: Fri Mar 8 19:55:55 2024 NAMESPACE: observability STATUS: deployed REVISION: 1 NOTES: kube-prometheus-stack has been installed. Check its status by running: kubectl --namespace observability get pods -l &quot;release=kube-prom-stack&quot; Visit https:\/\/github.com\/prometheus-operator\/kube-prometheus for instructions on how to create &amp; configure Alertmanager and Prometheus instances using the Operator. Release &quot;loki&quot; does not exist. Installing it now. NAME: loki LAST DEPLOYED: Fri Mar 8 19:56:53 2024 NAMESPACE: observability STATUS: deployed REVISION: 1 NOTES: The Loki stack has been deployed to your cluster. Loki can now be added as a datasource in Grafana. See http:\/\/docs.grafana.org\/features\/datasources\/loki\/ for more detail. Release &quot;tempo&quot; does not exist. Installing it now. NAME: tempo LAST DEPLOYED: Fri Mar 8 19:56:56 2024 NAMESPACE: observability STATUS: deployed REVISION: 1 TEST SUITE: None Adding argument --authentication-kubeconfig to nodes. Adding argument --authorization-kubeconfig to nodes. Restarting nodes. Adding argument --authentication-kubeconfig to nodes. Adding argument --authorization-kubeconfig to nodes. Restarting nodes. The connection to the server 127.0.0.1:16443 was refused - did you specify the right host or port? Failed to list nodes (try 1): Command '['\/snap\/microk8s\/6641\/microk8s-kubectl.wrapper', 'get', 'node', '-o', 'json']' returned non-zero exit status 1. Adding argument --metrics-bind-address to nodes. Restarting nodes. The connection to the server 127.0.0.1:16443 was refused - did you specify the right host or port? Failed to list nodes (try 1): Command '['\/snap\/microk8s\/6641\/microk8s-kubectl.wrapper', 'get', 'node', '-o', 'json']' returned non-zero exit status 1. Note: the observability stack is setup to monitor only the current nodes of the MicroK8s cluster. For any nodes joining the cluster at a later stage this addon will need to be set up again. Observability has been enabled (user\/pass: admin\/prom-operator) #Dashboard ##( 02\/18\/24@ 3:04PM )( donbuddenbaum@donbs-imac ):~\/Documents\/Kalaxy2\/yaml\/microk8s\/k8s-dashboard@main\u2717\u2717\u2717 kubectl apply -f k8s-dashboard-adminuser.yaml serviceaccount\/admin-user created clusterrolebinding.rbac.authorization.k8s.io\/admin-user created ##( 02\/18\/24@ 3:04PM )( donbuddenbaum@donbs-imac ):~\/Documents\/Kalaxy2\/yaml\/microk8s\/k8s-dashboard@main\u2717\u2717\u2717 kubectl apply -f k8s-dashboard-lb-svc.yaml service\/k8s-dashboard created #Token with Duration ##( 02\/18\/24@ 3:13PM )( donbuddenbaum@donbs-imac ):~\/Documents\/Kalaxy2\/yaml\/microk8s\/k8s-dashboard@main\u2717\u2717\u2717 kubectl -n kube-system create token admin-user \u2013duration=720h \ud83d\ude00 ##( 02\/18\/24@ 3:13PM )( donbuddenbaum@donbs-imac ):~\/Documents\/Kalaxy2\/yaml\/microk8s\/k8s-dashboard@main\u2717\u2717\u2717 kubectl get service -n kube-system NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE kube-dns ClusterIP 10.152.183.10 &lt;none&gt; 53\/UDP,53\/TCP,9153\/TCP 17h metrics-server ClusterIP 10.152.183.50 &lt;none&gt; 443\/TCP 14h kubernetes-dashboard ClusterIP 10.152.183.91 &lt;none&gt; 443\/TCP 14h dashboard-metrics-scraper ClusterIP 10.152.183.147 &lt;none&gt; 8000\/TCP 14h k8s-dashboard LoadBalancer 10.152.183.90 192.168.2.20 443:30545\/TCP 21m Kubernetes Dashboard Adjusting the timeout of the Kubernetes Dashboard kubectl patch --namespace kubernetes-dashboard deployment \\ kubernetes-dashboard --type='json' --patch \\ '[{&quot;op&quot;: &quot;add&quot;, &quot;path&quot;: &quot;\/spec\/template\/spec\/containers\/0\/args\/2&quot;, &quot;value&quot;: &quot;--token-ttl=43200&quot; }]' or #Observability #dbuddenbaum@arm64-01:~$ microk8s enable prometheus Infer repository core for addon prometheus DEPRECATION WARNING: 'prometheus' is deprecated and will soon be removed. Please use 'observability' instead. Infer repository core for addon observability Addon core\/dns is already enabled Addon core\/helm3 is already enabled Enabling default storage class. WARNING: Hostpath storage is not suitable for production environments. A hostpath volume can grow beyond the size limit set in the volume claim manifest. deployment.apps\/hostpath-provisioner created storageclass.storage.k8s.io\/microk8s-hostpath created serviceaccount\/microk8s-hostpath created clusterrole.rbac.authorization.k8s.io\/microk8s-hostpath created clusterrolebinding.rbac.authorization.k8s.io\/microk8s-hostpath created Storage will be available soon. Enabling observability Release &quot;kube-prom-stack&quot; does not exist. Installing it now. NAME: kube-prom-stack LAST DEPLOYED: Sun Feb 18 18:11:07 2024 NAMESPACE: observability STATUS: deployed REVISION: 1 NOTES: kube-prometheus-stack has been installed. Check its status by running: kubectl --namespace observability get pods -l &quot;release=kube-prom-stack&quot; Visit https:\/\/github.com\/prometheus-operator\/kube-prometheus for instructions on how to create &amp; configure Alertmanager and Prometheus instances using the Operator. Release &quot;loki&quot; does not exist. Installing it now. NAME: loki LAST DEPLOYED: Sun Feb 18 18:12:34 2024 NAMESPACE: observability STATUS: deployed REVISION: 1 NOTES: The Loki stack has been deployed to your cluster. Loki can now be added as a datasource in Grafana. See http:\/\/docs.grafana.org\/features\/datasources\/loki\/ for more detail. Release &quot;tempo&quot; does not exist. Installing it now. NAME: tempo LAST DEPLOYED: Sun Feb 18 18:12:40 2024 NAMESPACE: observability STATUS: deployed REVISION: 1 TEST SUITE: None Adding argument --authentication-kubeconfig to nodes. Adding argument --authorization-kubeconfig to nodes. Restarting nodes. The connection to the server 127.0.0.1:16443 was refused - did you specify the right host or port? Failed to list nodes (try 1): Command '['\/snap\/microk8s\/6357\/microk8s-kubectl.wrapper', 'get', 'node', '-o', 'json']' returned non-zero exit status 1. Adding argument --authentication-kubeconfig to nodes. Adding argument --authorization-kubeconfig to nodes. Restarting nodes. The connection to the server 127.0.0.1:16443 was refused - did you specify the right host or port? Failed to list nodes (try 1): Command '['\/snap\/microk8s\/6357\/microk8s-kubectl.wrapper', 'get', 'node', '-o', 'json']' returned non-zero exit status 1. Adding argument --metrics-bind-address to nodes. Restarting nodes. The connection to the server 127.0.0.1:16443 was refused - did you specify the right host or port? Failed to list nodes (try 1): Command '['\/snap\/microk8s\/6357\/microk8s-kubectl.wrapper', 'get', 'node', '-o', 'json']' returned non-zero exit status 1. Note: the observability stack is setup to monitor only the current nodes of the MicroK8s cluster. For any nodes joining the cluster at a later stage this addon will need to be set up again. Observability has been enabled (user\/pass: admin\/prom-operator) #Grafana ##( 02\/20\/24@ 6:54PM )( donbuddenbaum@donbs-imac ):~\/Documents\/Kalaxy2@main\u2717\u2717\u2717 kubectl get deployment -n observability NAME READY UP-TO-DATE AVAILABLE AGE kube-prom-stack-kube-prome-operator 1\/1 1 1 2d kube-prom-stack-kube-state-metrics 1\/1 1 1 2d kube-prom-stack-grafana 1\/1 1 1 2d ##( 02\/20\/24@ 6:56PM )( donbuddenbaum@donbs-imac ):~\/Documents\/Kalaxy2@main\u2717\u2717\u2717 kubectl port-forward deployment\/kube-prom-stack-grafana -n observability 3000 Forwarding from 127.0.0.1:3000 -&gt; 3000 Forwarding from [::1]:3000 -&gt; 3000 or for loadbalancer ##( 02\/20\/24@ 7:47PM )( donbuddenbaum@donbs-imac ):~\/Documents\/Kalaxy2\/yaml\/microk8s\/prometheus@main\u2717\u2717\u2717 kubectl apply -f grafana-lb-svc.yaml service\/grafana-dashboard configured #Config for Kubectl #dbuddenbaum@arm64-01:~\/.kube$ microk8s config &gt; config ##( 02\/29\/24@ 7:05PM )( donbuddenbaum@donbs-imac ):~\/.kube rsync dbuddenbaum@arm64-01:~\/.kube\/config config ##( 02\/29\/24@ 7:05PM )( donbuddenbaum@donbs-imac ):~\/.kube ls Untitled.pdf config.ha config.k8s.rpi4.old cache config.imac config.rpi4.opensource config config.k8s http-cache ##( 05\/07\/24@ 2:32PM )( donbuddenbaum@donbs-imac ):~ rsync -azP dbuddenbaum@arm64-05:~\/.kube\/config ~\/.kube\/config receiving file list ... 1 file to consider config 5462 100% 5.21MB\/s 0:00:00 (xfer#1, to-check=0\/1) sent 38 bytes received 3676 bytes 1061.14 bytes\/sec total size is 5462 speedup is 1.47","tags":"","url":"setup\/microk8s.html"},{"title":"minio","text":"Table of Contents Minio References Setup dbuddenbaum@arm64-01:~$ Setup Node Storage dbuddenbaum@arm64-01:~$ dbuddenbaum@arm64-01:~$ dbuddenbaum@amd64-03:~$ dbuddenbaum@arm64-01:~$ dbuddenbaum@arm64-01:~$ sudo mkdir \/mnt\/hdisk dbuddenbaum@arm64-01:~$ sudo mount \/dev\/sdb \/mnt\/hdisk dbuddenbaum@arm64-01:~$ dbuddenbaum@arm64-01:~$ dbuddenbaum@arm64-02:~$ dbuddenbaum@amd64-03:~$ #Minio #References Easy Guide: Setting Up Minio with MicroK8s Kubernetes https:\/\/github.com\/minio\/operator #Setup #dbuddenbaum@arm64-01:~$ sudo microk8s enable minio -c 300Gi -s openebs-jiva-csi-default Infer repository core for addon minio Infer repository core for addon dns Addon core\/dns is already enabled Infer repository core for addon hostpath-storage Addon core\/hostpath-storage is already enabled Download kubectl-minio % Total % Received % Xferd Average Speed Time Time Time Current Dload Upload Total Spent Left Speed 0 0 0 0 0 0 0 0 --:--:-- --:--:-- --:--:-- 0 100 35.6M 100 35.6M 0 0 9495k 0 0:00:03 0:00:03 --:--:-- 10.9M Initialize minio operator namespace\/minio-operator created serviceaccount\/minio-operator created clusterrole.rbac.authorization.k8s.io\/minio-operator-role created clusterrolebinding.rbac.authorization.k8s.io\/minio-operator-binding created customresourcedefinition.apiextensions.k8s.io\/tenants.minio.min.io created service\/operator created deployment.apps\/minio-operator created serviceaccount\/console-sa created secret\/console-sa-secret created clusterrole.rbac.authorization.k8s.io\/console-sa-role created clusterrolebinding.rbac.authorization.k8s.io\/console-sa-binding created configmap\/console-env created service\/console created deployment.apps\/console created ----------------- To open Operator UI, start a port forward using this command: kubectl minio proxy -n minio-operator ----------------- Create default tenant with: Name: microk8s Capacity: 300Gi Servers: 1 Volumes: 1 Storage class: openebs-jiva-csi-default TLS: no Prometheus: no + \/var\/snap\/microk8s\/common\/plugins\/kubectl-minio tenant create microk8s --storage-class openebs-jiva-csi-default --capacity 300Gi --servers 1 --volumes 1 --namespace minio-operator --enable-audit-logs=false --disable-tls --enable-prometheus=false W0229 21:14:49.752537 71434 warnings.go:70] unknown field &quot;spec.pools[0].volumeClaimTemplate.metadata.creationTimestamp&quot; Tenant 'microk8s' created in 'minio-operator' Namespace Username: ICNSF7L1666PNW0K0TBO Password: pc9pNbTlBsotppIH6hjuB9KUMRxQaeeItkI1bZif Note: Copy the credentials to a secure location. MinIO will not display these again. APPLICATION SERVICE NAME NAMESPACE SERVICE TYPE SERVICE PORT MinIO minio minio-operator ClusterIP 80 Console microk8s-console minio-operator ClusterIP 9090 + set +x ================================ Enabled minio addon. You can manage minio tenants using the kubectl-minio plugin. For more details, use microk8s kubectl-minio --help #Setup Node Storage #dbuddenbaum@arm64-01:~$ lsblk -f NAME FSTYPE LABEL UUID FSAVAIL FSUSE% MOUNTPOINT loop0 squashfs 0 100% \/snap\/core18\/1883 loop1 squashfs 0 100% \/snap\/core20\/2107 loop2 squashfs 0 100% \/snap\/lxd\/24065 loop3 squashfs 0 100% \/snap\/core18\/2810 loop4 squashfs 0 100% \/snap\/core20\/2186 loop5 squashfs 0 100% \/snap\/lxd\/16103 loop6 squashfs 0 100% \/snap\/microk8s\/6357 loop7 squashfs 0 100% \/snap\/snapd\/20674 loop8 squashfs 0 100% \/snap\/microk8s\/6564 sda \u251c\u2500sda1 vfat system-boot B726-57E2 81.7M 68% \/boot\/firmware \u2514\u2500sda2 ext4 writable 483efb12-d682-4daf-9b34-6e2f774b56f7 201G 5% \/ sdb \u2514\u2500sdb1 vfat UNTITLED B1E2-1721 #dbuddenbaum@arm64-01:~$ fdisk dev\/sdb Welcome to fdisk (util-linux 2.34). Changes will remain in memory only, until you decide to write them. Be careful before using the write command. Command (m for help): d Selected partition 1 Partition 1 has been deleted. Command (m for help): w The partition table has been altered. Calling ioctl() to re-read partition table. Syncing disks. #dbuddenbaum@amd64-03:~$ sudo mkfs.ext4 \/dev\/sdb mke2fs 1.45.5 (07-Jan-2020) Found a dos partition table in \/dev\/sdb Proceed anyway? (y,N) y Creating filesystem with 244190646 4k blocks and 61054976 inodes Filesystem UUID: 95ec5a28-daf8-475a-b6f0-06b20d1f154f Superblock backups stored on blocks: 32768, 98304, 163840, 229376, 294912, 819200, 884736, 1605632, 2654208, 4096000, 7962624, 11239424, 20480000, 23887872, 71663616, 78675968, 102400000, 214990848 Allocating group tables: done Writing inode tables: done Creating journal (262144 blocks): done Writing superblocks and filesystem accounting information: done #dbuddenbaum@arm64-01:~$ lsblk -f NAME FSTYPE LABEL UUID FSAVAIL FSUSE% MOUNTPOINT loop0 squashfs 0 100% \/snap\/core18\/1883 loop1 squashfs 0 100% \/snap\/core20\/2107 loop2 squashfs 0 100% \/snap\/lxd\/24065 loop3 squashfs 0 100% \/snap\/core18\/2810 loop4 squashfs 0 100% \/snap\/core20\/2186 loop5 squashfs 0 100% \/snap\/lxd\/16103 loop6 squashfs 0 100% \/snap\/microk8s\/6357 loop7 squashfs 0 100% \/snap\/snapd\/20674 loop8 squashfs 0 100% \/snap\/microk8s\/6564 sda \u251c\u2500sda1 vfat system-boot B726-57E2 81.7M 68% \/boot\/firmware \u2514\u2500sda2 ext4 writable 483efb12-d682-4daf-9b34-6e2f774b56f7 201G 5% \/ sdb ext4 95ec5a28-daf8-475a-b6f0-06b20d1f154f #dbuddenbaum@arm64-01:~$ sudo mkdir \/mnt\/hdisk #dbuddenbaum@arm64-01:~$ sudo mount \/dev\/sdb \/mnt\/hdisk #dbuddenbaum@arm64-01:~$ lsblk -f NAME FSTYPE LABEL UUID FSAVAIL FSUSE% MOUNTPOINT loop0 squashfs 0 100% \/snap\/core18\/1883 loop1 squashfs 0 100% \/snap\/core20\/2107 loop2 squashfs 0 100% \/snap\/lxd\/24065 loop3 squashfs 0 100% \/snap\/core18\/2810 loop4 squashfs 0 100% \/snap\/core20\/2186 loop5 squashfs 0 100% \/snap\/lxd\/16103 loop6 squashfs 0 100% \/snap\/microk8s\/6357 loop7 squashfs 0 100% \/snap\/snapd\/20674 loop8 squashfs 0 100% \/snap\/microk8s\/6564 sda \u251c\u2500sda1 vfat system-boot B726-57E2 81.7M 68% \/boot\/firmware \u2514\u2500sda2 ext4 writable 483efb12-d682-4daf-9b34-6e2f774b56f7 200.9G 5% \/ sdb ext4 95ec5a28-daf8-475a-b6f0-06b20d1f154f 869.2G 0% \/mnt\/hdisk #dbuddenbaum@arm64-01:~$ sudo vi \/etc\/fstab UUID=95ec5a28-daf8-475a-b6f0-06b20d1f154f \/mnt\/hdisk ext4 defaults 0 0 #dbuddenbaum@arm64-02:~$ microk8s stop 2024-02-29T20:22:57-05:00 INFO Waiting for &quot;snap.microk8s.daemon-k8s-dqlite.service&quot; to stop. Stopped. #dbuddenbaum@amd64-03:~$ sudo reboot","tags":"","url":"setup\/minio.html"},{"title":"notes","text":"Table of Contents Installation Notes Raspberry Pi Monitoring make up Flash AMD64 static ip ssh swapfile update\/upgrade Add User Change password SUDO Copy Id getting events from kubernetes Persistent Volume update secutiry fixes temperature probe amd64 Updating Linux #Installation Notes Build Bare Metal Kubernetes Dualstack Calico Metallb RaspberryPI 4 Ubuntu Server 64bit. (64bit required!!!) Force all pods in a specific namespace to schedule on defined hosts with Kubernetes Control Pod Placement to Projects Understanding and using the Kubernetes PodNodeSelector Admission Controller k8s HA cluster installation Fabian Lee : Software Engineer Install Ubuntu Desktop 20.04 LTS on Raspberry Pi 4 Installing fully-fledged vanilla Kubernetes on Raspberry Pi #Raspberry Pi Monitoring sudo apt-get update &amp;&amp; sudo apt-get install htop -y #make up xcode-select --install #Flash flash --userdata setup\/cloud-config.yml ~\/Downloads\/ubuntu-20.04-preinstalled-server-arm64+raspi.img #AMD64 #static ip (AMD) sudo vim \/etc\/netplan\/01-netcfg.yaml (ARM) \/etc\/netplan\/50-cloud-init.yaml network: version: 2 ethernets: eth0: dhcp4: false addresses: [192.168.2.5?\/16] gateway4: 192.168.2.253 nameservers: addresses: [192.168.2.253, 8.8.8.8, 8.8.4.4] sudo netplan apply ip address #ssh sudo apt install ssh sudo systemctl enable \u2013now ssh sudo systemctl status ssh #swapfile sudo vim \/etc\/fstab #\/swapfile sudo reboot or sudo poweroff #update\/upgrade su #Add User How To Use visudo Sudo nopasswd: How to run commands as root without a password? sudo adduser -u 1200 &lt;username&gt; #Change password pi@arm64-05:~$ sudo passwd dbuddenbaum New password: Retype new password: passwd: password updated successfully #SUDO sudo visudo dbuddenbaum ALL=(ALL) NOPASSWD:ALL &lt;&lt;&lt;&lt;&lt;&lt;&lt; HEAD #Copy Id ssh-copy-id pi@$ip_address ======= ssh-copy-id dbuddenbaum@192.168.2.58 \/usr\/bin\/ssh-copy-id: INFO: Source of key(s) to be installed: &quot;\/Users\/donbuddenbaum\/.ssh\/id_rsa.pub&quot; \/usr\/bin\/ssh-copy-id: INFO: attempting to log in with the new key(s), to filter out any that are already installed \/usr\/bin\/ssh-copy-id: INFO: 1 key(s) remain to be installed -- if you are prompted now it is to install the new keys dbuddenbaum@192.168.2.58's password: Number of key(s) added: 1 Now try logging into the machine, with: &quot;ssh 'dbuddenbaum@192.168.2.58'&quot; and check to make sure that only the key(s) you wanted were added. 38d6a03510f3dafb5c27383383689baf396cd5ce dbuddenbaum@amd64-worker-03:~$ sudo vim \/etc\/sysctl.d\/99-kubernetes-cri.conf net.bridge.bridge-nf-call-iptables=1 \/usr\/sbin\/sysctl net.bridge.bridge-nf-call-iptables=1 \/usr\/sbin\/sysctl\/net.bridge.bridge-nf-call-iptables=1 net.bridge.bridge-nf-call-ip6tables=1 net.bridge.bridge-nf-call-arptables=1 sudo modprobe br_netfilter install Ceph on ARM64 SBCs using Rook - kubernetes-xenial main v1.9.3 dbuddenbaum@amd64-worker-03:~$ echo \u201cdeb http:\/\/packages.azlux.fr\/debian\/ buster main\u201d | sudo tee \/etc\/apt\/sources.list.d\/azlux.list deb http:\/\/packages.azlux.fr\/debian\/ buster main dbuddenbaum@amd64-worker-03:~$ wget -qO - https:\/\/azlux.fr\/repo.gpg.key | sudo apt-key add - OK dbuddenbaum@amd64-worker-03:~$ sudo apt update Hit:1 http:\/\/us.archive.ubuntu.com\/ubuntu focal InRelease Building dependency tree Reading state information... Done All packages are up to date. N: Skipping acquire of configured file 'stable\/binary-i386\/Packages' as repository 'https:\/\/download.docker.com\/linux\/ubuntu focal InRelease' doesn't support architecture 'i386' dbuddenbaum@amd64-worker-03:~$ sudo apt install log2ram Reading package lists... Done Building dependency tree Reading state information... Done The following packages were automatically installed and are no longer required: conntrack cri-tools ebtables socat Use 'sudo apt autoremove' to remove them. The following NEW packages will be installed: log2ram 0 upgraded, 1 newly installed, 0 to remove and 0 not upgraded. Need to get 4288 B of archives. After this operation, 0 B of additional disk space will be used. Get:1 http:\/\/packages.azlux.fr\/debian buster\/main amd64 log2ram all 1.6.0 [4288 B] Fetched 4288 B in 1s (7037 B\/s) Selecting previously unselected package log2ram. (Reading database ... 107469 files and directories currently installed.) Preparing to unpack ...\/archives\/log2ram_1.6.0_all.deb ... Unpacking log2ram (1.6.0) ... Setting up log2ram (1.6.0) ... Created symlink \/etc\/systemd\/system\/sysinit.target.wants\/log2ram.service \u2192 \/etc\/systemd\/system\/log2ram.service. Created symlink \/etc\/systemd\/system\/timers.target.wants\/log2ram-daily.timer \u2192 \/etc\/systemd\/system\/log2ram-daily.timer. ##### Reboot to activate log2ram ##### ##### edit \/etc\/log2ram.conf to configure options #### make OPTS=\u2013limit=amd64-worker-xx up fix token kubeadm token create -&gt; build\/k8s-token dbuddenbaum@arm64-master-01:~$ sudo kubeadm token create \u2013print-join-command W1017 21:24:48.048542 1003621 validation.go:28] Cannot validate kube-proxy config - no validator is available W1017 21:24:48.048690 1003621 validation.go:28] Cannot validate kubelet config - no validator is available kubeadm join 192.168.2.50:6443 --token 1lzi9g.q1e5iabf9ct3khwe --discovery-token-ca-cert-hash sha256:758ae780462b33c21506c4052e4e1de8ddec35ffc167a931fa1cd6f85ff9ede3 dbuddenbaum@amd64-worker-02:~$ sudo kubeadm join 192.168.2.50:6443 \u2013token 1lzi9g.q1e5iabf9ct3khwe \u2013discovery-token-ca-cert-hash sha256:758ae780462b33c21506c4052e4e1de8ddec35ffc167a931fa1cd6f85ff9ede3 W1018 01:26:30.473800 6631 join.go:346] [preflight] WARNING: JoinControlPane.controlPlane settings will be ignored when control-plane flag is not set. [preflight] Running pre-flight checks [WARNING IsDockerSystemdCheck]: detected &quot;cgroupfs&quot; as the Docker cgroup driver. The recommended driver is &quot;systemd&quot;. Please follow the guide at https:\/\/kubernetes.io\/docs\/setup\/cri\/ [preflight] Reading configuration from the cluster... [preflight] FYI: You can look at this config file with 'kubectl -n kube-system get cm kubeadm-config -oyaml' [kubelet-start] Downloading configuration for the kubelet from the &quot;kubelet-config-1.17&quot; ConfigMap in the kube-system namespace [kubelet-start] Writing kubelet configuration to file &quot;\/var\/lib\/kubelet\/config.yaml&quot; [kubelet-start] Writing kubelet environment file with flags to file &quot;\/var\/lib\/kubelet\/kubeadm-flags.env&quot; [kubelet-start] Starting the kubelet [kubelet-start] Waiting for the kubelet to perform the TLS Bootstrap... This node has joined the cluster: * Certificate signing request was sent to apiserver and a response was received. * The Kubelet was informed of the new secure connection details. Run 'kubectl get nodes' on the control-plane to see this node join the cluster. #getting events from kubernetes kubectl get events \u2013all-namespaces \u2013sort-by=\u2019.metadata.creationTimestamp\u2019 #Persistent Volume #update secutiry fixes apt-get update sudo apt-get install -y \u2013only-upgrade $( apt-get \u2013just-print upgrade | awk \u2018tolower($4) ~ \/.security.\/ || tolower($5) ~ \/.security.\/ {print $2}\u2019 | sort | uniq ) ###cgroups for intel One aspect I want to point out is setting the cgroup for use by kubeadm. If you choose to use Docker as your container runtime, you should set it to use the cgroup systemd rather than cgroupfs as explained here. In \/etc\/docker\/daemon.conf { &quot;exec-opts&quot;: [&quot;native.cgroupdriver=systemd&quot;], &quot;log-driver&quot;: &quot;json-file&quot;, &quot;log-opts&quot;: { &quot;max-size&quot;: &quot;100m&quot; }, &quot;storage-driver&quot;: &quot;overlay2&quot; } Then reload sudo systemctl daemon-reload sudo systemctl restart docker #temperature probe amd64 sudo apt-get install lm-sensors sudo service kmod start dbuddenbaum@amd64-05:~$ sensors coretemp-isa-0000 Adapter: ISA adapter Core 0: +70.0\u00b0C (high = +74.0\u00b0C, crit = +100.0\u00b0C) Core 1: +63.0\u00b0C (high = +74.0\u00b0C, crit = +100.0\u00b0C) Core 2: +65.0\u00b0C (high = +74.0\u00b0C, crit = +100.0\u00b0C) Core 3: +64.0\u00b0C (high = +74.0\u00b0C, crit = +100.0\u00b0C) sudo sensors-detect #Updating Linux sudo apt-get update sudo apt-get upgrade sudo reboot","tags":"","url":"setup\/notes.html"},{"title":"podnodeselector","text":"Table of Contents Namespaces by node architecture Enable-admission-plugins=PodNodeSelector MicroK8s Enable-admission-plugins=PodNodeSelector K8s Create Namespace amd64default arm64default How to assign a namespace to certain node architectures #Namespaces by node architecture #Enable-admission-plugins=PodNodeSelector MicroK8s dbuddenbaum@amd64-03:~$ vi \/var\/snap\/microk8s\/current\/args\/kube-apiserver #Enable-admission-plugins=PodNodeSelector K8s dbuddenbaum@amd64-02:\/etc\/kubernetes\/manifests$ sudo vi kube-apiserver.yaml apiVersion: v1 kind: Pod metadata: annotations: kubeadm.kubernetes.io\/kube-apiserver.advertise-address.endpoint: 192.168.2.56:6443 creationTimestamp: null labels: component: kube-apiserver tier: control-plane name: kube-apiserver namespace: kube-system spec: containers: - command: - kube-apiserver - --advertise-address=192.168.2.56 - --allow-privileged=true - --authorization-mode=Node,RBAC - --client-ca-file=\/etc\/kubernetes\/pki\/ca.crt - --enable-admission-plugins=NodeRestriction,PodNodeSelector #Create Namespace #amd64default apiVersion: v1 kind: Namespace metadata: name: amd64default annotations: scheduler.alpha.kubernetes.io\/node-selector: kubernetes.io\/arch=amd64 spec: {} status: {} #arm64default apiVersion: v1 kind: Namespace metadata: name: arm64default annotations: scheduler.alpha.kubernetes.io\/node-selector: kubernetes.io\/arch=arm64 spec: {} status: {}","tags":"","url":"setup\/podnodeselector.html"},{"title":"README","text":"Table of Contents Ubuntu Downloads the Flash tool Download and extract the image Flash Boot USB Boot #Ubuntu The following instructions are to flash your SD card with the desired OS and configuration specified in the cloud-init config. See https:\/\/cloudinit.readthedocs.io\/en\/latest\/ for more details. cloud-init cloud-init-doc #Downloads the Flash tool sudo curl -L \"https:\/\/github.com\/hypriot\/flash\/releases\/download\/2.5.0\/flash\" -o \/usr\/local\/bin\/flash sudo chmod +x \/usr\/local\/bin\/flash #Download and extract the image curl -L \"http:\/\/cdimage.ubuntu.com\/releases\/focal\/release\/ubuntu-20.04-preinstalled-server-arm64+raspi.img.xz\" -o ~\/Downloads\/ubuntu-20.04-preinstalled-server-arm64+raspi.img.xz unxz -T 0 ~\/Downloads\/ubuntu-20.04-preinstalled-server-arm64+raspi.img.xz #Flash flash --userdata setup\/cloud-config.yml ~\/Downloads\/ubuntu-20.04.2-preinstalled-server-arm64+raspi.img #Boot Place the SD Card in your RPi and give the system approx ~10 minutes to boot before trying to SSH. #USB Boot ####( 09\/06\/21@ 1:00AM )( donbuddenbaum@donbs-iMac ):~\/Documents\/rPi4\/kalaxy@main\u2717\u2717\u2717 flash \\ --userdata setup\/cloud-config-5.yml \\ ~\/Downloads\/ubuntu-20.04.2-preinstalled-server-arm64+raspi.img Is \/dev\/disk3 correct? flash --userdata setup\/cloud-config-4.yml ~\/Downloads\/RPI-USB-BOOT.img switch to USB drive to trick flash remove the card, reboot, and then add the card to solve the boot requirement. so the rPi looks for a new boot devices Is \/dev\/disk3 correct? y Unmounting \/dev\/disk3 ... Unmount of all volumes on disk3 was successful Unmount of all volumes on disk3 was successful Flashing \/Users\/donbuddenbaum\/Downloads\/ubuntu-20.04.2-preinstalled-server-arm64+raspi.img to \/dev\/rdisk3 ... Password:","tags":"","url":"setup\/README.html"},{"title":"rpi usb ubuntu","text":"Table of Contents USB RPI 4 Boot for Ubuntu #USB RPI 4 Boot for Ubuntu RPI4 Direct USB Boot Ubuntu 20.04 #( 09\/13\/21@11:43PM )( donbuddenbaum@donbs-iMac ):~\/Documents\/rPi4\/kalaxy@main\u2717\u2717\u2717 flash \u2013userdata setup\/cloud-config-4.yml ~\/Downloads\/RPI-USB-BOOT.img Is \/dev\/disk2 correct? y Unmounting \/dev\/disk2 ... Unmount of all volumes on disk2 was successful Unmount of all volumes on disk2 was successful Flashing \/Users\/donbuddenbaum\/Downloads\/RPI-USB-BOOT.img to \/dev\/rdisk2 ... 3.03GiB 0:01:21 [38.1MiB\/s] [====================================================================================================================================================================================================================================================================================================&gt;] 100% 0+49604 records in 0+49604 records out 3250806272 bytes transferred in 81.256937 secs (40006508 bytes\/sec) Mounting Disk Mounting \/dev\/disk2 to customize... Copying cloud-init setup\/cloud-config-4.yml to \/Volumes\/system-boot\/user-data ... Unmounting \/dev\/disk2 ... &quot;disk2&quot; ejected. Finished.","tags":"","url":"setup\/rpi_usb_ubuntu.html"},{"title":"k8s cmd ref","text":"Table of Contents K8s Command Reference References #K8s Command Reference #References The guide to kubectl I never had.","tags":"","url":"utilities\/k8s_cmd_ref.html"},{"title":"k9s","text":"Table of Contents K9s References Setup Brew #( 02\/05\/22@11:04PM )( dbuddenbaum@donb-mbp4 ):~ Docker #( 11\/22\/22@ 3:43PM )( donbuddenbaum@donbs-imac ):~ #K9s #References K9s - Kubernetes CLI To Manage Your Clusters In Style! Use Docker to Run K9s to Manage a Kubernetes Cluster #Setup #Brew ##( 02\/05\/22@11:04PM )( dbuddenbaum@donb-mbp4 ):~ brew install derailed\/k9s\/k9s Running `brew update --preinstall`... ==&gt; Homebrew is run entirely by unpaid volunteers. Please consider donating: https:\/\/github.com\/Homebrew\/brew#donations ==&gt; Auto-updated Homebrew! Updated 1 tap (homebrew\/core). ==&gt; New Formulae ascii2binary ffmpeg@4 reshape asyncapi ghcup rure atlas http-prompt terminalimageviewer canfigger inotify-tools tfschema elixir-ls juliaup tidy-viewer elvis libadwaita usbutils esphome linode-cli vermin fdroidcl odo-dev weggli ==&gt; Updated Formulae Updated 799 formulae. ==&gt; Tapping derailed\/k9s Cloning into '\/usr\/local\/Homebrew\/Library\/Taps\/derailed\/homebrew-k9s'... remote: Enumerating objects: 788, done. remote: Counting objects: 100% (372\/372), done. remote: Compressing objects: 100% (186\/186), done. remote: Total 788 (delta 90), reused 0 (delta 0), pack-reused 416 Receiving objects: 100% (788\/788), 86.15 KiB | 4.53 MiB\/s, done. Resolving deltas: 100% (192\/192), done. Tapped 1 formula (12 files, 113.2KB). ==&gt; Downloading https:\/\/github.com\/derailed\/k9s\/releases\/download\/v0.25.18\/k9s_D ==&gt; Downloading from https:\/\/objects.githubusercontent.com\/github-production-rel ######################################################################## 100.0% ==&gt; Installing k9s from derailed\/k9s \ud83c\udf7a \/usr\/local\/Cellar\/k9s\/0.25.18: 5 files, 59.3MB, built in 6 seconds ==&gt; Running `brew cleanup k9s`... Disable this behaviour by setting HOMEBREW_NO_INSTALL_CLEANUP. Hide these hints with HOMEBREW_NO_ENV_HINTS (see `man brew`). #Docker ##( 11\/22\/22@ 3:43PM )( donbuddenbaum@donbs-imac ):~ docker run \u2013rm -it -v ~\/.kube\/config:\/root\/.kube\/config quay.io\/derailed\/k9s","tags":"","url":"utilities\/k9s.html"},{"title":"kube shark","text":"Table of Contents Kube Shark References Uninstall #( 06\/03\/24@ 4:16PM )( donbuddenbaum@donbs-imac ):~\/Documents #Kube Shark #References Navigating Kubernetes Networks: How KubeShark Makes It Simple #Uninstall ##( 06\/03\/24@ 4:16PM )( donbuddenbaum@donbs-imac ):~\/Documents kubeshark clean 2024-06-03T16:28:53-04:00 INF versionCheck.go:23 &gt; Checking for a newer version... 2024-06-03T16:28:53-04:00 INF helm.go:173 &gt; uninstall: Deleting kubeshark 2024-06-03T16:28:54-04:00 WRN versionCheck.go:48 &gt; There is a new release! v52.3.59 -&gt; v52.3.62 Please upgrade to the latest release, as new releases are not always backward compatible. Run: command=&quot;sh &lt;(curl -Ls https:\/\/kubeshark.co\/install)&quot; 2024-06-03T16:28:54-04:00 INF helm.go:173 &gt; uninstall: given cascade value: , defaulting to delete propagation background 2024-06-03T16:28:54-04:00 INF helm.go:173 &gt; Starting delete for &quot;kubeshark-worker-metrics&quot; Service 2024-06-03T16:28:54-04:00 INF helm.go:173 &gt; Starting delete for &quot;kubeshark-front&quot; Service 2024-06-03T16:28:54-04:00 INF helm.go:173 &gt; Starting delete for &quot;kubeshark-hub&quot; Service 2024-06-03T16:28:54-04:00 INF helm.go:173 &gt; Starting delete for &quot;kubeshark-hub&quot; Deployment 2024-06-03T16:28:54-04:00 INF helm.go:173 &gt; Starting delete for &quot;kubeshark-front&quot; Deployment 2024-06-03T16:28:54-04:00 INF helm.go:173 &gt; Starting delete for &quot;kubeshark-worker-daemon-set&quot; DaemonSet 2024-06-03T16:28:54-04:00 INF helm.go:173 &gt; Starting delete for &quot;kubeshark-self-config-role-binding&quot; RoleBinding 2024-06-03T16:28:54-04:00 INF helm.go:173 &gt; Starting delete for &quot;kubeshark-self-config-role&quot; Role 2024-06-03T16:28:54-04:00 INF helm.go:173 &gt; Starting delete for &quot;kubeshark-cluster-role-binding-default&quot; ClusterRoleBinding 2024-06-03T16:28:54-04:00 INF helm.go:173 &gt; Starting delete for &quot;kubeshark-cluster-role-default&quot; ClusterRole 2024-06-03T16:28:54-04:00 INF helm.go:173 &gt; Starting delete for &quot;kubeshark-config-map&quot; ConfigMap 2024-06-03T16:28:54-04:00 INF helm.go:173 &gt; Starting delete for &quot;kubeshark-nginx-config-map&quot; ConfigMap 2024-06-03T16:28:55-04:00 INF helm.go:173 &gt; Starting delete for &quot;kubeshark-saml-x509-key-secret&quot; Secret 2024-06-03T16:28:55-04:00 INF helm.go:173 &gt; Starting delete for &quot;kubeshark-secret&quot; Secret 2024-06-03T16:28:55-04:00 INF helm.go:173 &gt; Starting delete for &quot;kubeshark-saml-x509-crt-secret&quot; Secret 2024-06-03T16:28:55-04:00 INF helm.go:173 &gt; Starting delete for &quot;kubeshark-service-account&quot; ServiceAccount 2024-06-03T16:28:55-04:00 INF helm.go:173 &gt; Starting delete for &quot;kubeshark-hub-network-policy&quot; NetworkPolicy 2024-06-03T16:28:55-04:00 INF helm.go:173 &gt; Starting delete for &quot;kubeshark-worker-network-policy&quot; NetworkPolicy 2024-06-03T16:28:55-04:00 INF helm.go:173 &gt; Starting delete for &quot;kubeshark-front-network-policy&quot; NetworkPolicy 2024-06-03T16:28:55-04:00 INF helm.go:173 &gt; purge requested for kubeshark 2024-06-03T16:28:55-04:00 INF clean.go:27 &gt; Uninstalled the Helm release: kubeshark","tags":"","url":"utilities\/kube_shark.html"},{"title":"pvc backup","text":"Table of Contents Backing up PVC on NFD Reference Cleanup dbuddenbaum@donb-ms7821:\/media\/dbuddenbaum\/nfs\/nfs-server$ dbuddenbaum@donb-ms7821:\/media\/dbuddenbaum\/nfs\/nfs-server$ dbuddenbaum@donb-ms7821:\/media\/dbuddenbaum\/nfs\/nfs-server$ Backup dbuddenbaum@donb-ms7821:\/media\/dbuddenbaum\/nfs\/nfs-server$ dbuddenbaum@donb-ms7821:\/mnt\/sdd1$ Restore #Backing up PVC on NFD #Reference Which tool to backup an ext4 partition? FSArchiver - Quick Start guide #Cleanup #dbuddenbaum@donb-ms7821:\/media\/dbuddenbaum\/nfs\/nfs-server$ sudo rm -rf pvc-05da76b0-f710-4813-980b-1dde5acf2b87 #dbuddenbaum@donb-ms7821:\/media\/dbuddenbaum\/nfs\/nfs-server$ ls -la total 28 drwxrwxrwx 6 nobody nogroup 4096 May 12 00:41 . drwxrwxrwx 3 root root 4096 Apr 10 2022 .. drwxr-xr-x 4 root root 4096 May 11 21:29 pvc-12dd438f-229d-4689-95be-95705d37f450 drwxr-xr-x 4 systemd-coredump root 4096 May 12 00:03 pvc-13f27a96-e4e6-44b7-b2ce-1335f55e6455 drwxr-xr-x 4 root root 4096 May 11 01:29 pvc-2c9d7f1a-9aab-4d1c-9241-ad05b4c57048 drwxr-xr-x 2 root root 4096 Apr 9 22:45 pvc-cb075f35-3b04-4a75-9e98-c7402d54f11d -rw-r--r-- 1 502 dialout 8 Apr 10 2022 test #dbuddenbaum@donb-ms7821:\/media\/dbuddenbaum\/nfs\/nfs-server$ sudo du -hsc * 428K pvc-12dd438f-229d-4689-95be-95705d37f450 301M pvc-13f27a96-e4e6-44b7-b2ce-1335f55e6455 80K pvc-2c9d7f1a-9aab-4d1c-9241-ad05b4c57048 4.0K pvc-cb075f35-3b04-4a75-9e98-c7402d54f11d 4.0K test 302M total #Backup save the contents of \/usr\/src\/linux to an archive (similar to tar): fsarchiver savedir \/data\/linux-sources.fsa \/usr\/src\/linux #dbuddenbaum@donb-ms7821:\/media\/dbuddenbaum\/nfs\/nfs-server$ sudo fsarchiver savedir \/mnt\/sdd1\/20240512nfs.fsa \/media\/dbuddenbaum\/nfs\/nfs-server -Z8 -j4 Statistics for filesystem 0 * files successfully processed:....regfiles=46, directories=37, symlinks=0, hardlinks=0, specials=0 * files with errors:...............regfiles=0, directories=0, symlinks=0, hardlinks=0, specials=0 #dbuddenbaum@donb-ms7821:\/mnt\/sdd1$ ls -la total 1168 drwxrwxrwx 4 nobody nogroup 4096 May 12 01:14 . drwxr-xr-x 4 root root 4096 May 11 00:47 .. -rw-r--r-- 1 root root 1152360 May 12 01:14 20240512nfs.fsa #Restore restore an archive made of simple files to \/tmp\/extract: fsarchiver restdir \/data\/linux-sources.fsa \/tmp\/extract","tags":"","url":"utilities\/pvc_backup.html"}]});